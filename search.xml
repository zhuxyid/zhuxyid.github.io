<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2018%2F11%2F27%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx是什么Nginx是一个Web服务器,也是个高性能方向代理服务器，Nginx起初为了解决基于进程模型产生的C10k问题，由俄罗斯lgor sysoev研发。 Nginxy有企业版本Nginx Plus，还有二次发行版Tengine，OpenResy（淘宝研发） nginx反向代理支持两种协议 HTTP和MAIL C10K 连接超过10K ,1W个请求,1M =100万个请求 Netcraft可以查看全球服务器Web服务器占有率。 传统上基于进程或线程模型架构的web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。 在设计的最初阶段，nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 Nginx特性模块化设计，较好的扩展性，早期不支持模块的动态装载和卸载 高可靠性，基于Master/Worker模式 支持热部署（平滑升级迁移），不停机的状态下更新配置文件，跟换日志文件，更新服务器程序版本 内存消耗低，10K个keep-alive连接模式下的非活动连接只消耗2.5M内存 支持event-driven事件驱动模型，AIO驱动机制，MMAP内存映射机制 Nginx基本功能 静态资源的web服务器,自身只能简单的接收和响应http http协议的反向代理服务器 pop3,smtp imap4等邮件协议的反向代理 能缓存打开的文件(元数据缓存:文件的描述符等信息),能加快文件的打开速度 支持FastCGI(php-fpm)，UWSGI 等协议机制,实现代理后端应用程序交互 支持过滤器,例如ZIP,SSI(服务端包含) 支持SSL加密机制 模块化（非DSO机制） standard HTTP modules 标准(核心)HTTP模块:自动编译进程序不止一个Optional HTTP modules 可选http模块Mail modules 邮件模块3rd party modules第三方模块,在编译时需手动指明加载方式加载 Nginx服务相关功能虚拟主机，Keepalive，访问日志，日志缓冲（提高存取西能），URL重写，路径别名，访问控制（IP和用户），支持速率限制，并发限制 Nginx架构Master/Worker模型： 一个master进程可以生成一个或者多个worker进程，每个worker基于事件驱动，响应用户请求, 其支持sendfile,sendfile64,这两种支持的文件大小不同 事件驱动：Linux(epoll)，FreeBSD(kqueue)，Solaris(/dev/poll) 除此之外配置了缓存时还会有缓存加载器进程cache loader和缓存管理器进程cache manager等，所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。 主进程Master以root用户身份运行，而Worker、Cache Loader和Cache Manager均应以非特权用户身份运行。 Master 加载，验证配置文件 创建，绑定，关闭套接字 管理worker进程（启动，终止，维护） 平滑重启（无需终止服务重载配置） 平滑升级（启用新的二进制程序并在需要时回滚到老版本） 重新打开日志文件，实现日志滑动 其他嵌入式perl，go脚本 Worker 响应客户端请求，提供HTTP服务和代理，提供FastCGI，uWSGI，SCGI等代理 Cache Loader 检查缓存存储中的缓存对象； 使用缓存元数据建立内存数据库； Cache Manager 缓存的失效及过期检验； Nginx安装可使用yum或者源码方式安装 yum安装yum方式很简单，直接使用yum源来安装 12yum install nginx #自动安装依赖关系rpm -ql nginx #查找nginx安装生成的文件 源码安装123456789101112131415161718192021222324252627282930yum install -y pcre-devel openssl-devel zlib-develuseradd nginx -s /sbin/nologin#进入解压后的源码包路径，根据需求来定.** 注意:`--with`都是启用模块，`--without`都是禁用模块 **./configure \ --prefix=/usr \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --user=nginx \ --group=nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --with-http_ssl_module \ #使用ssl模块 --with-http_flv_module \ #使用flv流模块 --with-http_stub_status_module \ #使用监控模块 --with-http_gzip_static_module \ #使用gizp模块 --with-pcre #pcre模块启用 --with-file-aio #支持文件异步 --with-http_image_filter_module #支持图片过滤 --http-client-body-temp-path=/var/tmp/nginx/client/ \ #请求报文主体缓存目录 --http-proxy-temp-path=/var/tmp/nginx/proxy/ \ #代理临时目录 --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ #fastcgi目录，支持php框架 --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ #uwsgi目录，支持python框架 --http-scgi-temp-path=/var/tmp/nginx/scgi \ #scgi目录，类似fastcgi另外一种机制# make &amp;&amp; make install 配置文件说明123456789/etc/nginx/nginx.conf 主配置文件 Include conf.d/*.conf/etc/nginx/mime.types 所支持的MIME类型列表/etc/nginx/fastcgi_params fastcgi的配置文件/etc/nginx/fastcgi.conf 与fastcgi_params一般只使用一个/etc/nginx/uwsgi_params 与uwsgi框架的配置文件/etc/nginx/scgi_params cgi的配置文件/etc/nginx/proxy.conf 代理的配置/etc/nginx/sites.conf 配置虚拟主机的 主配置文件/etc/nginx/nginx.conf 格式如下 1234567891011121314151617181920worker_processerror_loguserevents &#123; use epoll;&#125;http &#123; access_log xxx; upstream server&#123; server IP:PORT &#125; server &#123; location URI &#123; driective &lt;parameters&gt;; &#125; &#125; server &#123; ....; &#125;&#125; MAIN该段落主要是配置Nginx运行启动时候必备参数 和 性能优化 以及 调试定位问题的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263user nginx;worker_processes 1;worker_cpu_affinity auto;worker_rlimit_nofile 10240;timer_resolution 100ms;worker_priority 20;error_log /var/log/nginx/error.logevents &#123; use epoll; worker_connections 1024;&#125;http:&#123; upstream server &#123; .....; &#125; server &#123; ...; location / &#123; ...; &#125; &#125;&#125;user USERNAME#指定nginx启动worker进程时 以什么用户启动worker_processes NUMBER|auto#启动worker个数#如果负载以CPU密集型为主(比如SSL或压缩)则worker数应与CPU数相同;如果以IO密集为主(如大量内容给客户端)，则worker数应是CPU的1.5或2倍worker_cpu_affinity auto|CPUMASK#根据物理cpu自动绑定,worker不使用进程或者线程处理请求,而是直接将worker绑定到CPU上，这样就没有进程切换这一说法#worker_processes 4;#worker_cpu_affinity 0001 0010 0100 1000;worker_rlimit_nofile NUMBER#设置worker进程打开文件数量，worker_rlimit_nofile需要大于等于woker_connections的大小timer_resolution INTERVAL#用于降低gettimeofday()系统调用的缓存时钟，默认情况下，每次从kevent(),epoll,/dev/poll,select()，poll都会执行此系统调用worker_priority [-20~19]#设置worker进程优先级，官方说明一般在-20到19之间，如果想要woker运行快优先级可调到20error_log PATHFILE#配置错误日志，改参数可用于main,http,server,已经localtion上下文中.events事件驱动I/O框架use [ kqueue | rtsig | epoll | /dev/epoll | select | poll | eventport ]#根据当前系统内核版本设置适合自己的事件模型。#kqueue freeBSD 4.1+#epoll linux2.6+#/dev/epoll solaris 7 11/99+worker_connections NUMBER#事件驱动每个worker支持的连接数,如果worker_process为2，那么服务器最大支持2048个连接#当nginx作为web服务时 最大客户端处理数max_clients = worker_processes * worker_connections#当nginx作为反向代理时 最大客户端处理数max_clients = worker_processes * worker_connections/2#这里的max_clients很多人都疑惑为什么有人认为max_clients = worker_preocesses * worker_connections/4呢？#如果max_clients指的是建立连接最大客户数,由于每个游览器默认两个并发连接,那么nginx作为反向代理是/4#如果max_clients指的是处理客户端数,那就nginx作为反向代理是/2 HTTPHTTP上下文配置用于http的各模块，此类指令很多，每个模块都有专用指令，具体参考nginx官方wiki模块部分的说明。大致上这些模块所提供的配置指令还可以分为以下几个类别: 1234567客户端指令：client_body_buffer_size，client_header_buffer_size，client_header_timeout，keepalive_timeout...文件IO指令：aio，directio，open_file_cache，open_file_cache_min_uses，open_file_cache_valid，sendfile....hash类指令：用于定义Nginx为特定的变量分配多大的内存空间，如types_bash_bucket_size，server_name_hash_bucket_size，variables_hash_bucket_size套接字指令：用于定义Nginx如何处理TCP套接字相关的功能，如tcp_nodelay（用于keepalive功能启用）和tcp_nopush（用于sendfile启用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117...;http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; #sendfile on; #tcp_nopush on; tcp_nodeplay on keepalive_timeout 65; keepalive_requests 100; gzip on; gzip_comp_level 2; gzip_types mine.types; gzip_min_length 1k; upstream name &#123; server 192.168.1.10:8080 keepalive 300 &#125; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;include mine.types#指定包含文件类型,mine.type里面定义，如html,css,gif,jpeg,js,txt....default_type application/octet-stream#默认是octet-stream，如果一个文件在mime.types没定义，就使用默认的类型octet-stream，这个表示下载，#如果设置default_type text/html;则表示可以在游览器查看log_format main string#设定log日志格式以及名称，main可以随便定义，string必须是nginx可识别的变量,可以自定义变量#$remote_addr，$http_x_forwarded_for #客户端的ip地址； #$remote_user #客户端用户名称； #$time_local #访问时间与时区； #$request #请求的url与http协议； #$status #请求状态，200,302，404，500等， #$body_bytes_sent #发送给客户端文件主体内容大小； #$request_body #请求体 #$http_referer #从那个页面链接访问过来的； #$http_user_agent #客户浏览器的相关信息； access_log path format_name#设定访问日志路径，使用哪个名称日志格式。#还有设置缓存大小刷新时间间隔，以及定义缓冲提升nginx性能#open_log_file_cache max=N [inactive=time] [min_uses] [valid=time]#open_log_file cache off;#max 设置缓存中描述符最大数量，如果缓存占满，最近最少使用(LRU)的描述符被关闭#inactive 设置缓存文件描述符在多长时间内没有被访问就关闭； 默认为10秒。#min_uses 设置在inactive参数指定的时间里， 最少访问多少次才能使文件描述符保留在缓存中；默认为1。#valid 设置一段用于检查超时后文件是否仍以同样名字存在的时间； 默认为60秒。#off 禁用缓存。sendfile on|off#在内核完成后直接封装响应客户端(支持小文件) sendfile64(支持大文件)#普通响应步骤client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;用户空间---&gt;内核(复制)--&gt;client#senfile响应client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;client#但是如果使用file aio模块，必须禁用sendfile支持tcp_nopush on#不做推送，在开启sendfile才有效，它和tcp_nodeplay互斥，TCP_CORK是linux下tcp/ip传输的一个标准（一般情况下tcp交互中，当程序收到数据包后马上传送不等待，而TCP_CORK选项是数据包不会传送出去，等到数据包最大时一次性传输，有助于解决网络拥堵），在tcp_nopush on时候，才会设置TCP_CORK方法，该选项对于www.ftp等大文件才有帮助。在FreeBSD使用TCP_NOPUSH套接字，在Linux使用TCP_CORK套接字，详见Nagle算法tcp_nodeplay on#对于keepalive模式下连接是否使用tcp_nodelay选项，默认关闭，其功能类似tcp_nopush，将多个小报文合并成一个报文一起发送，提高宽带利用率，将发往同一个主机很小的TCP报文合并成一个,实际生产对于用户请求即使浪费带宽也不能合并请求keepalive_timeout 75 75#长链接超时时间，0表示禁用,默认为75s，请求完成后还需要保持多久连接，目的是减少创建连接过程给系统带来的耗损,通常默认足够，如果内部服务器通讯场景过大建议增大。#第一个75设置keep-alive客户端连接在服务端保持开启超时时间，第二个75可选，在客户端响应的header区域中设置一个"keep-alive:timeout=time"#当nginx作为反向代理时候，为了支持场链接#从client到nginx 和 nginx到server连接都需要设置长连接#例子http &#123; keepalive_timeout 75 upstream www &#123; server 192.168.0.1:8080; server 192.168.0.2:8080; keepalive 300; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;#upstream 中的keepalive，设置upstream服务器的空闲keepalive连接最大数量，当数量被突破时，最近使用最少连接将被关闭，keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量。#HTTP协议对长连接支持从1.1版本后才有，需要通过proxy_http_version指令设置为1.1#而Connection header应该被清理，清理从客户端过来的http header，因为即使是客户端和nginx之间是短连接，nginx和upstream之间也是可以开启长连接。所以需要清理客户端请求中的"Conection" headerkeepalive_requests #在keepalive连接上允许请求的最大资源数量，默认为100，当一个keepalive建立后，nginx就会为这个连接设置一个计数器，记录这个keepalive长链接上已经接受并处理的客户端请求数量，如果达到这个参数设置最大时，nginx会强行关闭这个长链接，使客户端重新建立新的场链接。#大多数情况下QPS不是很高，100足够，但是对一些QPS高比如(10000QPS,甚至更高)100显的太低,#QPS=10000时候，客户端每秒发送10000个请求(通常建立长链接)，每个连接最多跑100次请求，意味着每秒就有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒重新新建100个连接，从而导致大量TIME_WAIT的socket链接，因此对于QPS较高场景，很有必要加大这个设置，避免出现大量连接被生成在抛弃。#出现大量TIME_WAIT情况#nginx出现大量TIME_WAIT情况有两种#keepalive_request设置较小，高并发超过此值后nginx悔强制关闭客户端保存keepalive长连接；(主动关闭连接后导致nginx出现TIME_WAIT)#keeaplive设置比较小(空闲数小)，导致高并发nginx会平凡出现连接数抖动(超过该值会关闭连接)，不停关闭\开启和后端server保持的keepalive长连接#后端server端出现大量TIME_WAIT情况#nginx没有打开和后端长连接，即使设置proxy_http_version 1.1和proxy_set_header Connection "" ;从而导致后端server每次关闭连接，高并发出现server端大量TIME_WAITgzip on|off#开启压缩gzip_comp_level [1-9]#压缩比率，默认为1，越大越占用cpu使用率gzip_types mine.types#指名对那些类型资源进行压缩gzip_min_length 0#设置允许压缩页面最小字节数，页面字节从header头中的content-length获取，默认值0，不管页面多大都会被压缩，通常设置大于1k字节，小于1k可能越压越大，比如本身10字节，压缩一下反而大了，噗噗噗 UPSTREAMupstream模块可定义一个新的上下文，位于server之上http之下，包含一组upstream服务器，这些服务器可能被赋予不同权重，不同类型，设置可以基于维护原因被标记为down。 123456789101112131415161718192021222324252627282930313233http&#123; ...; upstream myserver &#123; service 192.168.1.10:8080 wight=5 max_fails=3 file_timeout=6; service 192.168.1.10:8090 wight=5 max_fails=3 file_timeout=6; service 192.168.1.20:8080 backup; service 192.168.1.30:8080 down; ip_hash; keepalive 300; &#125; service &#123; ..; location &#123; ..; &#125; &#125;&#125;upstream模块常用的指令有：round-robin #默认为轮轮询ip_hash #基于客户端IP地址完成请求的分发，它可以保证来自于同一个客户端的请求始终被转发至同一个upstream服务器least_conn #最少连接调度算法keepalive： #每个worker进程为发送到upstream服务器的连接所缓存的个数；server:定义一个upstream服务器的地址，还可包括一系列可选参数，如： weight： 权重； max_fails： 最大失败连接次数，失败连接的超时时长由fail_timeout指定； fail_timeout： 等待请求的目标服务器发送响应的时长； backup： 用于fallback的目的，所有服务均故障时才启动此服务器； down： 手动标记其不再处理任何请求； SERVER用于定义虚拟服务器相关的属性，位于http上下文，常见的指令有backlog、rcvbuf、bind及sndbuf等 12345678910111213141516171819202122232425262728293031323334....;http &#123; ....; upstream &#123; ...; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; root /www; location / &#123; ....; &#125;&#125;listen [:port] | [default_server] | [ssl] [http2 | spdy];#监听端口，如果有多块网卡可以使用listen 192.168.1.2:80#ssl 用于限制只能通过SSL连接提供服务，不是以端口确认其协议,需要启用SSL,需要在监听的端口后面, 添加ssl选项。#http2 支持http version2，需要在nginx编译时开启http2协议支持#spdy google研发的http协议，比http1.1性能好。全称speedy,在编译时编译了spdy模块情况下，用于支持spdy协议server_name localhost;#服务名称或者域名，支持正则表达式匹配*.baidu.com 或者 ~^.*.baidu.com$charset koi8-r;#字符集设置access_log PATH main;#日志路径，以及使用哪个日志格式root /www;#设置web资源路径映射,用于指明请求url所对应的文件目录路径,可用于server或者location中 LOCATION通常位于server上下文，用于设定某URI的访问属性，location也可以嵌套, 12345678910111213141516171819202122232425262728293031323334353637383940....;http &#123; ....; upstream &#123; ...; &#125; server &#123; ...; location / &#123; root html; &#125; location /images/ &#123; alias /data/imgs/; &#125; location = /50x.html &#123; root html; &#125; &#125;&#125;root html#定义url路径，这里是绝对路径，nginx下的html目录,当访问daemon.com/时候访问的是nginx下的html目录alias /data/imgs#只能用于location配置段,定义路径别名root和alias区别location /imags/ &#123; root /data/imgs/;&#125;location /imags/ &#123; alias /data/imgs/;&#125; root指令:给定的路径对应location的"/",这个URI/imags/test.jpg --&gt; /data/imgs/imags/test.jpgalias指令:路径为对应的location的"/url/"这个URI/imags/test.jpg --&gt; /data/imgs/test.jpg location说明12345678910111213141516171819location语法格式:location [ = | ~ | ~* | ^~ ] url &#123; ...&#125;= : URI的精确匹配~ : 做正则表达式匹配,区分字符大小写~* : 做正则表达式匹配,不区分字符大小写^~ : URI的左半部分匹配,不区分字符大小写允许根据用户请求的URI来匹配定义的各location,匹配到时, 此请求将被相应的location块中的配置所处理, 简言之:用于为需要用到专用配置的uri提供特定配置，当匹配多次时,其匹配优先级为:精确匹配=,^~,~或~*,不带符号的URL, 如果优先级都一样, 就匹配最精确的规则#看个例子如果域名是www.zhuxyid.com,访问www.zhuxyid.com/helloworl的话location /hello &#123; #这里能匹配到 root xxx;&#125;location /hello/ &#123; #这里则不能匹配 root xxx;&#125; Nginx反向代理Nginx通过proxy模块实现反向代理功能。在作为web反向代理服务器时，nginx负责接收客户请求，并能够根据URI、客户端参数或其它的处理逻辑将用户请求调度至上游服务器上(upstream server)。nginx在实现反向代理功能时的最重要指令为proxy_pass，它能够将location定义的某URI代理至指定的上游服务器(组)上。 反向代理：正对外部网络，如果客户端访问某个网站，但该网站不提供页面，只把请求代理只后端，在从后端返回至代理，在响应给客户端，该代理称作反向代理。 正向代理：针对内部网络，如果客户端不能访问外网，需要设置通过某台机器代理至外网，外网结果返回至代理机，在返回给客户端，该代理称作正向代理。 透明代理：针对内部网络，不需要设置任何代理服务器地址，但是需要将网关指向代理服务器。 参考：Nginx proxy中文文档 proxy模块指令proxy模块的可用配置指令非常多，它们分别用于定义proxy模块工作时的诸多属性，如连接超时时长、代理时使用http协议版本等。下面对常用的指令做一个简单说明。 1234567891011121314151617181920212223242526272829proxy_connect_timeout： #nginx将一个请求发送至upstream server之前等待的最大时长；proxy_cookie_domain： #将upstream server通过Set-Cookie首部设定的domain属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量；proxy_cookie_path: #将upstream server通过Set-Cookie首部设定的path属性修改为指定的值，其值可以为一个字符串、正则表达式的模式或一个引用的变量；proxy_hide_header： #设定发送给客户端的报文中需要隐藏的首部；proxy_pass： #指定将请求代理至upstream server的URL路径；proxy_set_header： #将发送至upsream server的报文的某首部进行重写；proxy_redirect： #重写location并刷新从upstream server收到的报文的首部；proxy_send_timeout： #在连接断开之前两次发送至upstream server的写操作的最大间隔时长；proxy_read_timeout： #在连接断开之前两次从接收upstream server接收读操作的最大间隔时长；如下面的一个示例：proxy_redirect off;proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;client_max_body_size 10m;client_body_buffer_size 128k;proxy_connect_timeout 30;proxy_send_timeout 15;proxy_read_timeout 15;]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F11%2F26%2FDockerfile%2F</url>
    <content type="text"><![CDATA[关于Docker基础,请看http://blog.zhuxyid.com/2018/11/23/Docker 自制镜像方式​ 基于容器方式来制作镜像，这种方法配置繁琐,不适合使用,每次配置文件更该都需要制作镜像 ​ 基于Dockerfile DockerfileDockerfile是一个文本文档，包含用户可以在命令行上调用命令组合，使用docker build用户可以自动构建一个连续执行多个命令行 Dockerfile编译完成科研使用docker build来进行编译Dockerfile文件 1docker build -t IMAGE_NAME:TAGS /DOCKERFILE_PATH/Dockerfile Dockerfile注意事项12345Comment #注释 INSTRUCTION arguments #指令 参数(指令不区分大小写，约定惯例尽量使用大写) docker运行指令是按照你的指令的顺序。Dockerfile文件首字母必须是大写 .dockeringore定义忽略哪些文件，打包时不包含这些文件 Dockerfile语法FROMFROM指令是最重的 一个且必须为Dockerfile文件开篇的第一个非注释行, 用于镜像文件构建过程 指定基准镜像，后续的指令运行于 此基准镜像 所提供的运行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在docker主机上查找指定的镜像文件，其不存在时，则会从Docker hub registry拉去所需的镜像文件 (如果找不到指定的镜像文件，docker build会返回一个错误信息) 123456789语法:FROM &lt;repository&gt;[:&lt;tag&gt;]FROM &lt;repository&gt;@&lt;digest&gt; @digest指定hash码进行验证 &lt;repository&gt;:指定作为base image的名称 &lt;tag&gt;:base image的标签 可选性，默认是latest例子:# Description: test imgFROM busybox:latest MAINTANIER用于让dockerfile制作者提供信息，Dockerfile并不限制MAINTAINER指令可在出现的位置，但推荐放在FROM指令后 1234567891011语法:MAINTAINER &lt;authtor's detail&gt;&lt;authtor's detail&gt; 可以是任何文本信息，但是通常使用名称和地址邮箱例子:MAINTAINER "zhuxyid &lt;zhuxyid@gmail.com&gt;"LABLE:指定镜像元数据Syntax:LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;例子: LABEL maintainer="zhuxyid &lt;zhuxyid@gmail.com&gt;" COPY用于从Docker主机复制文件到创建的新镜像文件 1234567891011121314语法：COPY &lt;src&gt;&lt;dest&gt;COPY ["&lt;src&gt;",.."&lt;dest&gt;"] 如果路径有空白字符时候，用这种方式复制 src 源文件，支持使用通配符 dest 目标路径 即正在创建image文件系统路径,建议&lt;dest&gt;为绝对路径，否则COPY指定则以WORKDIR为起始路径文件复制准则:&lt;src&gt; 必须是build上下文中路径，不能是父目录的文件如果&lt;src&gt;是目录，则 内部文件或子目录都会 被递归复制,但&lt;src&gt;自身目录不会被复制 相当于 cp -r src/* /dest如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用通配符，则&lt;dest&gt;必须是一个目录，且必须以/结尾 相当于 cp -r src/* /desc/如果&lt;dest&gt;不存在，则会被自动创建，这包括其父目录路径例子：COPY index.html /data/web/html/ #这里index.html文件必须先创建，而且必须为build目录下！ ADDADD指令类似COPY指令，ADD支持使用TAR文件和URL路径 1234567891011语法:ADD &lt;src&gt;,..&lt;dest&gt;ADD ["&lt;src&gt;",.."&lt;dest&gt;"]操作准则: 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接创建为&lt;dest&gt;; 如果&lt;dest&gt;以/结尾,则文件名URL指定文件将被直接下载并保持为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式tar文本，他将被展开为一个目录，其行为类似"tar -x"命令，然而通过URL获取到的tar文件将不会自动展开 如果&lt;src&gt;有多个，或其间接或直接使用通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径； 如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt; WORKDIR用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 12345678语法:WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指定可出现多次，其路径也可以为相对路径，不过其是相对此前一个WORKDIR指令指定的路径,另外，WORKDIR也可以调用由ENV指定定义的变量例子：WORKDIR /var/logWORKDIR $STATEPATH VOLUME用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上的卷 1234语法:VOLUME &lt;mountpoint&gt;VOLUME ["&lt;mountpoint&gt;"]如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 EXPOSE用于为容器打开指定要监听的端口以实现与外部通讯,注意，这里只能是定义容器的端口.后期docker下载下来宿主机的端口并不确定 123456789语法：EXPOSE &lt;port&gt; [/&lt;protocol&gt;][&lt;port&gt;[/&lt;protocol&gt;]...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议EXPOSE指令可一次指定多个端口，如EXPORT 11211/udp 11211/tcpdocker run --name ttt -P 可以自动暴露需要暴露的端口 ENV用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY等)所调用 WORKDIR只是工作目录 调用格式为$variable_name或者${variable_name} 123456789语法:ENV &lt;key&gt;&lt;value&gt;ENV &lt;key&gt;=&lt;value&gt;$&#123;NAME:-tom&#125; #如果NAME变量没有值，将他设为tom，如果有值则使用本身$&#123;NAME:+tom&#125; #如果NAME为空则不设置，如果不为空则设置tom第一种格式中,&lt;key&gt;之后的所有内容均被视作其&lt;value&gt;的组成部分，因此，一次只能设置一个变量第二种格式中,可用一次设置多个变量，每个变量为一个&lt;key&gt;=&lt;value&gt; 的键值对，如果&lt;value&gt;中包含空格，可用反斜线(\)进行转移;也可以通过对&lt;value&gt;加引号进行标识,另外反斜线可以续行定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能 RUN用于指定docker build过程中运行的程序，其可以是任何命令 123456789语法:RUN &lt;command&gt;RUN ["&lt;executable&gt;","&lt;param1&gt;","&lt;param2&gt;"]第一个格式中,&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程在容器中的PID不为1，不能接受Unix型号，因此，当使用docker stop container命令停止容器时，次进程接受不到SIGTERM信号第二个格式中，参数就是一个JSON格式的数组，其&lt;executable&gt;为运行的命令，后面的&lt;paramN&gt;为传递给命令的选项或参数；然而此格式指定的命令不会以"/bin/sh -c"来发起；因此常见shell操作，如变量替换以及通配符(?,*等)替换将不会进行；不过如果要运行的命令依赖次shell特性的话，可以将其替换为类似下面格式RUN ["/bin/bash","-c","&lt;excutable&gt;","&lt;param1&gt;"] CMD类似RUN指令，CMD指令也可以用于运行任何命令或应用程序，不过二者运行时间点不同 RUN 指令运行与镜像文件构建过程，而CMD指令运行基于Dockerfile构建出的新映像文件启动一个容器时 CMD 指定的首要 目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器将终止；不过CMD指令的命令其可以被docker run的命令选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅是最后一个会生效，而RUN不是 1234567语法:CMD &lt;command&gt;CMD ["&lt;excutable&gt;","&lt;param1&gt;","&lt;param2&gt;"]CMD ["&lt;param1&gt;","&lt;param2&gt;"]前两种语法格式的意义相RUN第三种则用于为ENTRYPOINT指令提供默认参数 RUN 是运行在docker build过程中的命令，而CMD 是在docker run运行时的命令 注意:一个容器只是用于单个应用。nginx,redis,mysql都是运行在后台 所有进程都是一个进程的子进程，除了init。init是内核启动 比如手动启动nginx，它是shell的子进程，有些shell子经常会占据终端窗口，需要加&amp;符号 nginx &amp; 这里nginx父进程依然是shell，当shell结束后，会将nginx也结束 nohup nginx &amp; 这里是将nginx送到后台，重新赋予一个新的进程，这是shell退出这个依然存在 在用户空间先启动shell,才能使用ls，cat，等命令，可以直接exec执行命令. 在容器中可以基于shell启动程序，也可以通过exec启动程序 在json数组中，引号一定要写双引号，单引号可能会出现问题 ENTRYPOINT类似CMD指定的功能，用于为容器指定默认运行程序，从而使得容器像一个单独的可执行程序 于CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令指定的参数所覆盖，而且，这些命令参数会被当做参数传递给ENTRYPOINT指定指定的程序 不过,docker run命令的–entrypoint选项参数可覆盖ENTRYPOINT指令指定的程序 12345678910111213141516171819202122语法:ENTRYPOINT &lt;command&gt;ENTRYPOINT [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]ENTRYPOINT /bin/http -f -h /data/www/htmldocker run命令传入的命令参数会覆盖CMD指令的内容并且附加到EMTRYPOINT命令最后作为其参数使用Dockerfile文件中可用存在多个ENTRYPOINT指令，但仅最后一个生效如果Dockfile格式是这样CMD和ENTRYPOINT同时存在CMD [&quot;/bin/httpd&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;]CMD /bin/httpd -h /data/web/html #这样写会出错，因为不会被当成参数，需要写成列表的形式ENTRYPOINT /bin/httpd -f -h /data/web/html #如果需要CMD传参，这里建议写成列表，不然有问题CMD和ENTRYPOINT同时存在，那么CMD会将命令变成参数传递给ENTRYPOINT例子CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;] ENTRYPOINT [&quot;/bin/sh&quot;,&quot;-c&quot;]#CMD将传给ENTRYPONT作为默认参数#如果执行docker run --name ttt --rm image:v1 &quot;ls /data&quot;#&quot;ls /data&quot;则会覆盖CMD#如果执行docker run --name ttt --entrypoint &quot;ls&quot; --rm image:v1 &quot;/data&quot;#ls会覆盖EXTRYPOINT,/data覆盖CMD USER用于指定运行image时或者运行Dockerfile中任何RUN,CMD或者ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下, container运行身份是root用户. 123语法USER &lt;UID&gt;|&lt;USERNAME&gt;需要注意:&lt;UID&gt;可以是任意数字，但实践中必须为容器中/etc/passwd中某用户的有效UID,否则docker run会失败 HEALTHCHECK健康状态检查，判断容器里面的程序是否正常运行. 这里需要注意，如果nginx指定的目录不存在，nginx也会运行，但是用户访问是访问不了的，可以断定这虽然是可以运行但不是想要的结果，比如使用curl检测网页200的信息，如果是200则正常，非200则不正常 123456789101112131415HEALTHCHECK定义一个CMD来检测容器中主进程工作状态与否 HEALTHCHECK NONE 拒绝任何监控状态检查格式: HEALTHCHECK [OPTION] CMD --interval=DURATION(default:30s) 每隔多久 --timeout=DURATION(default:30s) 超时时长 --start-period=DURATION(default:0s) 等待主进程初始化完成在检查，如果tomcat这种应用建议等待5秒 --retries=N(default:3) 检查次数，默认3次#检测状态结果：0:success1:unhealthy2:reserved实例:HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1 #每隔5分钟检查，超时时间3s，curl结果如果成功则不管他，如果不成功则返回1 SHELLlinux默认shell是[“/bin/sh”,”-c”] windows默认是[“cmd”,”/S”,”/C”] 格式：SHELL [&quot;/bin/bash&quot;,&quot;-c&quot;] STOPSIGNAL定义停止的信号，默认是15 格式: STOPSIGNAL 14可以修改停止的信号 ARGARG的参数只是一个变量，只在docker build时候使用，在--build-arg &lt;varname&gt;=&lt;value&gt; 12345678910111213141516语法：ARG &lt;name&gt;[=&lt;default value&gt;]ARG version=1.14ARG user=zhuxyid例子:FROM:nginx:$&#123;version&#125;ARG version=1.15LABEL maintainer=$&#123;author&#125;ARG version=&quot;1.15&quot;ARG author=&quot;zhuxyid &lt;772931883@qq.com&gt;&quot;docker build -t nginx ./docker build --build-arg &quot;version=1.16&quot; --build-arg &quot;author=zhuxyid&lt;hello@qq.com&gt;&quot; -t nginx ./ #可以直接在编译时候使用在docker build中可以用--build-arg参数来传值 ONBUILD用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile作用FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中FROM指令在build过程中被执行，将会”触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 12345678910111213141516语法:ONBUILD &lt;INSTRUCTION&gt;#尽管任何指令都可注册成触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和MAINTAINER指令#使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild#在ONBUILD指令中使用ADD或者COPY要格外小心，因为新构建过程中的下下文在缺少指定源文件会失败例子:cat /dockerfile/baseFROM centos:latestONBUILD RUN yum install nginx gcc gcc-c++#docker build -t base.img ./ #这里并不去安装nginx gcc gcc-c++cat /dockerfile/phpprojectFROM base.img #指定基于刚才创建的base.img作为base imageRUM yum install php-5.6#docker build -t php:v1 ./ #这里才会去安装， Example1234567891011121314151617181920212223242526272829303132333435363738394041424344mkdir /data/container/web1 cp -r /etc/yum.repos.d /data/container/web1/ cd /data/container/web1 wget &lt;http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.90/bin/apache-tomcat-7.0.90.tar.gz&gt; #more Dockerfile #Description: test dockerfile FROM busybox:latest LABEL maintainer=&quot;zhuxyid &lt;zhuxyid@gmail.com&gt;&quot; ENV DOC_ROOT /data/web/html/ #定义DOC_ROOT变量 ENV TOMCAT_ROOT=/data/tomcat/ \ #定义多个变量 TOMCAT_VERSION=&quot;tomcat-7.0.90&quot; \ NGINX_VERSION=&quot;nginx-1.14.0.tar.gz&quot; COPY index.html $DOC_ROOT COPY yum.repos.d /etc/yum.repos.d/ WORKDIR /opt/ADD http://nginx.org/download/nginx-1.14.0.tar.gz ./ VOLUME /data/www ADD apache-$&#123;TOMCAT_VERSION&#125;.tar.gz $&#123;TOMCAT_ROOT:-/data/tomcat/&#125; EXPOSE 80/tcp RUN cd /opt &amp;&amp; \ tar xf $&#123;NGINX_VERSION&#125; &amp;&amp; \ mv nginx-1.14.0 /usr/local/nginx #建议使用一条命令，因为如果多个RUN 那么层级就会越多 echo &quot;this is docker build image&quot; &gt; index.html docker build -t zhuxyid/index:v1 ./#-t指定name:tagdocker run --name web1 -it --rm zhuxyid/index:v1 cat /data/web/html/index.html #查看web1容器中/data/web/html是否有文件index docker run --name webserver --rm -P zhuxyid/index:v1 httpd -f -h /data/web/html docker port webserver docker run --name ttest --rm -P zhuxyid/index:v1 printenv#prinenv查看环境变量 #注意在启动容器的时候可以重新设置环境变量 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 printenv #在初始化容器时候可以重新赋值 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 ls /data/tomcat/apache-tomcat-7.0.90.tar.gz #这里只是重新赋值变量并不能修改image，因为这是docker build中已经生成了]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F11%2F23%2FDocker%2F</url>
    <content type="text"><![CDATA[容器是什么？ 容器是一种基础工具，泛指任何可以用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，存储，运输物品；物体可以被放置在容器中，而容器可以保护内容物. 虚拟化技术有哪些？主机级别 虚拟化 完全 虚拟化：Vmware，Kvm，Xen 半 虚拟化：Xen,UML Xen如果CPU不支持虚拟化技术那就是半虚拟化，如果支持就是全虚拟化 半虚拟化：修改内核，通过被虚拟化出来的操作系统它是运行在虚拟化技术软件上的，虚拟化出来的操作系统执行的进程还是运行在真实机器上 完全虚拟化：不需要修改内核，直接通过虚拟机化技术软件上运行的操作系统。 容器级别 虚拟化 LXC,OpenVz,Solaris Containers,FreeBSD jails LXC(LinuX Container)容器是内核虚拟化技术,可以提供轻量级的虚拟化,以便隔离进程和资源,不需要提供指令解释机制以及全虚拟化的其他复杂性.容器可以有效的将单个操作系统管理的资源划分到孤立的组件中,以便更好的孤立组之间的平衡有冲突的资源使用需求。 早期容器应用在jail中,后来移植到linux中vserver(chroot),chroot所隔离仅仅只是看上去的,并没有真正隔离。 Linux namespace 是linux提供一种内核级别环境隔离的方法，有6种不同名称空间: linux namesapce: namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 MOUNT CLONE_NEWNS 挂载点(文件系统) 2.4.19 IPC CLONE_NEWIPC 信号量,消息队列,共享内存 2.6.19 PID CLONE_NEWPID 进程变化 2.6.24 USER CLONE_NEWUSER 用户和用户组 3.8 NETWORK CLONE_NEWNET 网络设备,网络栈,端口等 2.6.29 Docker是什么？Docker是LXC增强版,Docker简化容器使用难度,通常一个容器中只运行一个进程. 对开发来说带来极大便利,分发容易,一次编写到处运行 然而对运维来说(有优点有缺点), 对开发极大便利需要运维干什么? Docker安装环境说明: 操作系统发行版:CentOS7.4 内核版本:3.10+ 安装说明: 使用yum方式安装,下载国内docker的yum源,加速下载. 安装过程:12345wget -P /etc/yum.repos.d/ https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i s@https://download.docker.com/@https://mirrors.tuna.tsinghua.edu.cn/docker-ce/@g /etc/yum.repos.d/docker-ce.repoyum repolist | grep docker-ceyum install docker-cesystemctl start docker.service 此时docker已经启动了，现在我们来搞清楚什么是docker Docker架构c/s架构，由三个组件（Docker Daemon,Docker Client,Docker Registry）构成 Docker Registry：​ 类似GitHub,只不过Docker Registry是存放镜像的仓库， 官方 https://hub.docker.com 国内 https://www.docker-cn.com/ 当然也可以自己部署一个仓库，建议用Harbor。 Docker Daemon：​ Docker进程，Docker核心服务。 这个类比数据库，比如数据库是放数据的，启动数据库后，等待客户端连接后才能操作。 也就是当docker启动时，等待docker客户端来操作。 Docker Client：​ Docker客户端工具,用来操作Docker的 比如我想在仓库下载一个镜像，从而启动一个容器，在容器中启动一个nginx服务,都是在客户端操作的。（docker client是发出者，docker daemon是执行者） 这里提到的镜像和容器一定要区分清楚。 如果是开发,那这么理解：镜像就是你创建的类，容器就是你的对象，对象是通过类实例化而来。也就是容器通过镜像而来,（容器依赖于镜像） 不要问镜像怎么来的，上面提过镜像是在仓库中。 也不要问仓库中的镜像怎么来的，那是别人做好的。因为你也可以自己做镜像。 Docker客户端操作12docker --help 格式:docker [option] command [args] 镜像类操作1234567891011121314docker search SOFTWARE_NAME #查找镜像名称示例: docker search tomcat #查找tomcat相关镜像，通常建议使用官方镜像，OFFICIAL 为OK的，或者Star点赞数高的镜像，原因自己悟docker pull SOFTWARE_NAME:TAGS #下载镜像示例: docker pull tomcat #下载tomcat镜像，如果不指定tags就下载latest版本 docker pull tomcat:7.0.92-jre8-alpine #详见hub.docker.com找到指定的镜像后在看tagdocker image ls #查看本地镜像，如果没有下载那么这里为空docker image rm SOFTWARE_NAME:TAGS #删除本地镜像示例: docker image rm tomcat #如果不指定删除镜像版本默认删除latest 容器类操作123456789101112131415161718192021222324252627282930313233343536373839404142docker run #运行容器，需要指定镜像实例: docker run tomcat #运行镜像为tomcat的容器,容器里面有tomcat,启动容器后tomcat也将运行起来，容器里面的程序都是在前台运行，会占用窗口 docker run --name myapp -d tomcat #启动myapp容器，镜像使用tomcat:latest，以后台运行 更多命令使用:docker run --help docker ps #查看运行中的容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee1ff8df6e70 tomcat "catalina.sh run" 3 seconds ago Up 2 seconds 8080/tcp myapp说明: 如果在docker run不指定容器名称会随机创建一个容器名称。 端口是容器内的端口.关于docker网络的内容下面会有讲解docker exec实例: docker exec -it myapp /bin/bash #进入myapp容器中 -it #新建一个tty并且进入docker stop实例: docker stop myapp #停止myapp容器 docker ps -a #查看所有容器，如果不加-a不能看到停止的容器 docker start实例: docker start myapp #运行停止的容器docker restart #重启容器实例: docker restart myappdocker rm #删除容器实例: docker rm myappdocker logs #查看容器运行的程序日志实例: docker logs myapp docker kill #杀死容器里的进程，进程一旦停止，容器也就停止。因为容器一般只运行一个前台程序，容器的生命周期下面会讲解实例: docker kill myapp Docker ImageDocker镜像包含启动容器的所需文件系统以及其内容，因此，用于创建并启动docker容器： 分层机制：镜像采用分层构建机制，最底层为bootfs,其为rootfs。 rootfs：用于系统引导的文件系统，包含bootloader和kernel，容器启动完成后被卸载以节约内存资源 rootfs：位于bootfs之上，表现为docker容器根文件系统 传统模式中，系统启动时，内核挂载rootfs时首先将其挂载为“只读”模式，自检其完整性 完成后将其重新挂载为读写模式 docker中，rootfs由内核挂载为“只读”模式，而通过“联合挂载”技术额外挂载一个可写层，容器就是在镜像多了一个可写层 传统模式: Docker: docker镜像层级：位于下层的镜像 称之为 父镜像(parent image)，最底层的称之为 基础镜像(base image) 最上层“可读写成”，下面为“只读层” 联合挂载：Aufs（advanced multi-layered unification filesystem ） 高级多层统一文件系统，同于实现linux平台中的联合挂载 Aufs是unionFS的重新实现,docker最初使用aufs作为容器文件系统层，目前仍作为存储后端之一来支持 Aufs另外一个实现是overlayFS，后者从3.18版本中开始被合并到linux内核中，overlayerFS是叠加文件系统 除了aufs，docker还支持btrFS,Device Mapper和VSF等。在ubuntu中，默认是aufs device mapper在linux2.6中支持逻辑卷管理的通过设备映射机制，它为实现用于存储资源管理的块设备驱动提供一个高度模块化的内核架构，它通过一个个模块化的target driver插件实现对IO请求的过滤或者重新定向等工作，当前已经实现的target driver插件包括软raid，软加密，逻辑卷条带，多路径，镜像，快照等。 docker使用Thin provisioning的snapshot的技术实现了类似auFS分层镜像 12&gt; docker info | grep "Storage Driver:" #来查看&gt; Docker ContainerDocker容器具有生命周期，”STOPD”,’CREATED’,’RUNNING’,’PAUSED’四个稳定状态， 容器一旦删除数据就会丢失，所以项目或者配置文件不要直接存放在容器中，通过卷（volume）的方式挂载至容器里. Docker事件状态图: Docker Registry当容器启动时,docker daemon会试图先从本地获取相关镜像，当本地不存在的时候，其将从registry中下载该镜像并保存在本地 流程图: docker client &lt; - - - http/https - - - &gt;docker daemon &lt; - - - http/https - - - &gt;docker registry 默认是使用https连接到registry，但是可以修改成http Registry 分类registry用于保存docker镜像，包括镜像的层次结构和元数据: 用户可自建registry，也可以使用官方的docker hub 分类: sponsor registry 第三方registry，供客户和docker社区使用 mirror registry 第三方registry，只让客户用 verdor registry 由发布docker镜像的供应商提供registry private registry 通过舍友防火墙和额外的安全层的私有实体提供的registry repository及indexrepository 由某种特定的docker镜像的所有迭代版本组成的镜像仓库 一个registry中可以存在多个repository repository 可以为”顶层仓库”和“用户仓库” 用户仓库名称格式”用户名/仓库名” 每个仓库可以包含多个Tag，每个标签对应一个镜像 index 维护用户账号,镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 镜像相关操作主要介绍镜像如何生成，和如何推送镜像至仓库 镜像生成方式:​ 有三种方式：基于容器方式，Dockerfile方式，Docker Hub Automated Builds 基于容器制作镜像:1234567891011121314151617181920docker run --name web1 -it busybox &gt;mkdir -p /data/www/ &gt;echo "&lt;h1&gt;welcome busybox http server&lt;/h1&gt;" &gt; /data/www/index.html #注意:基于容器制作镜像，容器必须处于运行状态，这里切换终端 docker commit -p web1 #commit制作镜像前需要—p暂停docker image ls #可以看到镜像制作完成（缺少tag） docker tag IMAGEID zhuxyid/busyhttp:v1 #给刚才制作的镜像打标签(可以打多个标签) docker tag zhuxyid/busyhttp:v1 zhuxyid/busyhttp:test_env #在打一个标签 docker image rm zhuxyid/busyhttp:v1 #这里只是删除一个标签，并没有删除镜像 #查看镜像启动时候运行的命令 docker inspect web1 | grep -A 5 "Cmd" #如何在制作镜像运行时执行启动命令 docker commit -a "作者:zhuxy" -c 'CMD ["/bin/httpd","-f","-h","/data/www"]' -p web1 zhuxyid/busyhttp:test_env#运行制作后的镜像 docker run --name -d webserver zhuxyid/busyhttp:test_env 基于Dockerfile制作镜像: 详见:http://blog.zhuxyid.com/2018/11/26/Dockerfile/ 推送镜像推送到官方首先需要有hub.docker.com账号 ，hub.docker.com需要先建立好repositories 示例：这里的是zhuxyid/busyhttp命名,要跟本地的镜像保持一致 12345docker login #输入账号密码才可以登录 docker push zhuxyid/busyhttp:test_env #推送制作的镜像docker logout 推送到阿里云需要修改docker配置文件中的推送地址 12345678910111213141516171819#修改docker配置文件添加registry-mirrors,https://brjvf90f.mirror.aliyuncs.com为我自己的阿里云镜像仓库vi /etc/docker/daemon.json &#123; "registry-mirrors":["https://registry.docker-cn.com","https://brjvf90f.mirror.aliyuncs.com"]&#125;&#125;#重载配置文件并重启systemctl daemon-reloadsystemctl restart docker.service #阿里云创建命名空间，在创建镜像仓库 docker login --username=zhuxyid registry.cn-hangzhou.aliyuncs.com #先重命名镜像标签 docker tag imagename registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:test_env#在推送到阿里云docker push registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:version docker logout 镜像导入导出1234567#在本地导出镜像包，推送到目标机docker save -o busyhttp.gz zhuxyid/busyhttp:latest .. #可以打包多个文件 scp busyhttp.gz root@REMOTEIP:/opt#在目标机上导入推送的镜像docker load -i busyhttp.gz docker image ls Docker网络Docker安装后自动创建docker0网卡(虚拟) 网络虚拟化技术实现: OVS：Open VSwitch 开源虚拟交换 SDN：Software Defined Network 软件定义网络（需要硬件和软件支持） Docker网络接口Docker有三种网络接口： bridge，host，none，Containers 123456789docker image lsNETWORK ID NAME DRIVER SCOPE1f03c706f810 bridge bridge local75c5f8de6db4 host host local871ede94efa8 none null localbridge 桥接物理主机网卡(默认).这里是nat桥接，并不是物理桥接，如果是物理桥接,如果一个交换机下每个宿主机都有十几个容器，很容易导致广播风暴host 使用物理主机的名称空间none 不使用网络(特殊场景,有些程序不需要使用网络通信,比如自动任务不需要网络通信) docker安装后，会生成docker0，此网卡是个NAT桥，当启动容器的时候，宿主机也会生成veth*虚拟网卡，该网卡和容器内的网卡绑定，而veth*就是跟docker0相连，可以使用brctl show来查看 12345678910yum install bridge-utilsbrctl show #可以看出veth网络都是跟docker0关联bridge name bridge id STP enabled interfacesdocker0 8000.024259bff40e no veth05116c6 vethf8f26a6 iptables -t nat -vnL #查看POSTROUTING链,可以看出容器内访问其他网络都是通过MASQUERADE地址伪装方式访问Chain POSTROUTING (policy ACCEPT 54 packets, 3570 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 Docker通讯Docker中如果外部想访问内部的服务有如下三种方式: Bridge方式： 通过桥接，然后设置dnat才能被其他主机访问 Containers方式: 容器可以将6个名称空间分层: 如：docker-a和docker-b docker-a独立6个名称空间:USER,MOUNT,PID,UTS,NET,IPC docker-b独立3个名称空间:USER,MOUNT,PID,另外UTS,NET,IPC共享docker-a的 Host方式： 相当于Open container方式，只不过直接使用宿主机的UTS.NET.IPC Docker 网络相关命令指定网络类型以及端口映射123456789101112#docker run --name test -it --rm busybox:latest #运行busybox命名为test，执行完后直接删除 --network [none|bridge] #指定网络类型(默认是bridge) --hostname|-h HOSTNAME #指定主机名 --dns 114.114.114.114 #指定dns --add-host HOST:IP #设置容器hosts #映射 -p &lt;containerPort&gt; #将指定的容器端口 映射至 主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; #将容器端口containerPort 映射至 主机指定的主机端口&lt;host Port&gt; -p &lt;ip&gt;::&lt;containerPort&gt; #将指定的容器端口&lt;containerPort&gt; 映射至 主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;HostPort&gt;:&lt;containerPort&gt;#将指定容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; -P #-P暴露所有端口 Bridge1234567docker run --name test -it --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --dns 114.114.114.114 --rm busybox:latestdocker run --name webserver -p 80 -d busybox/httpd:latest #本地随机端口映射到容器的80端口docker run --name webserver -p 80:80 -d busybox/httpd:latest #本地80端口映射到容器的80端口docker port webserver #查看webserver容器端口 Containers联盟式容器是指使用某个已存在容器的网络接口的容器，接口被联盟内的各容器共享使用，因此，联盟式容器彼此间完全无隔离 #创建一个监听于80端口的http服务容器 docker run -d --it --rm -p 80:80 busybox/httpd:laster #创建一个联盟式容器 docker run --name web1 -it --rm busybox/httpd docker run --name web2 --network container:web1 -it --rm busybox/httpd #在web2中创建的文件web1看不到，因为隔离Mount名称空间，但是web1和web2的ip是一样的，因为web2共享了web1的Net名称空间 #联盟式容器彼此间 虽然 共享同一个网络名称空间，但其他名称空间如User,Mount，Pid等还是隔离的 #联盟式容器彼此间存在端口冲突的可能性，因此，通常只会在多个容器上的程序需要程序lookback接口互相通信，或对某已存在的容器的网络属性进行监控时才使用此模式的网络模型 Host 创建一个宿主机host的容器 123docker run --name webserver --network host -it --rm busybox/httpd#使用宿主机的IP，可能会郁闷，这跟直接在主机上部署个httpd服务在启动有什么不一样么？#容器，容器可以更加方便移值，直接run container就可以运行了。 Docker存储关于卷Docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层 并在镜像栈顶部 添加一个 读写层，如果运行中容器修改了现有的一个已挂载的文件，那该文件将会从 读写层下面的只读层 复制到读写层，该文件的只读版本依然存在，只是已经被读写层中该文件的副本所修改，即“写时复制(COW)”机制 注意:在IO要求高应用中，如果使用容器的话，那么效率非常低 Container: /data/web &lt; - - - - 建立绑定关系Mount - - - - &gt; Host:/container/web1/data/web 在容器写入时候，可以绕过容器内部层级关系 命名空间Mount是相互独立的,可以共享,关联到存储卷Volume，只要容器挂载存储卷.当容器被停止或者删除后,文件内容不被删除。 为什么用存储卷关闭并重启容器，其数据不受影响，但是删除容器，则数据全部丢失 存在的问题: 存储于联合文件系统中，不易于宿主机访问 容器间数据共享不便利 删除容器其数据丢失 卷的描述卷在容器初始化时候 会自动创建，由base image提供的卷中数据会于此间 完成复制 卷的初衷是独立于容器的生命周期实现数据持久化，因此删除容器时不会删除卷，也不会对哪怕未被应用的卷做垃圾回收 卷为docker提供了独立于容器的数据管理机制 可以把”镜像” 比作成静态文件，例如“程序” ，把卷类比为动态内容，例如“数据”；于是镜像可以重用，而卷可以共享 卷实现了”程序(镜像)”和“数据(卷)”分离，以及 “程序(镜像)”和“制作镜像主机”分离，用户制作镜像时无需考虑镜像运行容器所在的主机环境 卷的类型docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同 绑定挂载卷 bind mount volume: 在宿主机人工指定特定路径，在容器也人工指定特定路径，将两者绑定 容器管理卷 docker-managed volume: 宿主机不需要指定路径(docker daemon)，容器中需要指定路径，docker自动将两者绑定 如何使用卷12345678910111213141516171819docker run -v 选项docker-managed volumedocker run -it --name web1 -v /data busyboxdocker inspect -f &#123;&#123;.Mounts&#125;&#125; web1 #查看容器卷绑定关系docker run -it -v HOSTDIR:VOLUMEDIR --name web2 busyboxdocker run -it -v /data:/test --name web2 busybox #本机的data跟容器的test绑定，如果data不存在自动创建docker inspect -f &#123;&#123;.Mounts&#125;&#125; web1docker inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; web1 #获取web1下的ip地址#多个容器的卷使用同一个主机目录docker run -it --name nginx1 -v /docker/volumes/html:/data busyboxdocker run -it --name tomcat1 -v /docker/volumes/class:/data busybox#复制使用其他容器的卷，为docker run命令使用--volumes-formdocker run -it --name tomcat2 -v /docker/volumes/class:/data busyboxdocker run -it --name tomcat3 --network container:tomcat2 --volumes-from tomcat2 busybox #共享网络和卷 小结: 这些主要是针对CentOS7.4，对于其他平台或者版本可能实现方式略有不同。 如：在macOS下面对于 网络 和 卷 都有不同的地方。 网络在macOS中没有docker0桥，无法ping通容器，只能使用-P 或者-p映射端口的形式访问容器，或者通过host.docker.internal特殊DNS，解析为主机使用的内部IP地址。 卷的话如果要绑定User以外的目录，则需要修改权限让容器内部可以访问该目录，不然直接挂载会提示权限不足情况 暂时遇到这么多，感谢志哥让我遇到这么多坑。 主要是讲解一下Docker基础方面，后期的Dockerfile和Docker Registry在慢慢总结，如果本文有错误，还请大牛指出，谢谢:)]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
