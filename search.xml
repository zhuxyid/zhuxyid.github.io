<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2018%2F12%2F02%2FZabbix%2F</url>
    <content type="text"><![CDATA[Zabbixzabbix是一种开源监控软件，能实现各种强大监控功能（数据采集，展示，报警）等功能。 监控的过程 数据采集—&gt;数据存储—&gt;数据显示 时间序列数据（趋式，陡式），采集点连成线会生成数据趋式图 报警:采集到的数据超出阈值（如系统应用指标，文件变化，应用状态） Zabbix监控实现zabbix可使用Zabbix-Agent，ICMP，SNMP，HTTP，JMX，IPMI来监控客户端 IPMI(interlligent platform management interface)智慧平台管理接口，原本是一种inter架构企业系统的周边设备采用的一种工业标准 IPMI也是一个开放免费标准，使用者无需支付额外费用就可以使用 通常一些服务器如DELL,IBM支持这种接口 Zabbix可监控对象设备/软件： 设备：服务器，路由交换设备，IO设备 网络设备：snmp，ssh，ipmi 软件：操作系统，网络，应用 支持操作系统有：linux，windows，freebsd，aix，solaris，hp-unix 偶发现故障: 主机down机,服务不可用,主机不可达 严重事件: 数据节点宕机,磁盘满等 主机性能指标: 趋势数据(时间序列): SNMP协议架构： C/S架构：被监控端(Agent)，监控端(NMS), udp协议：Agent：161端口，NMS：162端口 工作模式: NMS向Agent采集数据 Agent向NMS报告数据 NMS请求Agent修改配置 组件: MIB（管理信息库）management information base OID(object id) SMI（MIB表示符） NMP协议 SNMP说明​ NMS可发起对Agent操作有：GET，GETNEXT，SET，TRAP ​ SNMP中的MIB定义被管理对象的一系列信息，每个Agent都有本地MIB库 ​ Agent操作：Response ​ SNMP仅仅实现数据采集功能 SNMP协议版本snmp版本有v1，v2，v3 V1：无验证 V2C：社区，NMS-&gt;Agent 双方共享一个秘钥，认证过程明文 V3：实现认证加密和解密功能，但是用的少 Linux实现snmp是net-snmp程序包 Windows实现snmp是在控制面板中找到程序SNMP 开源监控工具对比Cactiphp实现利用SNMP收集数据即使绘图展示，报警功能不够理想 cacti仅关注数据收集，数据展示，但是对报警功能较弱 cacti利用RRD库(round robin database)环状数据库，只能保存固定时长 Nagios仅关注是否超出阈值,监控功能强大(短信,网关等),可以报警升级,也可以维护时间暂停报警,定义各组件依赖关系,不适合大规模监控 nagios只是关注超出阈值状态转换，完成报警 如果需要增加图标显示需要安装pnp4nagios插件，如果需要存数据库需要NDOUtils，如果需要分布式需要NSCA icinga是Nagios变种 Zabbix能够实现各种强大监控功能（数据采集，展示，报警等） 支持MySQL，PgSQL，Oracle，DB2，SQLite 其他监控软件 OpenNMS ZenOS GangLia 强大的集合绘图，将多个主机组成一个趋势图 Open-Falcon 小米开源监控系统 Zabbix监控功能 zabbix agent，snmp，ping，ssh，ipmi，web监控,数据库监控,内部监控,内部支持复杂计算,自定义命令监控 zabbix agent，snmp，ipmi可以监控CPU、内存、网络、磁盘、服务、日志、文件监控 web监控可以监控到 响应时间、下载速度、响应代码、获取特定要求内容、支持http/https 报警方式:email、sms、jabber、chat message、自定义命令 Zabbix组件 zabbix-server：（C） zabbix-agent：（C） zabbix-web：GUI接口设定展示zabbix（php） zabbix-proxy:分布式监控环境中专用组件(大规模才能用到) Zabbix安装配置需求 版本 平台 cpu/内存 数据库 监控主机 Small ubuntu linux PII 350MHz 256M SQLite 20 Medium ubuntu linux64 bit AMD Athlon 3200+ 2G MySQL InnoDB 500 Large ubuntu linux64 bit Inter Dual Core6400 4G RAID10 MySQL InnoDB or PostgreSQL &gt;1000 Very large RedHat Enterprise Inter Xeon 2*CPU 8G Fatst RAID10 MySQL or PostgreSQL &gt;10000 zabbix数据 配置数据：很小 历史数据：50bytes/1m 历史趋势数据：128bytes/1m 事件数据：130bytes/1m 通常五分钟采集一次，一个监控项目就是320bytes，一小时3.8KB，一年就是34M，一台机器34M zabbix数据计算公式假设，如果一个主机60个监控项，1k个主机就是6万个监控项目。zabbix database需要用到的空间，60000/60 = 1000条，默认90天，趋势图默认一年 历史数据 历史数据 = 天数 x 每秒处理数据量 x 24 x 3600 x 50Bytes 每个历史数据50bytes 90x1000x24x3600x50 三个月产生360G数据 趋势数据 趋势数据 = 天数 x 监控项数 x 24 x 128bytes 每个趋势数据大概128bytes，按小时保存，假设保存一年 365x6000x24x128 一年大概62G数据 事件数据 事件数据 = 天数 x 86400 X 130bytes 每个事件数据大概130bytes，假设保存一年 365 x 86400 x 130bytes 一年大约3G数据 每分钟取一次数据，每秒请求数据大概千次，数据库写压力巨大（建议，监控5分钟取一次） Zabbix安装yum安装1234#需要实现安装mysql or PostreSQLyum install mysql-serverrpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/6/x86_64/zabbix-release-3.2-1.el6.noarch.rpmyum install zabbix-agent zabbix-get zabbix-java-gateway zabbix-proxy-mysql zabbix-sender zabbix-server-mysql zabbix-web zabbix-web-mysql 源码安装下载zabbix源码包 123#需事先安装好LAMP平台，编译zabbix同时安装server和agent，并支持将数据放入mysql数据库中./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-ssh2make &amp;&amp; make install 安装Server端， 1./configure --enable-server --with-mysql --with-net-snmp --with-libcurl 安装Agent端 1./configure --enable-agent --with-ssh2 导入数据库 1234567#导入数据库顺序(schema.sql，images.sql，data.sql)CREATE DATABASE zabbix CHARACTER SET UTF8;GRANT ALL PRIVILEGES ON zabbix.* TO &apos;zabbix&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;zabbixpass&apos;USE zabbix;source schema.sqlsource images.sqlsource data.sql Zabbix配置文件Zabbix-Server端123456789101112131415161718192021222324#/etc/zabbix/zabbix_server.confLogFile=/tmp/zabbix_server.log #日志文件LogFileSize=0 #不做日志滚动DBHost=127.0.0.1DBName=zabbixDBUser=zabbixDBPassword=zabbixpassDBPort=3306StartPollers=5 #启动poller进程多少个,各agent拉取对应指标StartIPMIPollers=0 #启动多少ipmi的poller进程,默认空闲StartPollersUnreachable=1 #不可达的pollerStartTrappers=5 #如果经常拉取对zabbix性能又影响,agent可以自动发送数据到server端,这个Trapper就是捕获该数据StartPingers=1 #icmp探测主机是否在线StartDiscoverers=1 #启动多个自动发现进程(消耗带宽)StartHTTPPoller=1 #启动web的拉取数据进程StartTimers=1 #启动计时器JavaGateway=127.0.0.1 #启动java网关连接jmxJavaGatewayPort=10052 #使用10052端口StartJavaPollers=5 #启动多少java的poller进程StartVMwareCollectors=0 #监控vm的虚拟主机VMwareFrequency=60 #监控vm的频率AlertScriptsPath=/usr/local/zabbix/alertscripts #脚本报警路径ExternalScripts=/usr/local/zabbix/externalscripts #外部脚本路径FpingLocation=/usr/sbin/fping #fping程序路径需要事先安装,fping(并行ping) Zabbix-Agent端123456#/etc/zabbix/zabbix_agent.confServer=192.168.1.2 #服务端ip可用逗号分隔ListenPort=10050ListenIP=192.168.1.100ServerActive=192.168.1.2 #自动推送数据到监控端(默认是被动监控)Hostname=node1 #主机名,唯一 Zabbix Server Process123456789101112watchdoghowsekeeperalerterproller (拉取)httppoller (web拉取)discoverer (自动发现)pinger (探测主机)nodewatcher (监控各节点) timer (计时器) escalator (报警升级)db_config_syncer(数据库配置同步)db_data_syncer (数据库数据同步) Zabbix配置详解Zabbix术语Host 主机要监控的网络设备,由IP或DNS名称指定 Host Group 主机组主机的逻辑容器,可以包含主机和模板,但同一个组内的主机和模板不能互相链接,主机组通常在给用户和用户组指派监控权限时候使用 Item 监控项一个特定监控指标的相关数据，这些数据来自于被监控对象，对于item是zabbix进行数据收集的核心，没有item将没有数据；相对某监控对象来说，每个item都是由”key”标识 监控项 是zabbix服务器用于监控一个特定对象上的一个特定指标,并负载针对其收集相关监控数据 如CPU每分钟平均负载可以是一个item，每五分钟平均负载是一个item 在比如特定网口接受报文速率也是一个item 每一个item都拥有相应的的类型”type” 例如”zabbix_agent”，“snmp”，“external check”，“IPMI Agent”，“SSH Agent”，“JMX Agent” Zabbix服务器会自动使用相应类型的协议或机制同时被监控端通讯 监控项目Key zabbix服务器在与被监控端通讯时就使用相应的协议或机制去询问被监控端这个key值,被监控端则调用与此key对应的监控脚本获取数据并返回给服务端 key的命名只能使用”0-9a-zA-Z_-.”等字符,且可以接受参数,其命令习惯如system.cpu.load[,],其中括号中的内容为参数,且分别可按次序使用$1,$2,进行引用,此实例中仅有两个参数 若要使用不定数目的参数,则使用”*”表示 zabbix有需要预先定义的key，获取详细地址 https://www.zabbix.com/documentation/2.0/manual/items/itemtypes/zabbx_agent 对于每一个Item,zabbix服务器还定义了这么存储这个item数据以及数据采集频率及历史数据的保存时长等, 多个item还可归类为一个由”Application”定义逻辑组 数据库查看zabbix自定义的Key 12USE zabbix;SELECT keys_ FROM items; 如何获取Key 1$ZABBIX/bin/zabbix_get -s IP -p PORT -k "system.uname" 创建Item过程 1configuration- - &gt; hosts - - &gt;(选择对应主机的items) - - &gt;create item Item默认Items由多类型 zabbix-agent：工作模式passive,active 网卡流量相关: net.if.in[if,] 进入 net.if.out[if,] 流出 net.if.total[if,] 总流量 if：接口 如eth0 mode: bytes,packets,erros,dropped 实例：create items key:net.if.in[eth0,bytes] 监控eth0网卡 store value:delta(speed per second)，计算上一次和这一次 端口相关 net.tcp.listen[port] #监听的端口,布尔值float net.tcp.port[,port] net.tcp.service[service,,] net.upd.listen[port] 进程相关 kernel.maxfiles 最大文件数 kernel.maxproc 最大进程数 ​ cpu相关 system.cpu.intr 中断次数 system.cpu.load[,]负载 system.cpu.num[] CPU颗数 system.cpu.switches CPU上下文切换次数 system.cpu.util[,,] CPU利用率 磁盘io或文件系统相关 vfs.dev.read[,,] 磁盘读 vfs.dev.write[,,] 磁盘写 vfs.fs.inode[fs,] 磁盘inode值 用户可定义item: 关键:选取一个唯一的key 命令:收集数据的命令或脚本 Application 应用一组item的集合，建立一个Application，将item加入该Application，下次主机直接使用该Application Trigger 触发器监控项 仅负责收集收据，而通常收集数据的目的还包括在某指标对应的数据超出合理范围时给相关人员发送告警信息,该工作就是触发器来定义用于为监控项所收集的数据定义阈值，每一个触发器仅能关联至一个监控项,但可以为一个监控项同时使用多个触发器（一个trigger只能属于一个item，但一个item可以有多个trigger） 事实上为一个监控项定义多个具有不同阈值的触发器可以实现不同级别的报警功能 一个触发器由一个表达式构成，它定义了监控项所采取的数据的一个阈值 一旦某次采集的数据超出了此触发器定义的阈值,触发器状态会转换成”problem”;而采取的数据再次回归至合理规范内时,其状态将重新返回到”ok” 触发器表达式高度灵活,可以创建出非常复杂的测试条件 12345678910111213格式:&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt; server #主机名称 key #主机上关系的相应监控项的key function #评估采集到的数据是否在合理范围内时所使用的函数,其评估过程可以根据采集的数据,当前时间以及其他因素进行 #目前触发器所支持的函数avg,count,change,date,dayofweek,delta(增量),diff,iregexp,last,max,min,nodata,now,sum等 operator #表达式所支持的运算符及其功能如下表示 #/ * - + &lt; &gt; # = &amp; |例子:&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125;&gt;3#表示主机www.zhuxyid.com上所有cpu过去1分钟内的平均负载的最后一次取值大于3时,将触发状态变换#对last函数来说,last(0)相当于last(#1)&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125; or &#123;www.zhuxyid.com:system.cpu.load[all,avg5].last)(0)&#125; or.... 触发器依赖关系 在一个网络中，主机的可用性之间可能存在依赖关系 例如当某网关主机不可达时,其背后的所有主机都将无法正常访问 如果所有主机都配置触发器并设定了相关的通知功能，相关人员将会接受到许多告警信息，这既不利于快速定位,也会浪费资源 正确定义的触发器依赖关系可以避免类似情况发生,他将使用通知机制仅发送最根本的问题相关告警 目前zabbix不能直接定义主机间的依赖关系,其依赖关系仅能通过触发器来定义 触发器等级 SEVERITY DEFINITION COLOUR Not Classified 未知级别 Grey Infromation 一般信息 Light Green Warning 警告信息 Yellow Average 一般故障 Orange Hight 高级别故障 Red Disaster 致命故障 Bright Red 触发器状态 zabbix server每次接受到items的新数据时，对items当前采样值进行判断，即与trigger表达式进行比较 OK PROPLEM 触发器创建过程 Configuration - - &gt; Host - - &gt; Triggers - - &gt; Create trigger Trigger名称使用宏 ​ (HOST.HOST)，{HOST.NAME}，{HOST.IP}，{HOST.CONN}，{HOST.DNS} Even，Action，Escalation，Media，Notification，Remote CommandEven 事件 即发生的一个值得关注的事情,例如触发器的状态转变,新的agent或重新上线的agent自动注册等 Action 动作 指对特定时间事先定义的处理方法，通过包含操作(如发送通知)和条件(何时执行操作) Escalation 报警升级 发送报警或执行远程命令的自定义方案,如每隔5分钟发送一次报警,发5次 Media 媒介 发送通知的手段或者通道,如email,jabber或者sms Notification 通知 通过选的的媒体向用户发送有关某事件的信息 Remote command 远程命令 预定义的命令,可在被监控主机处于某特定条件下自动执行 触发条件一般为事件: Trigger events: ok—&gt;proplem Discovery event: zabbix的network discovery工作时发现主机 Auto registration event:主动模式的agent注册时发生的时间 Internal event:item变成不在被支持,或者trigger变成未知状态 Operations的功能: 动作: send message: 发送通知手段如下 ​ EMAIL,SMS,Jabber,Scripts,EZ texting Remote command:远程命令 配置send message 定义media 定义用户 配置要发送消息;action就已经定义好 配置Remote Command 前提:执行命令需要agent开启执行远程命令zabbix_agent.conf EnableRemoteCommands=1 #是否开启远程执行命令 LogRemoteCommands=1 #是否将命令记录到日志中 给zabbix定义sudo规则 zabbix ALL=(ALL) ALL 不支持active模式的agent 不支持代理模式 命令长度不得超过255个字符 远程命令可以使用宏定义 zabbix server仅执行命令,不关心命令是否执行成功 注意: 如果用到以其他用户身份执行命令的话,那么命令本身要以sudo方式运行 sudo /etc/rc.d/init.d/httpd restart 注释agent上的sudoers文件,需要注释(sudo模式下需要一个真实的tty) Default requiretty 报警升级可以使用setp定义几次处理可以邮件升级。 Template 模板用于快速定义被监控主机的预设定条目集合,通常包含item,trigger,graph,screen,application以及low-level discovery rule(自动发现);模板可以直接链接到单个主机 模板是一系列配置的集合,它可以方便地快速部署在某监控对象上,并支持重复应用，此配置可通过”链接”方式应用于指定的主机 items trggers graphs applications screens(since zabbix 2.0) low-level discovery rules(since zabbix 2.0) 将模板应用至某主机上时，其定义的所有条目都会自动添加 模板的另一个好处在于,必要时,修改了模板,应用的主机都会相应作出修改 创建模板 configuration –&gt; templates 在模板上按需添加item,trigger,screen,graph,application以及发现规则 模板可以嵌套 macros 宏 宏是一种抽象(abstraction),它根据一系列预定义的规则替换一定文本模式,而解释器或者编译器在遇到宏时会自动进行这一模式的替换 类似,zabbix基于宏保存预设文本模式,并且调用时将其替换为其中文本 zabbix有许多内置宏,如{HOST.NAME} {HOST.IP} {TRIGGER.DESCRIPTION} {TRIGGER.NAME} {TRIGGER.EVENTS.ACK}等 详细信息参考文档:https://www.zabbix.com/documentation/3.0/manual/appendix/macros 为了更强的灵活性,zabbix还支持在全局,模板或者主机级别使用用户自定义宏(user macro) 用户自定义宏使用”${MACRO}”这种特殊的语法格式 宏可以应用在Item keys和descriptions,trigger名称和表达式,主机接口ip/dns以端口,discovery机制的snmp协议的相关信息中等 宏名称只能使用大写字母、数字、下划线 参考https://www.zabbix.com/documentation/3.0/manual/appendix/macros/supported_by_location 宏替换次序 首先是主机级别的宏 其次是当前主机上的上一级模板中(直接连接至主机的模板)的宏,多个一级模板按其ID号排序 再接着就是二级模板中的宏,而后以此类推 最后检查的是全局宏 zabbix如果无法查找某主机定义的宏,则不会对其进行替换操作,要使用用户自定义宏,有一下两种途径 全局宏:”administratorion” –&gt; general —&gt; macros macro:{$NGINX_PORT} value:80 主机或模板级别的宏:编辑相应主机或模板的属性即可,(只针对当前主机.主机级别最高) 总结: 宏分为两类: 内建:{MACRO_NAME} 自建:${MACRO_NAME} 三个级别使用: global全局 template模板 host主机 优先级:host —&gt; template—&gt;global 在某级别找到后直接使用不会往后查找 Web Scennario web场景用于检测web站定可用性一个或多个http请求 zabbix还可对web站点可用性的可用性检测 创建web监控需要先定义一个web方案(scenarios) web方案包含一个或多个http请求或”步骤)step” ，步骤(step)的执行过程按照预先定义的顺序进行执行 通过web监控可实现获取如下信息 整个web方案中所有的步骤平均下载速度 失败的步骤号 失败的报错信息 在web方案的具体步骤中,可按需进行如下信息 该步骤的下载速度 回应时间 回应状态吗 zabbix可以检测获取到html页面中是否包含预设的字符串,可以实现登陆和页面点击 创建web方案 创建web方案前提需要创建一个使用的应用(application) 可以在”hosts”或者”templates”上创建应用 如果在”templates”上创建应用,则需要将此”templates”连接至要监控其web的主机上方能使此”application” 步骤： configuration–&gt;web(zabbix2.4) configuration–&gt;templates(host)–&gt;web(zabbix3.0) 例子： 1234567891011121314scenario name:zhuxyid.comnew application:zhuxyid.com update interval:30s agent:chrome3.8(windows) 其他默认 step name:zhuxyid.indexurl:http://www.zhuxyid.comfollow redirects:enable timeout:10 required status codes:200 monitoring--&gt;web--&gt;zhuxyid.com即可出图 Zabbix自动发现]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F11%2F30%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis介绍Redis是一个基于BSD开源的高性能键值缓存服务，支持数据结构string，list，hash，set，sorted，bitmaps，hyperloglog。 官方站点：http://www.redis.io redis特点: kv存储，存储在内存中， redis可以持久化周期性的存储在磁盘上(冗余作用) ​ 快照，内存数据异步传输到磁盘（RDB）。 ​ AOF，每次写操作附加在文件中。 ​ Master-Slave方式,主写，从读。 redis支持主从模式，借助哨兵（Sentinel实现一定意义上的高可用） redis3.0开始支持群集（分布式） Redis和Memcache区别 memcache是一个分布式内存对象缓存系统，且不可持久化，redis支持 持久存储 memcache是基于LRU cache(最近最少使用) ，redis有不同特性以及跟多数据类型 memcache是多线程，redis是单线程，两者的性能几乎相同 Redis优点： ​ 丰富(资料形式)操作(Hashs,Lists,Sorted,Sets,HyperLoglog) ​ 内建replication及cluster ​ 就地更新(in-place update)操作 ​ 支持持久化(磁盘)，避免雪崩 Memcache优点 ​ 多线程(善用多核cpu，更少堵塞操作) ​ 更少内存开销 ​ 更少内存分配压力 ​ 内存碎片更少 其他资料常见的存储系统分为三类: RDBMS：如Oracle，SQLServer，MySQL。 NoSQL：如Hbash，MongoDB，Redis NewSQL：分布式关系型事物系统 NoSQL四种流派： 键值NoSQL：如Redis，Memcache 列族NoSQL：如Hbash，MongoDB，Redis 文档NoSQL：MongoDB 图形NoSQL：Neo4J Redis案例: ​ 一百万的key，内存使用约100M ​ 单线程，虽然单线程，却能承受500k的并发请求 Redis安装12345678910111213141516171819#安装redis需要安装jemalloc内存管理工具(google研发)yum install tcl#下载源码地址：http://download.redis.io/releases/#安装步骤tar zxvf redis-VERSION.tar.gzcd redis-VERSIONmake#安装完成后，生成如下文件redis.conf redis配置文件sentinel.conf 主从架构配置文件src/redis-server redis服务端src/redis-cli redis客户端src/redis-check-aof redis检查工具（AOF）src/redis-check-dump redis检查工具（快照）src/redis-benchmark redis性能工具src/redis-sentinel redis主从架构提供高性能工具 Redis基本配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107cat redis.conf | grep -v "^#" | grep -v "^$"#全局设置####INCLUDE####daemonize nopidfile /var/run/redis.pidport 6379tcp-backlog 511 #tcp-backlog长度 （backlog是个队列缓冲，tcp通常会有backlog）bind 126.0.0.1 192.168.2.21unixsocket /tmp/redis.sock #如果不使用tcp方式，可以直接使用unixsocket方式,效率比tcp高timeout 0 #客户端连接超时时间(0表示不会超时)，根据需求设定tcp-keepalive 0loglevel noticelogfile "/var/log/redis/redis.log"syslog-enabled no #是否启用系统日志syslog-ident redis #日志识别syslog-facility local0 #日志设施databases 16 #redis是否支持多内部数据集合，默认放在0，在redis集群中只支持16#快照，持久化配置信息####SNAPSHOTTING#####格式 save seconds changessave 900 1 #900s（15分钟），如果有1个键值发生改变，就存储save 300 10 #300s（5分钟），如果有10个键值发生改变，就存储save 60 10000 #60s（1分钟），如果有1000个键值发生改变，就存储#save "" #取消注释表示禁用持久化功能stop-writes-on-bgsave-error yes #在RDB方式下，如果使用bgsave保存是否检查如果检查错误是否停止rdbcompression yes #RDB是否压缩，压缩会消耗cpu资源rdbchecksum yes #是否对rdb进行校验码检测dbfilename dump.rdb #DBfile文件名称dir ./ #指明文件保存目录#主从配置信息####REPLICATION#####slaveof &lt;masterip&gt; &lt;master-ports&gt; #如果这个注释，说明是master模式，如果开启需要指定master的IP和端口slave-serve-stale-data yes #是否从服务器使用过期数据slave-read-only yes #是否只读，如果slaveof注释，这里是没有用的，repl-diskless-sync no #是否给予diskess同步，如果网络快，磁盘写慢建议开启repl-diskless-sync-delay 5 #延迟时间多久repl-disable-tcp-nodelay no #tcp nodelay功能slave-priority 100 #slave优先级min-slaves-to-write 3 #从节点至少3个节点，将禁止主服务器写请求min-slaves-max-lag 10 #从节点如果相差10s，主服务器拒绝执行写入操作#安全相关配置####SECURITY#####requirepass foobared #认证密码foobaredrename-command CONFIG ""#并发相关配置####LIMITS######maxclients 10000 #最大并发数量，多少客户端连接maxmemory &lt;bytes&gt; #每个客户端内存使用量maxmemory-policy noevictionmaxmemory-samples 5#AOF持久化####APPEND ONLY MODE####appendonly no #是否使用AOF功能，yes使用，这里是禁用appendfilename "appendonly.aof" #AOF文件名appendfsync &#123;always | everysec | no&#125; #AOF追加方式&#123;always没接受一条写一条，everyse每秒写一条，no 表示根据系统调用来写&#125;no-appendfsync-on-rewrite no #如果是yes表示重写的时候对新写的操作是存在内存auto-aof-rewrite-percentage 100 #aof文件增长了100%也就是两倍，触发重写操作auto-aof-rewrite-min-size 64mb #如果重写大小达到64M就重写aof-load-truncated yes#redis加载aof文件，发现末尾命令不完整自动截掉，成功加载前面正确数据，如果设置no，遇到不完整redis启动失败，redis-check-aof修复#lua脚本设置####LUA SCRIPTING####lua-time-limit 5000#redis群集设置####REDIS CLUSTER####cluster-enabled yescluster-config-file nodes-6379.confcluster-node-timeout 15000cluster-slave-validity-factor 10cluster-require-full-coverage yes#慢查询日志设置####SLOW LOG####slowlog-log-slower-than 10000slowlog-max-len 128#监控设置####LATENCY MONITOR####latency-monitor-threshold 0#事件通知设置 跟发布订阅有关####EVENT NOTIFICATION####notify-keyspace-events ""#高级设置####ADVANCED CONFIG####hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes Redis命令123456789101112131415161718192021222324#启动redis前需要设置echo 'vm.overcommit_memory=1' &gt;&gt; /etc/sysctl.conf #内存不足的情况下，后台程序save可能失败，建议将其改成1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled#如果使用透明大页，可能导致redis延迟和内存使用问题echo 511 &gt; /proc/sys/net/core/somaxconn#tcp backlog值#启动redis-server &amp;-h HOST : 连接的主机地址或主机名-p PORT :连接的端口-s socket : 指定套接字-a password : 指定连接密码-r &lt;repeat&gt; : 指定命令运行多次overcommit_memory参数说明设置内存分配策略，可以设定0、1、20 表示内核将检查是否有足够的内存供应进程应用，如果没有足够的可用内存，内存允许申请；否则内存申请失败，并将错误返回给应用进程1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何2 表示内核允许分配超过所有物理内存和交换空间总内存注：redis在dump数据时，会fork出一个子进程，理论上child进程所占有内存和parent是一样的，如果parent占用内存为8G，这个时候同样分配8G的内存给child，如果内存无法负担，往往会造成redis服务的down机或者IO负载过高，导致效率下降，所有这里比较优化的内存策略应该为1（表示内核运行分配所有的物理内存，而不管当前内存状态) Redis基本操作1234567891011#redis-cli -h 127.0.0.1127.0.0.1:6379&gt;helpType help @&lt;group&gt; help &lt;tab&gt;127.0.0.1:6379&gt; help @connection #帮助命令 127.0.0.1:6379&gt; help @STRING #获取字符串操作帮组127.0.0.1:6379&gt; ping #测试 PONG127.0.0.1:6379&gt; echo 'hello world' #回显 "hello world" 127.0.0.1:6379&gt; QUIT #退出 server主要设置redis服务器 1234567891011121314151617181920127.0.0.1:6379&gt; CLIENT SETNAME localconn #设置名称OK127.0.0.1:6379&gt; CLIENT GETNAME #获取名称"localconn"127.0.0.1:6379&gt; CLIENT LIST #client列表"id=2 addr=127.0.0.1:38521 fd=6 name= age=272 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client"127.0.0.1:6379&gt; CLIENT KILL ip:port #剔除一个client127.0.0.1:6379&gt; INFO #获取信息127.0.0.1:6379&gt; INFO MEMORY #获取memory信息，如获取cpu，执行info cpu127.0.0.1:6379&gt; CONFIG RESETSTAT #重置所有配置信息127.0.0.1:6379&gt; CONFIG SET #设置仅在内存生效127.0.0.1:6379&gt; CONFIG REWRITE #同步到配置文件中，如果用CONFIG SET方式设置redis参数需要REWRITE同步到配置文件中 SELECT使用0的命名空间，默认是0，使用SELECT [空间名进行跳转最大16个] 同一个名称空间不能使用相同的键值 12345127.0.0.1:6379&gt;SELECT 0127.0.0.1:6379&gt;SELECT 15OK127.0.0.1:6379[15]&gt;SELECT 16(error)ERR invalid DB index SET12345678910111213127.0.0.1:6379&gt; help set格式:SET key value [EX seconds] [PX milliseconds] [NX|XX] #set key value [过期时间] [标识] [如果键值不存在才会创建|如果键值存在覆盖]127.0.0.1:6379&gt; set 01 nameOK127.0.0.1:6379&gt; set 02 name2OK127.0.0.1:6379&gt; set 01 name nx(nil)127.0.0.1:6379&gt; set 03 name nxOK127.0.0.1:6379&gt; set 04 name ex 5 设置5s过期 GET123456127.0.0.1:6379&gt; get 02&quot;name2&quot;127.0.0.1:6379&gt; get 01&quot;name&quot;127.0.0.1:6379&gt; get 04 过期后会提示nil(nil) APPEND12345127.0.0.1:6379&gt; append 01 haha (integer) 8 127.0.0.1:6379&gt; get 01 &quot;namehaha&quot; STRLEN12127.0.0.1:6379&gt; STRLEN 01 #长度(integer) 8 INCR只针对整数增加生效 12345678127.0.0.1:6379&gt; set count 0 OK 127.0.0.1:6379&gt; INCR count #增加(integer) 1 127.0.0.1:6379&gt; INCR count (integer) 2 DECR12345127.0.0.1:6379&gt; DECR count #减(integer) 1 127.0.0.1:6379&gt; DECR count (integer) 0 事物通过MULTI,EXEC,WATCH等命令实现事物功能: redis事物只是将一个或者多个命令打包一个操作服务端按顺序执行机制redis事务不支持回滚操作 123456789101112131415127.0.0.1:6379&gt; MULTT #启动一个事务OK127.0.0.1:6379&gt; SET IP 192.168.2.21QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; SET PORT 8080QUEUED127.0.0.1:6379&gt; GET PORTQUEUED127.0.0.1:6379&gt; EXEC #执行事务，一次性将事务中的所有操作执行完成后返回给客户端1) OK2) "192.168.2.21"3) OK4) "8080" 清空操作:)for _ in range(1000):print(“不要在生产使用”) 12FLUSHDB 清空当前数据库FLUSHALL 清空所有数据库0~15 WATCH 乐观锁WATCH在EXEC命令执行之前，用于监视指定数量的键，如果监视中的某任意键数据被修改，则服务器拒绝执行事务 12345678910127.0.0.1:6379&gt; WATCH IP #监控IP键OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET IP 10.0.0.1QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; EXEC #如果在MULTI之后,EXEC之前有个客户端修改了IP，这里EXEC的话，就会拒绝事务(nil) Redis认证如果使用认证功能需要编辑配置文件找到requirepass 123456789101112格式：requirepass PASS $vi /etc/redis.conf requirepass zhuxyid $redis-server /etc/redis.conf redis-cli -h 127.0.0.1 127.0.0.1:6379&gt; select 0 (error) NOAUTH Authentication required. 127.0.0.1:6379&gt; auth zhuxyid OK 127.0.0.1:6379&gt; select 0 OK Redis发布订阅频道:消息队列 123456789101112SUBSCRIBE:订阅一个或多个队列PUBLISH:向频道发布消息例子&gt;SUBSCRIBE www.zhuxyid.com #订阅www.zhuxyid.com频道&gt;PUBLISH www.zhuxyid.com hello #向www.zhuxyid.com频道发送PSUBSCRIBE:订阅多个队列&gt;PSUBSCRIBE www.zhuxy.i[to] #订阅www.zhuxy.io 和 www.zhuxy.it频道&gt;PUBLISH www.zhuxy.io hello io&gt;PUBLISH www.zhuxy.it hello it Redis持久化#####RDB和AOF RDB:snapshot，二进制格式：被事先定制的策略,如save 900 1,周期性将数据保存到磁盘:数据文件默认为dump.rdb; ​ 客户端也可以使用SAVE或者BGSAVE命令启动快照保持机制 ​ SAVE:在主线程中保存快照，此时会堵塞所有用户请求，如果数据量大，严重影响性能 ​ BGSAVE:异步，不会被堵塞，只是创建子进程，保存到临时文件，主进程依然处理客户端请求 AOF:Append Only File. 记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可通过重新执行文件中的命令，在内存中重建数据库。 ​ BGREWRITEAOF:AOF文件重写； ​ 不会读取正在使用的AOF文件，在通过将内存中的数据以命令的方式保存在临时文件中，完成后替换原来的AOF文件 RDB：配置:redis-cli可以用config get dir查看 123456789配置如下：save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir ./ AOF:AOF重写过程： redis主进程调用fork生成子进程 子进程根据redis内存中的数据创建数据库重建命令列于临时文件中 父进程继承clinet请求，并会把这些请求写操作继续追加至原来的AOF文件，额外的这些新的请求会被放置于一个缓冲队列中 子进程重写完成会通知父进程，父进程会把缓冲中的命令写到临时文件中 父进程用临时文件替换老的AOF文件 12345678配置如下：appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yes RDB和AOF注意事项：redis如果同时使用两种持久化会导致IO影响大。 需要注意的是，就算可以持久化也不要忘记备份，万一磁盘坏了持久化也没什么用，对redis持久化文件进行备份。 RDB和AOF同时使用： BGSAVE和BGREWRITEAOF不会同时执行 在redis服务器启动用于恢复数据时，优先是有AOF，因为RDB是周期性的，数据不能保证为最新的 Redis复制特点: 一个master可以有多个slave 支持链式复制：slave可以有多个slave master以非阻塞方式同步至slave master&amp;slave工作原理: 启动一个slave，会请求同步master，master启动子进程，将快照保存在文件中，将文件传送给slave，slave接受文件保存本地加载至内存，完成同步 配置过程12345678910111213141516配置master&amp;slave192.168.2.21(master)修改配置文件bind 192.168.2.21启动redis192.168.2.23(slave)修改配置文件bind 192.168.2.23slaveof 192.168.2.21 6379启动redis或者直接在redis-cli输入slaveof 192.168.2.21 6379建议master写，slave读。如果master使用requirepass开启认证功能，从服务器要使用masterauth &lt;PASSWORD&gt; 来连入服务请求使用此密码进行认证 主从复制缺点:如果redismaster离线了，怎么办？可以使用redis-sentinel(主从架构实现高可用) Redis sentinelsentinel主要作用： 用于管理多个redis服务实现HA 监控，通知，故障转移 留言协议，投票协议。 启动流程: 服务器自身初始化，运行redis-server中专用于sentinel功能代码初始化sentinel状态，根据给定配置文件，初始化监控的master服务器列表创建连向master的链接 12345依赖配置文件sentinel.confredis-sentinel /path/to/sentinel启动redis-server /path/to/sentinel --sentinel sentinel配置文件说明1234567891011121314151617port 26379dir /tmpsentinel monitor mymaster 127.0.0.1 6379 2#格式:sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;#&lt;quorum&gt;票数,sentinel至少两票启动，如果只有一个则改成1&gt; !!如果还有其他应用使用redis主从也可以做监控，改变master-name就可以sentinel down-after-milliseconds mymaster 3000#格式:sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;#判断节点离线超过多少秒认为离线的。单位毫秒,sentinel parallel-syncs mymaster 1#格式:sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;#执行故障转移时候允许多少从服务器向新的主服务器同步请求sentinel failover-timeout mymaster 180000#格式:sentinel failover-timeout &lt;mymaster&gt; &lt;failover-timeout&gt;#当主服务器出现故障时候,从服务器提升主服务器的超时时间，单位毫秒 sentinel下线机制：主观下线和客观下线 主观下线:一个sentinel实例判断出某个节点下线 客观下线:多个sentinel节点协商后判断出某节点下线 专用命令123456redis-clit -h sentinelip -p sentinelport SENTINEL masters #列出所有主服务器SENTINEL slaves &lt;master name&gt; #获取当前redis示例中的从节点信息SENTINEL get-master-addr-by-name &lt;master name&gt; #直接获取当前redis实例主节点IP地址和端口SENTINEL reset #重置SENTINEL failover &lt;master name&gt; #手动切换 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596环境如下:172.16.36.70 : redis主节点 172.16.36.71 : redis从节点 172.16.36.72 : redis从节点 172.16.36.74 : sentinel节点1 172.16.36.75 : sentinel节点2 172.16.36.76 : sentinel节点3####配置redis主节点 操作主机: 172.16.36.70 #vim /etc/redis.confbind 172.16.36.70daemonize yes #启动服务 #redis-server /etc/redis.conf####配置redis从节点 #操作主机: 172.16.36.71 #vim /etc/redis.conf bind 172.16.36.71 daemonize yes #启动服务#redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置redis从节点#操作主机: 172.16.36.72 #vim /etc/redis.confbind 172.16.36.72daemonize yes #启动服务 #redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置sentinel节点#操作主机: 172.16.36.74 #vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14)) #操作主机: 172.16.36.75 # vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14))操作主机: 172.16.36.76# vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 启动服务 redis-sentinel /etc/redis-sentinel.conf 查看服务启动状态 users:((&quot;master&quot;,2112,14)) #这里有个问题，当一个redis挂掉后，如果连接主redis？可以使用vip(虚拟ip(keepalived)来实现)$sentinel client-reconfig-script myredis /opt/notify_myredis.sh$more /opt/notify_myredis.sh#!/bin/bashMASTERIP=$6 #第六个参数是redis的ip地址LOCALIP=&apos;192.168.0.101&apos; #另外一台按需填写VIP=&apos;192.168.0.100&apos; #client连接的redisNETMASK=&apos;24&apos;INTERFACE=&apos;eth1&apos;if [ $&#123;MASTERIP&#125; = $&#123;local_IP&#125; ];then /sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #将vip绑定到服务器上 /sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else /sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #删除 exit 0fiexit 1 #如果返回1，sentinel会一致执行这个脚本]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2018%2F11%2F27%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx是什么Nginx是一个Web服务器,也是个高性能方向代理服务器，Nginx起初为了解决基于进程模型产生的C10k问题，由俄罗斯lgor sysoev研发。 Nginxy有企业版本Nginx Plus，还有二次发行版Tengine，OpenResy（淘宝研发） nginx反向代理支持两种协议 HTTP和MAIL C10K 连接超过10K ,1W个请求,1M =100万个请求 Netcraft可以查看全球服务器Web服务器占有率。 传统上基于进程或线程模型架构的web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。 在设计的最初阶段，nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 Nginx特性模块化设计，较好的扩展性，早期不支持模块的动态装载和卸载 高可靠性，基于Master/Worker模式 支持热部署（平滑升级迁移），不停机的状态下更新配置文件，跟换日志文件，更新服务器程序版本 内存消耗低，10K个keep-alive连接模式下的非活动连接只消耗2.5M内存 支持event-driven事件驱动模型，AIO驱动机制，MMAP内存映射机制 Nginx基本功能 静态资源的web服务器,自身只能简单的接收和响应http http协议的反向代理服务器 pop3,smtp imap4等邮件协议的反向代理 能缓存打开的文件(元数据缓存:文件的描述符等信息),能加快文件的打开速度 支持FastCGI(php-fpm)，UWSGI 等协议机制,实现代理后端应用程序交互 支持过滤器,例如ZIP,SSI(服务端包含) 支持SSL加密机制 模块化（非DSO机制） standard HTTP modules 标准(核心)HTTP模块:自动编译进程序不止一个Optional HTTP modules 可选http模块Mail modules 邮件模块3rd party modules第三方模块,在编译时需手动指明加载方式加载 Nginx服务相关功能虚拟主机，Keepalive，访问日志，日志缓冲（提高存取西能），URL重写，路径别名，访问控制（IP和用户），支持速率限制，并发限制 Nginx架构Master/Worker模型： 一个master进程可以生成一个或者多个worker进程，每个worker基于事件驱动，响应用户请求, 其支持sendfile,sendfile64,这两种支持的文件大小不同 事件驱动：Linux(epoll)，FreeBSD(kqueue)，Solaris(/dev/poll) 除此之外配置了缓存时还会有缓存加载器进程cache loader和缓存管理器进程cache manager等，所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。 主进程Master以root用户身份运行，而Worker、Cache Loader和Cache Manager均应以非特权用户身份运行。 Master 加载，验证配置文件 创建，绑定，关闭套接字 管理worker进程（启动，终止，维护） 平滑重启（无需终止服务重载配置） 平滑升级（启用新的二进制程序并在需要时回滚到老版本） 重新打开日志文件，实现日志滑动 其他嵌入式perl，go脚本 Worker 响应客户端请求，提供HTTP服务和代理，提供FastCGI，uWSGI，SCGI等代理 Cache Loader 检查缓存存储中的缓存对象； 使用缓存元数据建立内存数据库； Cache Manager 缓存的失效及过期检验； Nginx安装可使用yum或者源码方式安装 yum安装yum方式很简单，直接使用yum源来安装 12yum install nginx #自动安装依赖关系rpm -ql nginx #查找nginx安装生成的文件 源码安装123456789101112131415161718192021222324252627282930yum install -y pcre-devel openssl-devel zlib-develuseradd nginx -s /sbin/nologin#进入解压后的源码包路径，根据需求来定.** 注意:`--with`都是启用模块，`--without`都是禁用模块 **./configure \ --prefix=/usr \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --user=nginx \ --group=nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --with-http_ssl_module \ #使用ssl模块 --with-http_flv_module \ #使用flv流模块 --with-http_stub_status_module \ #使用监控模块 --with-http_gzip_static_module \ #使用gizp模块 --with-pcre #pcre模块启用 --with-file-aio #支持文件异步 --with-http_image_filter_module #支持图片过滤 --http-client-body-temp-path=/var/tmp/nginx/client/ \ #请求报文主体缓存目录 --http-proxy-temp-path=/var/tmp/nginx/proxy/ \ #代理临时目录 --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ #fastcgi目录，支持php框架 --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ #uwsgi目录，支持python框架 --http-scgi-temp-path=/var/tmp/nginx/scgi \ #scgi目录，类似fastcgi另外一种机制# make &amp;&amp; make install Nginx常用命令1234nginx -t #测试配置文件是否正确nginx -s reload #nginx重载文件nginx -V #nginx显示版本号,已经编译的那些模块nginx --help查看更多帮助 配置文件说明123456789/etc/nginx/nginx.conf #主配置文件 Include conf.d/*.conf/etc/nginx/mime.types #所支持的MIME类型列表/etc/nginx/fastcgi_params #fastcgi的配置文件/etc/nginx/fastcgi.conf #与fastcgi_params一般只使用一个/etc/nginx/uwsgi_params #与uwsgi框架的配置文件/etc/nginx/scgi_params #cgi的配置文件/etc/nginx/proxy.conf #代理的配置/etc/nginx/sites.conf #配置虚拟主机的 主配置文件/etc/nginx/nginx.conf 格式如下 1234567891011121314151617181920worker_processerror_loguserevents &#123; use epoll;&#125;http &#123; access_log xxx; upstream server&#123; server IP:PORT &#125; server &#123; location URI &#123; driective &lt;parameters&gt;; &#125; &#125; server &#123; ....; &#125;&#125; MAIN该段落主要是配置Nginx运行启动时候必备参数 和 性能优化 以及 调试定位问题的配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465user nginx;worker_processes 1;worker_cpu_affinity auto;worker_rlimit_nofile 10240;timer_resolution 100ms;worker_priority 20;error_log /var/log/nginx/error.logevents &#123; use epoll; worker_connections 1024;&#125;http:&#123; upstream server &#123; .....; &#125; server &#123; ...; location / &#123; ...; &#125; &#125;&#125;user USERNAME#指定nginx启动worker进程时 以什么用户启动worker_processes NUMBER|auto#启动worker个数#如果负载以CPU密集型为主(比如SSL或压缩)则worker数应与CPU数相同;如果以IO密集为主(如大量内容给客户端)，则worker数应是CPU的1.5或2倍worker_cpu_affinity auto|CPUMASK#根据物理cpu自动绑定,worker不使用进程或者线程处理请求,而是直接将worker绑定到CPU上，这样就没有进程切换这一说法#worker_processes 4;#worker_cpu_affinity 0001 0010 0100 1000;worker_rlimit_nofile NUMBER#设置worker进程打开文件数量，worker_rlimit_nofile需要大于等于woker_connections的大小timer_resolution INTERVAL#用于降低gettimeofday()系统调用的缓存时钟，默认情况下，每次从kevent(),epoll,/dev/poll,select()，poll都会执行此系统调用worker_priority [-20~19]#设置worker进程优先级，官方说明一般在-20到19之间，如果想要woker运行快优先级可调到20error_log PATHFILE#配置错误日志，改参数可用于main,http,server,已经localtion上下文中.events事件驱动I/O框架use [ kqueue | rtsig | epoll | /dev/epoll | select | poll | eventport ]#根据当前系统内核版本设置适合自己的事件模型。#kqueue freeBSD 4.1+#epoll linux2.6+#/dev/epoll solaris 7 11/99+worker_connections NUMBER#事件驱动每个worker支持的连接数,如果worker_process为2，那么服务器最大支持2048个连接#当nginx作为web服务时 最大客户端处理数max_clients = worker_processes * worker_connections#当nginx作为反向代理时 最大客户端处理数max_clients = worker_processes * worker_connections/2#这里的max_clients很多人都疑惑为什么有人认为max_clients = worker_preocesses * worker_connections/4呢？#如果max_clients指的是建立连接最大客户数,由于每个游览器默认两个并发连接,那么nginx作为反向代理是/4#如果max_clients指的是处理客户端数,那就nginx作为反向代理是/2server_tokens off;#隐藏版本号 HTTPHTTP上下文配置用于http的各模块，此类指令很多，每个模块都有专用指令，具体参考nginx官方wiki模块部分的说明。大致上这些模块所提供的配置指令还可以分为以下几个类别: 1234567客户端指令：client_body_buffer_size，client_header_buffer_size，client_header_timeout，keepalive_timeout...文件IO指令：aio，directio，open_file_cache，open_file_cache_min_uses，open_file_cache_valid，sendfile....hash类指令：用于定义Nginx为特定的变量分配多大的内存空间，如types_bash_bucket_size，server_name_hash_bucket_size，variables_hash_bucket_size套接字指令：用于定义Nginx如何处理TCP套接字相关的功能，如tcp_nodelay（用于keepalive功能启用）和tcp_nopush（用于sendfile启用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147...;http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; #send_time #; #sendfile on; #tcp_nopush on; tcp_nodeplay on keepalive_timeout 65; keepalive_requests 100; #keepalive_disable none | browser; #client_body_buffer_size SIZE(8|16K); #client_body_temp_path [LEVEL1 [LEVEL2 [LEVEL3]]]; #aio on; #directio off; #open_file_cache off; #open_file_cache errors off; #open_file_cache_valid TIME; #open_file_cache_min_uses NUMBER; upstream name &#123; server 192.168.1.10:8080 keepalive 300 &#125; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;include mine.types#指定包含文件类型,mine.type里面定义，如html,css,gif,jpeg,js,txt....default_type application/octet-stream#默认是octet-stream，如果一个文件在mime.types没定义，就使用默认的类型octet-stream，这个表示下载，#如果设置default_type text/html;则表示可以在游览器查看log_format main string#设定log日志格式以及名称，main可以随便定义，string必须是nginx可识别的变量,可以自定义变量#$remote_addr，$http_x_forwarded_for #客户端的ip地址； #$remote_user #客户端用户名称； #$time_local #访问时间与时区； #$request #请求的url与http协议； #$status #请求状态，200,302，404，500等， #$body_bytes_sent #发送给客户端文件主体内容大小； #$request_body #请求体 #$http_referer #从那个页面链接访问过来的； #$http_user_agent #客户浏览器的相关信息； access_log path format_name#设定访问日志路径，使用哪个名称日志格式。#还有设置缓存大小刷新时间间隔，以及定义缓冲提升nginx性能#open_log_file_cache max=N [inactive=time] [min_uses] [valid=time]#open_log_file cache off;#max 设置缓存中描述符最大数量，如果缓存占满，最近最少使用(LRU)的描述符被关闭#inactive 设置缓存文件描述符在多长时间内没有被访问就关闭； 默认为10秒。#min_uses 设置在inactive参数指定的时间里， 最少访问多少次才能使文件描述符保留在缓存中；默认为1。#valid 设置一段用于检查超时后文件是否仍以同样名字存在的时间； 默认为60秒。#off 禁用缓存。send_time #;#发送响应报文的超时时长，默认60ssendfile on|off#在内核完成后直接封装响应客户端(支持小文件) sendfile64(支持大文件)#普通响应步骤client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;用户空间---&gt;内核(复制)--&gt;client#senfile响应client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;client#但是如果使用file aio模块，必须禁用sendfile支持tcp_nopush on#不做推送，在开启sendfile才有效，它和tcp_nodeplay互斥，TCP_CORK是linux下tcp/ip传输的一个标准（一般情况下tcp交互中，当程序收到数据包后马上传送不等待，而TCP_CORK选项是数据包不会传送出去，等到数据包最大时一次性传输，有助于解决网络拥堵），在tcp_nopush on时候，才会设置TCP_CORK方法，该选项对于www.ftp等大文件才有帮助。在FreeBSD使用TCP_NOPUSH套接字，在Linux使用TCP_CORK套接字，详见Nagle算法tcp_nodeplay on#对于keepalive模式下连接是否使用tcp_nodelay选项，默认关闭，其功能类似tcp_nopush，将多个小报文合并成一个报文一起发送，提高宽带利用率，将发往同一个主机很小的TCP报文合并成一个,实际生产对于用户请求即使浪费带宽也不能合并请求keepalive_timeout 75 75#长链接超时时间，0表示禁用,默认为75s，请求完成后还需要保持多久连接，目的是减少创建连接过程给系统带来的耗损,通常默认足够，如果内部服务器通讯场景过大建议增大。#第一个75设置keep-alive客户端连接在服务端保持开启超时时间，第二个75可选，在客户端响应的header区域中设置一个"keep-alive:timeout=time"#当nginx作为反向代理时候，为了支持场链接#从client到nginx 和 nginx到server连接都需要设置长连接#例子http &#123; keepalive_timeout 75 upstream www &#123; server 192.168.0.1:8080; server 192.168.0.2:8080; keepalive 300; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;#upstream 中的keepalive，设置upstream服务器的空闲keepalive连接最大数量，当数量被突破时，最近使用最少连接将被关闭，keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量。#HTTP协议对长连接支持从1.1版本后才有，需要通过proxy_http_version指令设置为1.1#而Connection header应该被清理，清理从客户端过来的http header，因为即使是客户端和nginx之间是短连接，nginx和upstream之间也是可以开启长连接。所以需要清理客户端请求中的"Conection" headerkeepalive_requests #在keepalive连接上允许请求的最大资源数量，默认为100，当一个keepalive建立后，nginx就会为这个连接设置一个计数器，记录这个keepalive长链接上已经接受并处理的客户端请求数量，如果达到这个参数设置最大时，nginx会强行关闭这个长链接，使客户端重新建立新的场链接。#大多数情况下QPS不是很高，100足够，但是对一些QPS高比如(10000QPS,甚至更高)100显的太低,#QPS=10000时候，客户端每秒发送10000个请求(通常建立长链接)，每个连接最多跑100次请求，意味着每秒就有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒重新新建100个连接，从而导致大量TIME_WAIT的socket链接，因此对于QPS较高场景，很有必要加大这个设置，避免出现大量连接被生成在抛弃。#出现大量TIME_WAIT情况#nginx出现大量TIME_WAIT情况有两种#keepalive_request设置较小，高并发超过此值后nginx悔强制关闭客户端保存keepalive长连接；(主动关闭连接后导致nginx出现TIME_WAIT)#keeaplive设置比较小(空闲数小)，导致高并发nginx会平凡出现连接数抖动(超过该值会关闭连接)，不停关闭\开启和后端server保持的keepalive长连接#后端server端出现大量TIME_WAIT情况#nginx没有打开和后端长连接，即使设置proxy_http_version 1.1和proxy_set_header Connection "" ;从而导致后端server每次关闭连接，高并发出现server端大量TIME_WAIT。keepalive_disable none|browser;#禁止那些游览器不使用keepalive功能，如果keepalive_disable msie6，禁止ie6不使用keepalive功能client_body_buffer_size;#接受客户端请求报文body的缓存区大小，默认为16k，在32位系统上是8k，超出指定大小将移存在磁盘上client_body_temp_path [Level1 [level2 [level3]]]#设定与存储客户端请求body临时存放路径以及子目录结构和数量#例子client_body_temp_path /var/tmp 2 2;#说明椅子子目录使用2个字符表示,二级目录下用2字符表示,每级目录都有256个文件夹，采用16进制表示文件，1个字符最多表示16，2字符表示256 aio on;#是否启用异步IO模式,可用于HTTP,SERVER,LOCATION上下文，sendfile不能与AIO同时使用 directio SIZE|off;#当大于SIZE的时候是否直接IO操作,不存在内存缓冲,直接从硬盘加载使用，用于HTTP,SERVER,LOCATION上下文中 open_file_cache off | max=N [inactive=time];#对打开文件缓存.主要包括:文件描述符,文件大小,最近修改时间，目录结构，没有找到或者没有权限操作文件相关信息，#max=N,可缓存的最大条目上限,一旦达到上限, 则会使用LRU算法从缓存中删除最近最少使用的缓存项#inactive=time : 在此处指定的时长内没有被访问过的缓存项识别为非活动缓存项, 因此直接删除 open_file_cache errors on|off;#是否缓存找不到其路径的文件,或没有权限访问的文件相关信息 open_file_cache_valid TIME;#每隔多久检查一次缓存中缓存项的有效性,默认为60秒 open_file_cache_min_uses NUMBER;#缓存项在非活动其限内最少应该被访问的次数 UPSTREAMupstream模块可定义一个新的上下文，位于server之上http之下，包含一组upstream服务器，这些服务器可能被赋予不同权重，不同类型，设置可以基于维护原因被标记为down。 1234567891011121314151617181920212223242526272829303132333435363738http&#123; ...; upstream myserver &#123; service 192.168.1.10:8080 wight=5 max_fails=3 file_timeout=6; service 192.168.1.10:8090 wight=5 max_fails=3 file_timeout=6; service 192.168.1.20:8080 backup; service 192.168.1.30:8080 down; ip_hash; keepalive 300; &#125; service &#123; ..; location &#123; ..; &#125; &#125;&#125;upstream模块常用的指令有：round-robin#轮询发往后端默认为轮轮询ip_hash#基于客户端IP地址完成请求的分发，它可以保证来自于同一个客户端的请求始终被转发至同一个upstream服务器least_conn#最少连接调度算法keepalive#每个worker进程为发送到upstream服务器的连接所缓存的个数.server:定义一个upstream服务器的地址，还可包括一系列可选参数，如： weight： 权重； max_fails： 最大失败连接次数，失败连接的超时时长由fail_timeout指定； fail_timeout： 等待请求的目标服务器发送响应的时长； backup： 用于fallback的目的，所有服务均故障时才启动此服务器； down： 手动标记其不再处理任何请求； SERVER用于定义虚拟服务器相关的属性，位于http上下文，常见的指令有backlog、rcvbuf、bind及sndbuf等 12345678910111213141516171819202122232425262728293031323334....;http &#123; ....; upstream &#123; ...; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; root /www; location / &#123; ....; &#125;&#125;listen [:port] | [default_server] | [ssl] [http2 | spdy];#监听端口，如果有多块网卡可以使用listen 192.168.1.2:80#ssl 用于限制只能通过SSL连接提供服务，不是以端口确认其协议,需要启用SSL,需要在监听的端口后面, 添加ssl选项。#http2 支持http version2，需要在nginx编译时开启http2协议支持#spdy google研发的http协议，比http1.1性能好。全称speedy,在编译时编译了spdy模块情况下，用于支持spdy协议server_name localhost;#服务名称或者域名，支持正则表达式匹配*.baidu.com 或者 ~^.*.baidu.com$charset koi8-r;#字符集设置access_log PATH main;#日志路径，以及使用哪个日志格式root /www;#设置web资源路径映射,用于指明请求url所对应的文件目录路径,可用于server或者location中 LOCATION通常位于server上下文，用于设定某URI的访问属性，location也可以嵌套, 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657....;http &#123; ....; upstream &#123; ...; &#125; server &#123; ...; location / &#123; root html; index index.html; try_files index.html /images/test1.html; &#125; location /images/ &#123; alias /data/imgs/; &#125; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125;root html;#定义url路径，这里是绝对路径，nginx下的html目录,当访问daemon.com/时候访问的是nginx下的html目录index index.html;#定义默认主页(nginx_http_index_module模块引入),可定义在http,server,locationtry_files $uri $uri/ /index.php?$args;#可用于server和location中,尝试查找第1到最后一个文件,如果第一个不存在跳转到下一个，必须确保最后一个存在,如果不存在则会导致死循环。alias /data/imgs;#只能用于location配置段,定义路径别名root和alias区别:location /imags/ &#123; root /data/imgs/;&#125;location /imags/ &#123; alias /data/imgs/;&#125;root指令:给定的路径对应location的"/",这个URI/imags/test.jpg --&gt; /data/imgs/imags/test.jpgalias指令:路径为对应的location的"/url/"这个URI/imags/test.jpg --&gt; /data/imgs/test.jpgerror_page code $uri;#定义错误页面，根据http状态码重写向错误页面#实例:error_page 404 /404.html;如果页面返回404就以404.html页面返回，状态码是404error_page 404 = /404.html;如果页面返回404就以404.html页面返回，状态码是200 location说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354location语法格式:location [ = | ~ | ~* | ^~ ] url &#123; ...&#125;= URI的精确匹配~ 做正则表达式匹配,区分字符大小写~* 做正则表达式匹配,不区分字符大小写^~ URI的左半部分匹配,不区分字符大小写!~,!~* 区分大小写不匹配，不区分大小写不匹配#允许根据用户请求的URI来匹配定义的各location,匹配到时, 此请求将被相应的location块中的配置所处理。#简言之:用于为需要用到专用配置的uri提供特定配置，当匹配多次时,其匹配优先级为:精确匹配=,^~,~或~*,不带符号的URL, 如果优先级都一样, 就匹配最精确的规则#优先级:location = / &#123; [configuration A]&#125;location / &#123; [configuration B]&#125;location /documents/ &#123; [configuration C]&#125;location ^~ /images/ &#123; [configuration D]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; [configuration E]&#125;#例子:location ~ /\.ht &#123; deny all;&#125;#当访问.htaccess文件时候拒绝所有location ~ \.php$ &#123; root /xxx; fastcgi_pass 127.0.0.1:9000;&#125;#将所有php文件推送到php-fpmlocation ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ &#123; ...;&#125;#匹配gif|jpg|jpeg|png|bmp|swf|js|css结尾文件location 后面"/"和没有"/"的区别#看个例子如果域名是www.zhuxyid.com,访问www.zhuxyid.com/helloworl的话location /hello &#123; #这里能匹配到 root xxx;&#125;location /hello/ &#123; #这里则不能匹配 root xxx;&#125; Nginx If判断在location中使用if语句可以实现条件判断，其通常有一个return语句，且一般与有着last或break标记的rewrite规则一同,防盗链模块使用。但其也可以按需要使用在多种场景下，需要注意的是，不当的使用可能会导致不可预料的后果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#if语句中的判断条件#正则表达式匹配： ~ 与指定正则表达式模式匹配时返回“真”，判断匹配与否时区分字符大小写； ~* 与指定正则表达式模式匹配时返回“真”，判断匹配与否时不区分字符大小写； !~ 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时区分字符大小写； !~* 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时不区分字符大小写；#文件及目录匹配判断： -f, !-f 判断指定的路径是否为存在且为文件； -d, !-d 判断指定的路径是否为存在且为目录； -e, !-e 判断指定的路径是否存在，文件或目录均可； -x, !-x 判断指定路径的文件是否存在且可执行； #例子:http &#123; upstream imageserver&#123; server 192.168.0.10:80; server 192.168.0.11:81; &#125; server &#123;&#125; location / &#123; if ($request_method == “PUT”) &#123; #如果客户端方法是PUT,就代理到0.11上，有点读写分离的感觉。 proxy_pass http://192.168.0.11:8021; &#125; if ($request_uri ~ "\.(jpg|gif|jpeg|png)$") &#123; proxy_pass imageservers; break; &#125; &#125; &#125;实例:#cookie首部检测匹配if ($http_cookie ~* "id=([^;]+)(?:;l$)") &#123; set $id $1;&#125;#请求报文的请求方法是POST,返回405if ($request_method = POST) &#123; return 405;&#125;#限速if($slow) &#123; limit_rate 10k; break;&#125;#非法引用,返回403,注:也可以对非法引用到其它页面if($invalid_referer) &#123; return 403;&#125;#根据IE类型重写if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;returncode [text];returncode URLreturn URL;#return:立即停止对请求的URI的处理,并返回指定的状态码set $variable value;#set:设定变量值,或者自定义变量rewrite_log on | off;#是否将重写日志记录errorlog中,默认为关闭(调试方法:错误日志debug,并开启rewrite_log) Nginx全局变量1234567891011121314151617181920212223$args$content_length$content_type$document_root$document_uri$host$http_user_agent$http_cookie$limit_rate$request_body_file$request_method$remote_addr$remote_port$remote_user$request_filename$request_uri$query_string$scheme$server_protocol$server_addr$server_name$server_port$uri Nginx反向代理Nginx通过proxy模块实现反向代理功能。在作为web反向代理服务器时，nginx负责接收客户请求，并能够根据URI、客户端参数或其它的处理逻辑将用户请求调度至上游服务器上(upstream server)。nginx在实现反向代理功能时的最重要指令为proxy_pass，它能够将location定义的某URI代理至指定的上游服务器(组)上。 反向代理：正对外部网络，如果客户端访问某个网站，但该网站不提供页面，只把请求代理只后端，在从后端返回至代理，在响应给客户端，该代理称作反向代理。 正向代理：针对内部网络，如果客户端不能访问外网，需要设置通过某台机器代理至外网，外网结果返回至代理机，在返回给客户端，该代理称作正向代理。 透明代理：针对内部网络，不需要设置任何代理服务器地址，但是需要将网关指向代理服务器。 参考：Nginx proxy中文文档 proxy模块指令proxy模块的可用配置指令非常多，它们分别用于定义proxy模块工作时的诸多属性，如连接超时时长、代理时使用http协议版本等.下面对常用的指令做一个简单说明。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556proxy_pass [domain | ip | upstream_name]|:PORT;#将location代理到哪里，这里可以是域名,IP,upstream名称，可以加端口，应用于Location上下文#这里值得注意:#当proxy_pass后有"/"时候，相当于绝对根路径，不会将location 中匹配的路径代理走#当proxy_pass后没有"/"时，会把location中部分路径代理走#示例:#访问:http://www.aaa.com/abc/index.html,配置如下location /abc/ &#123; proxy_pass http://127.0.0.1:8080/;&#125;#会代理到:http://127.0.0.1:8080/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080;&#125;#会代理到:http://127.0.0.1:8080/abc/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev;&#125;#会代理到: http://127.0.0.1:8080/devindex.html;localtion /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev/;&#125;#会被代理到: http://127.0.0.1:8080/dev/index.html;proxy_pass_header field;#传递头部给后端服务器proxy_hide_header field;#设定发送给客户端的报文中需要隐藏的首部proxy_set_header field value;#用于向后端服务器发请求报文时，将某请求首部重新赋值，或在原有值后面添加一个新的值#示例:proxy_set_header HOST $http_host;#将$http_host传递给HOST变量, 在nginx向后端发请求时,加入HOST首部proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#将客户端的真实IP地址赋值给X-Forwarded-For变量，在nginx想后端发时加入X-Forwarded-For变量，#如果中间有多层代理，每经过一层代理时,代理服务器都会将在后面增加自己的IP地址，并以分号分隔proxy_redirect;#重写location并刷新从后端收到报文首部proxy_connect_timeout;#nginx将一个请求发送到后端之前等待最大时长proxy_send_timeout;#在连接断开之前两次发送到后端的写操作的最大间隔时长proxy_rend_timeout;#在连接断开之前两次发送到后端接受操作的最大间隔时长proxy_cookie_domain;#发往后端时SET-COOKIE首部设定的domain属性修改为指定的值，可以设置为字符串,正则表达式模式或者一个引用变量proxy_cookie_path;#发送后端时通过SET-COOKIE首部设定的PATH属性修改为指定的值 proxy缓冲nginx在默认情况下在将其响应给客户端之前会尽可能地接收来upstream服务器的响应报文，它会将这些响应报文存暂存于本地并尽量一次性地响应给客户端。然而，在来自于客户端的请求或来自upsteam服务器的响应过多时，nginx会试图将之存储于本地磁盘中，这将大大降低nginx的性能。因此，在有着更多可用内存的场景中，应该将用于暂存这些报文的缓冲区调大至一个合理的值。 12345678proxy_buffer_size size#设定用于暂存来自于upsteam服务器的第一个响应报文的缓冲区大小；proxy_buffering on|off;#启用缓冲upstream服务器的响应报文，否则，如果proxy_max_temp_file_size指令的值为0，来自upstream服务器的响应报文在接收到的那一刻将同步发送至客户端；一般情况下，启用proxy_buffering并将proxy_max_temp_file_size设定为0能够启用缓存响应报文的功能，并能够避免将其缓存至磁盘中；proxy_buffers 8 4k|8k#用于缓冲来自upstream服务器的响应报文的缓冲区大小； proxy缓存nginx做为反向代理时，能够将来自upstream的响应缓存至本地，并在后续的客户端请求同样内容时直接从本地构造响应报文。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162proxy_cache_path PATH [levels=levels] keys_zone=name:size [inactive=time][max_size=size];#定义缓存，设置缓存名称，缓存路径，缓存大小等。只能用于HTTP上下文#实例:proxy_cache_path /data/nginx/cache/img levels=1:2:1 keys_zone=my_img:20m max_size=10g;#levels=1:2:1 #表示一级目录1个字符,二级目录2个字符,三级目录1个字符,最多只能设置3级#keys_zone=my_img:20m #存储键区域大小#max_size=1g #/img目录空间上限1G，当缓存对象超出时候,采用LRU清理，谁用的少清理谁#inactive #非活动缓存项从缓存中剔除之前的最大缓存时长#loader_files #缓存加载器每次工作过程最多为多少个文件加载器#loader_sleep #缓存加载器的每次迭代工作后的睡眠时长#loader_threashold #缓存加载器的最大睡眠时长proxy_cache NAME;#调用设置的缓存名称，必须实现设定好缓存proxy_cache_lock#在缓存未命中阻止多个相同的请求同时发往后端，其生效范围是worker级别proxy_cache_lock_timeout#proxy_cache_lock功能锁定时长proxy_cache_min_uses#某响应报文被缓存之前至少应该被请求次数proxy_cache_use_stale#在无法连到upstream服务器时候那种情况(error，timeout，http_500)让nginx本地缓存过期的缓存对象之间响应给客户端#实例proxy_cache_use_stable error|timeout|invalid_header|updating|http_50[1~4]|http_404|offproxy_cache_valid#用于为不同响应设定不同时长的有效缓存时长#实例proxy_cache_valid 200 302 10m;#设定状态为200和302的缓存时长为10分钟proxy_cache_methods [GET|POST|HEAD];#为那些方法启用缓存功能.proxy_cache_bypass STRING;#设置那种情况下，nginx不从缓存读取数据#实例proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment;proxy_cache_bypass $http_pragma $httpp_authorization;#配置实例http &#123; proxy_cache_path /data/nginx/cache levels=1:2:1 keys_zone=MYHTML:10m inactive=24h max_size=1g; upstream my_web &#123; server 172.16.0.2:8080; server 172.16.0.2:8081; &#125; server &#123; location / &#123; proxy_pass http://my_web; proxy_set_header Host $host; proxy_cache MYHTML; proxy_cache_valid 200 1d; proxy_cache_valid 301 302 10m; proxy_cache_vaild any 1m; &#125; &#125;&#125; Nginx常用模块nginx-limit模块 ngx_http_core_module，ngx_http_limit_conn_module，ngx_http_limit_req_module中的limit相关参数 123456789101112131415161718192021222324limit_except METHOD &#123;...&#125;;#对指定范围之外的其它方法进行访问控制,应用于location上下文#例子limit_except GET &#123; allow 172.16.0.0/16; deny all;&#125;limit_rate SPEED;#限制客户端每秒种所能够传输的字节数, 默认为0,表示不限制,应用于http,server,location,if in location上下文中#例子server &#123; if ($slow) &#123; set $limit_rate 4k; &#125;&#125;limit_rate_after SIZE;#超出SIZE的值, 就限制速度,应用于http,server,location,if in locataion上下文中#例子location /flv/ &#123; limit_rate_after 500k; limit_rate 50k;&#125; 访问控制12345678910111213141516#allow和deny可用于http，server，location上下文中allow address | CIDR | UNIX | ALL;#允许那些地址可以是网络地址deny address | CIDR | UNIX | ALL;#拒绝，同上例子:location / &#123; allow 172.16.0.2; allow 192.168.1.0/24; allow 2018:abc8::22; deny 172.16.0.1; deny all;&#125; 基本认证模块1234567891011auth_basic STRING;#定义认证名称,主要是提示作用.认证时显示提示信息auth_basic_user_file FILE;#用户认证的用户账号文件#格式:user1:pwd1user2:pwd2#也可以直接使用httpd程序提供的htpasswd生成#htpasswd -c -m /www/.htpasswd user1#&gt;pwd输入密码 自定义头信息12345678add_header_name value [always]#向响应报文添加自定义首部，并为其赋值,应用上下文为http,server.localtion中#例子add_hreader Via $server_addrexpires [modified] time;expires epoch | max | off#允许或者禁止向响应报文的cache-control或者expires首部添加新值或修改其值 nginx状态功能1234567891011121314151617181920#stub_statu功能,编译时添加--with-http_stub_status_module选项#实例location /my_ngx_monitor &#123; stub_status on; allow 172.16.0.100; deny all;&#125;#访问http://www.zhuxyid.com/my_ngx_monitorActive connections: 1server accepts handled requests2 2 18Reading: 0 Writing: 1 Waiting: 0#active connections:当前活动客户端连接数(包括等待)#accepts:已接受客户端连接总数量#handled:已处理完成的客户端连接请求总数量#requests:客户端总的请求数#reading:当前正在读取客户端请求报文首部信息的数量#writing:当前正在向客户端发送响应报文的链接数量#wating:长连接模式的保持连接个数,或者活动连接个数(reading+writing) nginx防盗链模块基于请求报文中的referer首部的值, 做访问控制 ,可以防止盗链,其只应用于server,location上下文 123456789101112131415161718referer_hash_bucket_size SIZE;#可以放多个缓存我要上,默认是64referer_hash_max_size SIZE;#默认2048valid_referers none|blocked|server_names|string...;#none : 请求的报文不存在referer首部#blocked : 请求报文中存在referer首部,但其没有有效值,或其值非以http://或https开头#server_names :其值为一个主机名#arbitrary string : 直接字符串,可以使用*号匹配#rugular expression : 以~起始的正则表达式#注意: 内置变量:$invalid_referer(所有不能符合valid_referer指定定义的引用请求均为不合法引用),需要加上条件判断语句#示例:valid_referers none blocked server_name *.example.com example.* www.example.org/aglleries/ ~\.google\.;if ($invalid_referer) &#123; return 403;&#125; nginx重写模块将请求的url基于正则表达式进行重写(URL重定向), 在如下情况下可以使用: http转换成httpd服务(http —- https) 域名转换domain.tld —-domain2.tld, URL转换uri1—-url2 1234567891011121314151617181920rewrite regex replacement [flag];#应用于server,location,if上下文regex:基于PERL的正则表达式,用于匹配用户请求的URL;replacement:重写重定向的结果flag:标志位[last|break|redirect|permanent]#regex:PCRE正则表达式元字符: 字符: .,[],[^] 次数: *,+,?,&#123;m&#125;,&#123;m,&#125;&#123;m,n&#125; 位置锚定: ^,$ 或者: | 分组: (), 后向引用: 2,…..#flag:last #重写完成之后停止对当前uri的进一步处理,改为对新uri的新一轮处理(对URI的重写规则进行匹配,当检查到第一条匹配到的时候,进行重写.然后返回到重写规则的第一条位置进行重新匹配,如果有匹配到的再进行重写,默认只能10次匹配). 此过程用户端感受不到.break #对URI的重写规则进行匹配,只要匹配到就重写,不再进行再次匹配,此过程用户端感受不到.redirect #重写完成之后返回客户端一个临时重定向,由客户端对新的URI重新发起请求, 即302的状态码permanent #重写完成之后,会返回客户端一个永久的重写向,由客户端对新的URI重新发起请求,即301的状态码 nginx ssl12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485listen 443;#监听端口server_name www.zhuxyid.com;#ssl主机的FQDN名称ssl_certificate cert.pem;#ssl的公钥ssl_certificate_key cert.key;#ssl的私钥ssl on | off;#启用或关闭ssl,若不在listen处定义，也可以在server&#123; &#125;中定义ssl on; 来启用https服务ssl_session_cache off | none | [builtin[:size]] [shard:name:size];#默认使用shared模式#off : 禁止缓存 ,关闭缓存,不支持缓存功能#none :禁止缓存 ,不响应缓存#builtin : 使用openssl内置的ssl会话缓存 ,此机制为各worker私有#shared: 在各worker之间使用一个共享的缓存,name:独有名称,size:缓存空间大小, 默认为1M,可以调到10M示例: ssl_session_cache shared:ssl:1m;ssl_session_timeout 5m;#ssl会议超时时长,即ssl session cache中的缓存有效时长,默认为5mssl_protocols [sslv2][sslv3][tlsv1][tlsv1.1][tlsv1.2];#使用哪些协议版本, 默认为TLSv1,TLSv1.1,TLSv1.2#ssl_protocols SSLv2 SSLv3 TLSv1;ssl_ciphers HIGH:!aNULL:!MD5;ssl_ciphers CIPHERS#nginx使用的加密算法ssl_prefer_server_ciphers on;#依赖SSLv3和TLv1协议的服务器密码将优先于客户端密码ssl_buffer_size SIZE;#ssl缓冲大小ssl_client_certificate file;#需要验证客户端证书ssl_crl FILE;#证书吊销列表ssl_trusted_certificate FILE;#信任的根证书#配置实例a.创建系统私钥(umask 077; openssl genrsa 2048 &gt; /PATH/cakey.pem)b.生成系统自签证书openssl req -new -x509 -key /PATH/cakey.pen -out cacert.pem一次输入:CN,JS,NJ,zhuxyid,it,ca.zhuxyid.com,caadmin@zhuxyid.comc.创建serial index.txtecho 01 &gt; serial &amp; touch index.txt &amp; cd nginx/ssl/d.创建私钥(umake 077;openssl genrsa 1024 &gt; nginx.key)openssl req -new -key nginx.key -out nginx.csr依次输入:CN,JS,NJ,zhuxyid,it,www.zhuxyid.comopenssl ca -in nginx.csr -out nginx.crt -days 3650more nginx.confserver &#123; listen 443; server_name www.zhuxyid.com; ssl on; ssl_certificate /ssl/nginx.crt; ssl_certificate_key /ssl/nginx.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers HIGH:!aNULL:!MD5; listen 443; location / &#123; root html; index index.html index.htm; &#125;&#125;/usr/local/nginx/sbin/nginx -s reload#这里只是测试用,如果是外网需要向权威机构申请证书，freessl.org nginx压缩模块123456789101112131415161718192021222324gzip on|off#开启压缩,通常位于http上下文gzip_comp_level [1-9]#压缩比率，默认为1，越大越占用cpu使用率gzip_types mine.types#指名对那些类型资源进行压缩gzip_disable msie6;#根据游览器来设置是否压缩，这里是ie6不开启压缩gzip_min_length 0#设置允许压缩页面最小字节数，页面字节从header头中的content-length获取，默认值0，不管页面多大都会被压缩，通常设置大于1k字节，小于1k可能越压越大，比如本身10字节，压缩一下反而大了，噗噗噗#实例:http &#123; gzip on; gzip_comp_level 6; gzip_disable msie6; gzip_types text/plain text/css text/xml application/x-javascript application/xml application/json application/java-script; gzip_min_length 2;&#125; 小结 对于nginx模块还有很多很多，以上是最基础的一些安装配置说明，后期还需要总结关于nginx的一些奇淫技巧]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F11%2F26%2FDockerfile%2F</url>
    <content type="text"><![CDATA[关于Docker基础,请看http://blog.zhuxyid.com/2018/11/23/Docker 自制镜像方式​ 基于容器方式来制作镜像，这种方法配置繁琐,不适合使用,每次配置文件更该都需要制作镜像 ​ 基于Dockerfile DockerfileDockerfile是一个文本文档，包含用户可以在命令行上调用命令组合，使用docker build用户可以自动构建一个连续执行多个命令行 Dockerfile编译完成科研使用docker build来进行编译Dockerfile文件 1docker build -t IMAGE_NAME:TAGS /DOCKERFILE_PATH/Dockerfile Dockerfile注意事项12345Comment #注释 INSTRUCTION arguments #指令 参数(指令不区分大小写，约定惯例尽量使用大写) docker运行指令是按照你的指令的顺序。Dockerfile文件首字母必须是大写 .dockeringore定义忽略哪些文件，打包时不包含这些文件 Dockerfile语法FROMFROM指令是最重的 一个且必须为Dockerfile文件开篇的第一个非注释行, 用于镜像文件构建过程 指定基准镜像，后续的指令运行于 此基准镜像 所提供的运行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在docker主机上查找指定的镜像文件，其不存在时，则会从Docker hub registry拉去所需的镜像文件 (如果找不到指定的镜像文件，docker build会返回一个错误信息) 123456789语法:FROM &lt;repository&gt;[:&lt;tag&gt;]FROM &lt;repository&gt;@&lt;digest&gt; @digest指定hash码进行验证 &lt;repository&gt;:指定作为base image的名称 &lt;tag&gt;:base image的标签 可选性，默认是latest例子:# Description: test imgFROM busybox:latest MAINTANIER用于让dockerfile制作者提供信息，Dockerfile并不限制MAINTAINER指令可在出现的位置，但推荐放在FROM指令后 1234567891011语法:MAINTAINER &lt;authtor's detail&gt;&lt;authtor's detail&gt; 可以是任何文本信息，但是通常使用名称和地址邮箱例子:MAINTAINER "zhuxyid &lt;zhuxyid@gmail.com&gt;"LABLE:指定镜像元数据Syntax:LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;例子: LABEL maintainer="zhuxyid &lt;zhuxyid@gmail.com&gt;" COPY用于从Docker主机复制文件到创建的新镜像文件 1234567891011121314语法：COPY &lt;src&gt;&lt;dest&gt;COPY ["&lt;src&gt;",.."&lt;dest&gt;"] 如果路径有空白字符时候，用这种方式复制 src 源文件，支持使用通配符 dest 目标路径 即正在创建image文件系统路径,建议&lt;dest&gt;为绝对路径，否则COPY指定则以WORKDIR为起始路径文件复制准则:&lt;src&gt; 必须是build上下文中路径，不能是父目录的文件如果&lt;src&gt;是目录，则 内部文件或子目录都会 被递归复制,但&lt;src&gt;自身目录不会被复制 相当于 cp -r src/* /dest如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用通配符，则&lt;dest&gt;必须是一个目录，且必须以/结尾 相当于 cp -r src/* /desc/如果&lt;dest&gt;不存在，则会被自动创建，这包括其父目录路径例子：COPY index.html /data/web/html/ #这里index.html文件必须先创建，而且必须为build目录下！ ADDADD指令类似COPY指令，ADD支持使用TAR文件和URL路径 1234567891011语法:ADD &lt;src&gt;,..&lt;dest&gt;ADD ["&lt;src&gt;",.."&lt;dest&gt;"]操作准则: 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接创建为&lt;dest&gt;; 如果&lt;dest&gt;以/结尾,则文件名URL指定文件将被直接下载并保持为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式tar文本，他将被展开为一个目录，其行为类似"tar -x"命令，然而通过URL获取到的tar文件将不会自动展开 如果&lt;src&gt;有多个，或其间接或直接使用通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径； 如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt; WORKDIR用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 12345678语法:WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指定可出现多次，其路径也可以为相对路径，不过其是相对此前一个WORKDIR指令指定的路径,另外，WORKDIR也可以调用由ENV指定定义的变量例子：WORKDIR /var/logWORKDIR $STATEPATH VOLUME用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上的卷 1234语法:VOLUME &lt;mountpoint&gt;VOLUME ["&lt;mountpoint&gt;"]如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 EXPOSE用于为容器打开指定要监听的端口以实现与外部通讯,注意，这里只能是定义容器的端口.后期docker下载下来宿主机的端口并不确定 123456789语法：EXPOSE &lt;port&gt; [/&lt;protocol&gt;][&lt;port&gt;[/&lt;protocol&gt;]...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议EXPOSE指令可一次指定多个端口，如EXPORT 11211/udp 11211/tcpdocker run --name ttt -P 可以自动暴露需要暴露的端口 ENV用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY等)所调用 WORKDIR只是工作目录 调用格式为$variable_name或者${variable_name} 123456789语法:ENV &lt;key&gt;&lt;value&gt;ENV &lt;key&gt;=&lt;value&gt;$&#123;NAME:-tom&#125; #如果NAME变量没有值，将他设为tom，如果有值则使用本身$&#123;NAME:+tom&#125; #如果NAME为空则不设置，如果不为空则设置tom第一种格式中,&lt;key&gt;之后的所有内容均被视作其&lt;value&gt;的组成部分，因此，一次只能设置一个变量第二种格式中,可用一次设置多个变量，每个变量为一个&lt;key&gt;=&lt;value&gt; 的键值对，如果&lt;value&gt;中包含空格，可用反斜线(\)进行转移;也可以通过对&lt;value&gt;加引号进行标识,另外反斜线可以续行定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能 RUN用于指定docker build过程中运行的程序，其可以是任何命令 123456789语法:RUN &lt;command&gt;RUN ["&lt;executable&gt;","&lt;param1&gt;","&lt;param2&gt;"]第一个格式中,&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程在容器中的PID不为1，不能接受Unix型号，因此，当使用docker stop container命令停止容器时，次进程接受不到SIGTERM信号第二个格式中，参数就是一个JSON格式的数组，其&lt;executable&gt;为运行的命令，后面的&lt;paramN&gt;为传递给命令的选项或参数；然而此格式指定的命令不会以"/bin/sh -c"来发起；因此常见shell操作，如变量替换以及通配符(?,*等)替换将不会进行；不过如果要运行的命令依赖次shell特性的话，可以将其替换为类似下面格式RUN ["/bin/bash","-c","&lt;excutable&gt;","&lt;param1&gt;"] CMD类似RUN指令，CMD指令也可以用于运行任何命令或应用程序，不过二者运行时间点不同 RUN 指令运行与镜像文件构建过程，而CMD指令运行基于Dockerfile构建出的新映像文件启动一个容器时 CMD 指定的首要 目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器将终止；不过CMD指令的命令其可以被docker run的命令选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅是最后一个会生效，而RUN不是 1234567语法:CMD &lt;command&gt;CMD ["&lt;excutable&gt;","&lt;param1&gt;","&lt;param2&gt;"]CMD ["&lt;param1&gt;","&lt;param2&gt;"]前两种语法格式的意义相RUN第三种则用于为ENTRYPOINT指令提供默认参数 RUN 是运行在docker build过程中的命令，而CMD 是在docker run运行时的命令 注意:一个容器只是用于单个应用。nginx,redis,mysql都是运行在后台 所有进程都是一个进程的子进程，除了init。init是内核启动 比如手动启动nginx，它是shell的子进程，有些shell子经常会占据终端窗口，需要加&amp;符号 nginx &amp; 这里nginx父进程依然是shell，当shell结束后，会将nginx也结束 nohup nginx &amp; 这里是将nginx送到后台，重新赋予一个新的进程，这是shell退出这个依然存在 在用户空间先启动shell,才能使用ls，cat，等命令，可以直接exec执行命令. 在容器中可以基于shell启动程序，也可以通过exec启动程序 在json数组中，引号一定要写双引号，单引号可能会出现问题 ENTRYPOINT类似CMD指定的功能，用于为容器指定默认运行程序，从而使得容器像一个单独的可执行程序 于CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令指定的参数所覆盖，而且，这些命令参数会被当做参数传递给ENTRYPOINT指定指定的程序 不过,docker run命令的–entrypoint选项参数可覆盖ENTRYPOINT指令指定的程序 12345678910111213141516171819202122语法:ENTRYPOINT &lt;command&gt;ENTRYPOINT [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]ENTRYPOINT /bin/http -f -h /data/www/htmldocker run命令传入的命令参数会覆盖CMD指令的内容并且附加到EMTRYPOINT命令最后作为其参数使用Dockerfile文件中可用存在多个ENTRYPOINT指令，但仅最后一个生效如果Dockfile格式是这样CMD和ENTRYPOINT同时存在CMD [&quot;/bin/httpd&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;]CMD /bin/httpd -h /data/web/html #这样写会出错，因为不会被当成参数，需要写成列表的形式ENTRYPOINT /bin/httpd -f -h /data/web/html #如果需要CMD传参，这里建议写成列表，不然有问题CMD和ENTRYPOINT同时存在，那么CMD会将命令变成参数传递给ENTRYPOINT例子CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;] ENTRYPOINT [&quot;/bin/sh&quot;,&quot;-c&quot;]#CMD将传给ENTRYPONT作为默认参数#如果执行docker run --name ttt --rm image:v1 &quot;ls /data&quot;#&quot;ls /data&quot;则会覆盖CMD#如果执行docker run --name ttt --entrypoint &quot;ls&quot; --rm image:v1 &quot;/data&quot;#ls会覆盖EXTRYPOINT,/data覆盖CMD USER用于指定运行image时或者运行Dockerfile中任何RUN,CMD或者ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下, container运行身份是root用户. 123语法USER &lt;UID&gt;|&lt;USERNAME&gt;需要注意:&lt;UID&gt;可以是任意数字，但实践中必须为容器中/etc/passwd中某用户的有效UID,否则docker run会失败 HEALTHCHECK健康状态检查，判断容器里面的程序是否正常运行. 这里需要注意，如果nginx指定的目录不存在，nginx也会运行，但是用户访问是访问不了的，可以断定这虽然是可以运行但不是想要的结果，比如使用curl检测网页200的信息，如果是200则正常，非200则不正常 123456789101112131415HEALTHCHECK定义一个CMD来检测容器中主进程工作状态与否 HEALTHCHECK NONE 拒绝任何监控状态检查格式: HEALTHCHECK [OPTION] CMD --interval=DURATION(default:30s) 每隔多久 --timeout=DURATION(default:30s) 超时时长 --start-period=DURATION(default:0s) 等待主进程初始化完成在检查，如果tomcat这种应用建议等待5秒 --retries=N(default:3) 检查次数，默认3次#检测状态结果：0:success1:unhealthy2:reserved实例:HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1 #每隔5分钟检查，超时时间3s，curl结果如果成功则不管他，如果不成功则返回1 SHELLlinux默认shell是[“/bin/sh”,”-c”] windows默认是[“cmd”,”/S”,”/C”] 格式：SHELL [&quot;/bin/bash&quot;,&quot;-c&quot;] STOPSIGNAL定义停止的信号，默认是15 格式: STOPSIGNAL 14可以修改停止的信号 ARGARG的参数只是一个变量，只在docker build时候使用，在--build-arg &lt;varname&gt;=&lt;value&gt; 12345678910111213141516语法：ARG &lt;name&gt;[=&lt;default value&gt;]ARG version=1.14ARG user=zhuxyid例子:FROM:nginx:$&#123;version&#125;ARG version=1.15LABEL maintainer=$&#123;author&#125;ARG version=&quot;1.15&quot;ARG author=&quot;zhuxyid &lt;772931883@qq.com&gt;&quot;docker build -t nginx ./docker build --build-arg &quot;version=1.16&quot; --build-arg &quot;author=zhuxyid&lt;hello@qq.com&gt;&quot; -t nginx ./ #可以直接在编译时候使用在docker build中可以用--build-arg参数来传值 ONBUILD用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile作用FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中FROM指令在build过程中被执行，将会”触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 12345678910111213141516语法:ONBUILD &lt;INSTRUCTION&gt;#尽管任何指令都可注册成触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和MAINTAINER指令#使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild#在ONBUILD指令中使用ADD或者COPY要格外小心，因为新构建过程中的下下文在缺少指定源文件会失败例子:cat /dockerfile/baseFROM centos:latestONBUILD RUN yum install nginx gcc gcc-c++#docker build -t base.img ./ #这里并不去安装nginx gcc gcc-c++cat /dockerfile/phpprojectFROM base.img #指定基于刚才创建的base.img作为base imageRUM yum install php-5.6#docker build -t php:v1 ./ #这里才会去安装， Example1234567891011121314151617181920212223242526272829303132333435363738394041424344mkdir /data/container/web1 cp -r /etc/yum.repos.d /data/container/web1/ cd /data/container/web1 wget &lt;http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.90/bin/apache-tomcat-7.0.90.tar.gz&gt; #more Dockerfile #Description: test dockerfile FROM busybox:latest LABEL maintainer=&quot;zhuxyid &lt;zhuxyid@gmail.com&gt;&quot; ENV DOC_ROOT /data/web/html/ #定义DOC_ROOT变量 ENV TOMCAT_ROOT=/data/tomcat/ \ #定义多个变量 TOMCAT_VERSION=&quot;tomcat-7.0.90&quot; \ NGINX_VERSION=&quot;nginx-1.14.0.tar.gz&quot; COPY index.html $DOC_ROOT COPY yum.repos.d /etc/yum.repos.d/ WORKDIR /opt/ADD http://nginx.org/download/nginx-1.14.0.tar.gz ./ VOLUME /data/www ADD apache-$&#123;TOMCAT_VERSION&#125;.tar.gz $&#123;TOMCAT_ROOT:-/data/tomcat/&#125; EXPOSE 80/tcp RUN cd /opt &amp;&amp; \ tar xf $&#123;NGINX_VERSION&#125; &amp;&amp; \ mv nginx-1.14.0 /usr/local/nginx #建议使用一条命令，因为如果多个RUN 那么层级就会越多 echo &quot;this is docker build image&quot; &gt; index.html docker build -t zhuxyid/index:v1 ./#-t指定name:tagdocker run --name web1 -it --rm zhuxyid/index:v1 cat /data/web/html/index.html #查看web1容器中/data/web/html是否有文件index docker run --name webserver --rm -P zhuxyid/index:v1 httpd -f -h /data/web/html docker port webserver docker run --name ttest --rm -P zhuxyid/index:v1 printenv#prinenv查看环境变量 #注意在启动容器的时候可以重新设置环境变量 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 printenv #在初始化容器时候可以重新赋值 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 ls /data/tomcat/apache-tomcat-7.0.90.tar.gz #这里只是重新赋值变量并不能修改image，因为这是docker build中已经生成了]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F11%2F23%2FDocker%2F</url>
    <content type="text"><![CDATA[容器是什么 容器是一种基础工具，泛指任何可以用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，存储，运输物品；物体可以被放置在容器中，而容器可以保护内容物. 虚拟化技术有哪些主机级别 虚拟化 完全 虚拟化：Vmware，Kvm，Xen 半 虚拟化：Xen,UML Xen如果CPU不支持虚拟化技术那就是半虚拟化，如果支持就是全虚拟化 半虚拟化：修改内核，通过被虚拟化出来的操作系统它是运行在虚拟化技术软件上的，虚拟化出来的操作系统执行的进程还是运行在真实机器上 完全虚拟化：不需要修改内核，直接通过虚拟机化技术软件上运行的操作系统。 容器级别 虚拟化 LXC,OpenVz,Solaris Containers,FreeBSD jails LXC(LinuX Container)容器是内核虚拟化技术,可以提供轻量级的虚拟化,以便隔离进程和资源,不需要提供指令解释机制以及全虚拟化的其他复杂性.容器可以有效的将单个操作系统管理的资源划分到孤立的组件中,以便更好的孤立组之间的平衡有冲突的资源使用需求。 早期容器应用在jail中,后来移植到linux中vserver(chroot),chroot所隔离仅仅只是看上去的,并没有真正隔离。 Linux namespace 是linux提供一种内核级别环境隔离的方法，有6种不同名称空间: linux namesapce: namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 MOUNT CLONE_NEWNS 挂载点(文件系统) 2.4.19 IPC CLONE_NEWIPC 信号量,消息队列,共享内存 2.6.19 PID CLONE_NEWPID 进程变化 2.6.24 USER CLONE_NEWUSER 用户和用户组 3.8 NETWORK CLONE_NEWNET 网络设备,网络栈,端口等 2.6.29 Docker是什么Docker是LXC增强版,Docker简化容器使用难度,通常一个容器中只运行一个进程. 对开发来说带来极大便利,分发容易,一次编写到处运行 然而对运维来说(有优点有缺点), 对开发极大便利需要运维干什么? Docker安装环境说明: 操作系统发行版:CentOS7.4 内核版本:3.10+ 安装说明: 使用yum方式安装,下载国内docker的yum源,加速下载. 安装过程:12345wget -P /etc/yum.repos.d/ https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i s@https://download.docker.com/@https://mirrors.tuna.tsinghua.edu.cn/docker-ce/@g /etc/yum.repos.d/docker-ce.repoyum repolist | grep docker-ceyum install docker-cesystemctl start docker.service 此时docker已经启动了，现在我们来搞清楚什么是docker Docker架构c/s架构，由三个组件（Docker Daemon,Docker Client,Docker Registry）构成 Docker Registry：​ 类似GitHub,只不过Docker Registry是存放镜像的仓库， 官方 https://hub.docker.com 国内 https://www.docker-cn.com/ 当然也可以自己部署一个仓库，建议用Harbor。 Docker Daemon：​ Docker进程，Docker核心服务。 这个类比数据库，比如数据库是放数据的，启动数据库后，等待客户端连接后才能操作。 也就是当docker启动时，等待docker客户端来操作。 Docker Client：​ Docker客户端工具,用来操作Docker的 比如我想在仓库下载一个镜像，从而启动一个容器，在容器中启动一个nginx服务,都是在客户端操作的。（docker client是发出者，docker daemon是执行者） 这里提到的镜像和容器一定要区分清楚。 如果是开发,那这么理解：镜像就是你创建的类，容器就是你的对象，对象是通过类实例化而来。也就是容器通过镜像而来,（容器依赖于镜像） 不要问镜像怎么来的，上面提过镜像是在仓库中。 也不要问仓库中的镜像怎么来的，那是别人做好的。因为你也可以自己做镜像。 Docker客户端操作12docker --help 格式:docker [option] command [args] 镜像类操作1234567891011121314docker search SOFTWARE_NAME #查找镜像名称示例: docker search tomcat #查找tomcat相关镜像，通常建议使用官方镜像，OFFICIAL 为OK的，或者Star点赞数高的镜像，原因自己悟docker pull SOFTWARE_NAME:TAGS #下载镜像示例: docker pull tomcat #下载tomcat镜像，如果不指定tags就下载latest版本 docker pull tomcat:7.0.92-jre8-alpine #详见hub.docker.com找到指定的镜像后在看tagdocker image ls #查看本地镜像，如果没有下载那么这里为空docker image rm SOFTWARE_NAME:TAGS #删除本地镜像示例: docker image rm tomcat #如果不指定删除镜像版本默认删除latest 容器类操作123456789101112131415161718192021222324252627282930313233343536373839404142docker run #运行容器，需要指定镜像实例: docker run tomcat #运行镜像为tomcat的容器,容器里面有tomcat,启动容器后tomcat也将运行起来，容器里面的程序都是在前台运行，会占用窗口 docker run --name myapp -d tomcat #启动myapp容器，镜像使用tomcat:latest，以后台运行 更多命令使用:docker run --help docker ps #查看运行中的容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee1ff8df6e70 tomcat "catalina.sh run" 3 seconds ago Up 2 seconds 8080/tcp myapp说明: 如果在docker run不指定容器名称会随机创建一个容器名称。 端口是容器内的端口.关于docker网络的内容下面会有讲解docker exec实例: docker exec -it myapp /bin/bash #进入myapp容器中 -it #新建一个tty并且进入docker stop实例: docker stop myapp #停止myapp容器 docker ps -a #查看所有容器，如果不加-a不能看到停止的容器 docker start实例: docker start myapp #运行停止的容器docker restart #重启容器实例: docker restart myappdocker rm #删除容器实例: docker rm myappdocker logs #查看容器运行的程序日志实例: docker logs myapp docker kill #杀死容器里的进程，进程一旦停止，容器也就停止。因为容器一般只运行一个前台程序，容器的生命周期下面会讲解实例: docker kill myapp Docker ImageDocker镜像包含启动容器的所需文件系统以及其内容，因此，用于创建并启动docker容器： 分层机制：镜像采用分层构建机制，最底层为bootfs,其为rootfs。 rootfs：用于系统引导的文件系统，包含bootloader和kernel，容器启动完成后被卸载以节约内存资源 rootfs：位于bootfs之上，表现为docker容器根文件系统 传统模式中，系统启动时，内核挂载rootfs时首先将其挂载为“只读”模式，自检其完整性 完成后将其重新挂载为读写模式 docker中，rootfs由内核挂载为“只读”模式，而通过“联合挂载”技术额外挂载一个可写层，容器就是在镜像多了一个可写层 传统模式: Docker: docker镜像层级：位于下层的镜像 称之为 父镜像(parent image)，最底层的称之为 基础镜像(base image) 最上层“可读写成”，下面为“只读层” 联合挂载：Aufs（advanced multi-layered unification filesystem ） 高级多层统一文件系统，同于实现linux平台中的联合挂载 Aufs是unionFS的重新实现,docker最初使用aufs作为容器文件系统层，目前仍作为存储后端之一来支持 Aufs另外一个实现是overlayFS，后者从3.18版本中开始被合并到linux内核中，overlayerFS是叠加文件系统 除了aufs，docker还支持btrFS,Device Mapper和VSF等。在ubuntu中，默认是aufs device mapper在linux2.6中支持逻辑卷管理的通过设备映射机制，它为实现用于存储资源管理的块设备驱动提供一个高度模块化的内核架构，它通过一个个模块化的target driver插件实现对IO请求的过滤或者重新定向等工作，当前已经实现的target driver插件包括软raid，软加密，逻辑卷条带，多路径，镜像，快照等。 docker使用Thin provisioning的snapshot的技术实现了类似auFS分层镜像 12&gt; docker info | grep "Storage Driver:" #来查看&gt; Docker ContainerDocker容器具有生命周期，”STOPD”,’CREATED’,’RUNNING’,’PAUSED’四个稳定状态， 容器一旦删除数据就会丢失，所以项目或者配置文件不要直接存放在容器中，通过卷（volume）的方式挂载至容器里. Docker事件状态图: Docker Registry当容器启动时,docker daemon会试图先从本地获取相关镜像，当本地不存在的时候，其将从registry中下载该镜像并保存在本地 流程图: docker client &lt; - - - http/https - - - &gt;docker daemon &lt; - - - http/https - - - &gt;docker registry 默认是使用https连接到registry，但是可以修改成http Registry 分类registry用于保存docker镜像，包括镜像的层次结构和元数据: 用户可自建registry，也可以使用官方的docker hub 分类: sponsor registry 第三方registry，供客户和docker社区使用 mirror registry 第三方registry，只让客户用 verdor registry 由发布docker镜像的供应商提供registry private registry 通过舍友防火墙和额外的安全层的私有实体提供的registry repository及indexrepository 由某种特定的docker镜像的所有迭代版本组成的镜像仓库 一个registry中可以存在多个repository repository 可以为”顶层仓库”和“用户仓库” 用户仓库名称格式”用户名/仓库名” 每个仓库可以包含多个Tag，每个标签对应一个镜像 index 维护用户账号,镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 镜像相关操作主要介绍镜像如何生成，和如何推送镜像至仓库 镜像生成方式:​ 有三种方式：基于容器方式，Dockerfile方式，Docker Hub Automated Builds 基于容器制作镜像:1234567891011121314151617181920docker run --name web1 -it busybox &gt;mkdir -p /data/www/ &gt;echo "&lt;h1&gt;welcome busybox http server&lt;/h1&gt;" &gt; /data/www/index.html #注意:基于容器制作镜像，容器必须处于运行状态，这里切换终端 docker commit -p web1 #commit制作镜像前需要—p暂停docker image ls #可以看到镜像制作完成（缺少tag） docker tag IMAGEID zhuxyid/busyhttp:v1 #给刚才制作的镜像打标签(可以打多个标签) docker tag zhuxyid/busyhttp:v1 zhuxyid/busyhttp:test_env #在打一个标签 docker image rm zhuxyid/busyhttp:v1 #这里只是删除一个标签，并没有删除镜像 #查看镜像启动时候运行的命令 docker inspect web1 | grep -A 5 "Cmd" #如何在制作镜像运行时执行启动命令 docker commit -a "作者:zhuxy" -c 'CMD ["/bin/httpd","-f","-h","/data/www"]' -p web1 zhuxyid/busyhttp:test_env#运行制作后的镜像 docker run --name -d webserver zhuxyid/busyhttp:test_env 基于Dockerfile制作镜像: 详见:http://blog.zhuxyid.com/2018/11/26/Dockerfile/ 推送镜像推送到官方首先需要有hub.docker.com账号 ，hub.docker.com需要先建立好repositories 示例：这里的是zhuxyid/busyhttp命名,要跟本地的镜像保持一致 12345docker login #输入账号密码才可以登录 docker push zhuxyid/busyhttp:test_env #推送制作的镜像docker logout 推送到阿里云需要修改docker配置文件中的推送地址 12345678910111213141516171819#修改docker配置文件添加registry-mirrors,https://brjvf90f.mirror.aliyuncs.com为我自己的阿里云镜像仓库vi /etc/docker/daemon.json &#123; "registry-mirrors":["https://registry.docker-cn.com","https://brjvf90f.mirror.aliyuncs.com"]&#125;&#125;#重载配置文件并重启systemctl daemon-reloadsystemctl restart docker.service #阿里云创建命名空间，在创建镜像仓库 docker login --username=zhuxyid registry.cn-hangzhou.aliyuncs.com #先重命名镜像标签 docker tag imagename registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:test_env#在推送到阿里云docker push registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:version docker logout 镜像导入导出1234567#在本地导出镜像包，推送到目标机docker save -o busyhttp.gz zhuxyid/busyhttp:latest .. #可以打包多个文件 scp busyhttp.gz root@REMOTEIP:/opt#在目标机上导入推送的镜像docker load -i busyhttp.gz docker image ls Docker网络Docker安装后自动创建docker0网卡(虚拟) 网络虚拟化技术实现: OVS：Open VSwitch 开源虚拟交换 SDN：Software Defined Network 软件定义网络（需要硬件和软件支持） Docker网络接口Docker有三种网络接口： bridge，host，none，Containers 123456789docker image lsNETWORK ID NAME DRIVER SCOPE1f03c706f810 bridge bridge local75c5f8de6db4 host host local871ede94efa8 none null localbridge 桥接物理主机网卡(默认).这里是nat桥接，并不是物理桥接，如果是物理桥接,如果一个交换机下每个宿主机都有十几个容器，很容易导致广播风暴host 使用物理主机的名称空间none 不使用网络(特殊场景,有些程序不需要使用网络通信,比如自动任务不需要网络通信) docker安装后，会生成docker0，此网卡是个NAT桥，当启动容器的时候，宿主机也会生成veth*虚拟网卡，该网卡和容器内的网卡绑定，而veth*就是跟docker0相连，可以使用brctl show来查看 12345678910yum install bridge-utilsbrctl show #可以看出veth网络都是跟docker0关联bridge name bridge id STP enabled interfacesdocker0 8000.024259bff40e no veth05116c6 vethf8f26a6 iptables -t nat -vnL #查看POSTROUTING链,可以看出容器内访问其他网络都是通过MASQUERADE地址伪装方式访问Chain POSTROUTING (policy ACCEPT 54 packets, 3570 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 Docker通讯Docker中如果外部想访问内部的服务有如下三种方式: Bridge方式： 通过桥接，然后设置dnat才能被其他主机访问 Containers方式: 容器可以将6个名称空间分层: 如：docker-a和docker-b docker-a独立6个名称空间:USER,MOUNT,PID,UTS,NET,IPC docker-b独立3个名称空间:USER,MOUNT,PID,另外UTS,NET,IPC共享docker-a的 Host方式： 相当于Open container方式，只不过直接使用宿主机的UTS.NET.IPC Docker 网络相关命令指定网络类型以及端口映射123456789101112#docker run --name test -it --rm busybox:latest #运行busybox命名为test，执行完后直接删除 --network [none|bridge] #指定网络类型(默认是bridge) --hostname|-h HOSTNAME #指定主机名 --dns 114.114.114.114 #指定dns --add-host HOST:IP #设置容器hosts #映射 -p &lt;containerPort&gt; #将指定的容器端口 映射至 主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; #将容器端口containerPort 映射至 主机指定的主机端口&lt;host Port&gt; -p &lt;ip&gt;::&lt;containerPort&gt; #将指定的容器端口&lt;containerPort&gt; 映射至 主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;HostPort&gt;:&lt;containerPort&gt;#将指定容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; -P #-P暴露所有端口 Bridge1234567docker run --name test -it --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --dns 114.114.114.114 --rm busybox:latestdocker run --name webserver -p 80 -d busybox/httpd:latest #本地随机端口映射到容器的80端口docker run --name webserver -p 80:80 -d busybox/httpd:latest #本地80端口映射到容器的80端口docker port webserver #查看webserver容器端口 Containers联盟式容器是指使用某个已存在容器的网络接口的容器，接口被联盟内的各容器共享使用，因此，联盟式容器彼此间完全无隔离 #创建一个监听于80端口的http服务容器 docker run -d --it --rm -p 80:80 busybox/httpd:laster #创建一个联盟式容器 docker run --name web1 -it --rm busybox/httpd docker run --name web2 --network container:web1 -it --rm busybox/httpd #在web2中创建的文件web1看不到，因为隔离Mount名称空间，但是web1和web2的ip是一样的，因为web2共享了web1的Net名称空间 #联盟式容器彼此间 虽然 共享同一个网络名称空间，但其他名称空间如User,Mount，Pid等还是隔离的 #联盟式容器彼此间存在端口冲突的可能性，因此，通常只会在多个容器上的程序需要程序lookback接口互相通信，或对某已存在的容器的网络属性进行监控时才使用此模式的网络模型 Host 创建一个宿主机host的容器 123docker run --name webserver --network host -it --rm busybox/httpd#使用宿主机的IP，可能会郁闷，这跟直接在主机上部署个httpd服务在启动有什么不一样么？#容器，容器可以更加方便移值，直接run container就可以运行了。 Docker存储关于卷Docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层 并在镜像栈顶部 添加一个 读写层，如果运行中容器修改了现有的一个已挂载的文件，那该文件将会从 读写层下面的只读层 复制到读写层，该文件的只读版本依然存在，只是已经被读写层中该文件的副本所修改，即“写时复制(COW)”机制 注意:在IO要求高应用中，如果使用容器的话，那么效率非常低 Container: /data/web &lt; - - - - 建立绑定关系Mount - - - - &gt; Host:/container/web1/data/web 在容器写入时候，可以绕过容器内部层级关系 命名空间Mount是相互独立的,可以共享,关联到存储卷Volume，只要容器挂载存储卷.当容器被停止或者删除后,文件内容不被删除。 为什么用存储卷关闭并重启容器，其数据不受影响，但是删除容器，则数据全部丢失 存在的问题: 存储于联合文件系统中，不易于宿主机访问 容器间数据共享不便利 删除容器其数据丢失 卷的描述卷在容器初始化时候 会自动创建，由base image提供的卷中数据会于此间 完成复制 卷的初衷是独立于容器的生命周期实现数据持久化，因此删除容器时不会删除卷，也不会对哪怕未被应用的卷做垃圾回收 卷为docker提供了独立于容器的数据管理机制 可以把”镜像” 比作成静态文件，例如“程序” ，把卷类比为动态内容，例如“数据”；于是镜像可以重用，而卷可以共享 卷实现了”程序(镜像)”和“数据(卷)”分离，以及 “程序(镜像)”和“制作镜像主机”分离，用户制作镜像时无需考虑镜像运行容器所在的主机环境 卷的类型docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同 绑定挂载卷 bind mount volume: 在宿主机人工指定特定路径，在容器也人工指定特定路径，将两者绑定 容器管理卷 docker-managed volume: 宿主机不需要指定路径(docker daemon)，容器中需要指定路径，docker自动将两者绑定 如何使用卷12345678910111213141516171819docker run -v 选项docker-managed volumedocker run -it --name web1 -v /data busyboxdocker inspect -f &#123;&#123;.Mounts&#125;&#125; web1 #查看容器卷绑定关系docker run -it -v HOSTDIR:VOLUMEDIR --name web2 busyboxdocker run -it -v /data:/test --name web2 busybox #本机的data跟容器的test绑定，如果data不存在自动创建docker inspect -f &#123;&#123;.Mounts&#125;&#125; web1docker inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; web1 #获取web1下的ip地址#多个容器的卷使用同一个主机目录docker run -it --name nginx1 -v /docker/volumes/html:/data busyboxdocker run -it --name tomcat1 -v /docker/volumes/class:/data busybox#复制使用其他容器的卷，为docker run命令使用--volumes-formdocker run -it --name tomcat2 -v /docker/volumes/class:/data busyboxdocker run -it --name tomcat3 --network container:tomcat2 --volumes-from tomcat2 busybox #共享网络和卷 Docker资源限制默认情况下,系统对容器没有做任何资源限制，容器可以使用掉宿主机所有资源。 docker provides可以控制Memory，CPU， Block IO（其实只能控制内存和CPU） 依赖于Linux Capabilities 。 这里需要注意:内存是非可压缩资源，CPU可压缩资源 ​ 如何内存被进程耗尽会触发OOME直接KILL进程，而CPU没有关系 OOM在linux主机中，如果内核探测到当前宿主机没有足够内存可用(用于执行某些重要的系统功能)会抛出OOME 异常，并且kill掉某些进行保证其正常,一旦发生OOME,任何进程包括docker daemon在内,都有可能杀死。因此docker特地调整 docker daemon的OOM优先级，以免它被内核”杀死”，但容器的优先级并未被调整 。 优先级越低，得分越低，通常检测oom-adj，分数越高越容易被kill 不重要的业务建议oom-adj默认值，重要的调低oom-adj Memory从ram，swap两个层面: 123限制单位k,b,m,g-m | --memory 限制ram内存 -m 1g 限制ram为1g，如果后期资源占用超过1G，可能被kill掉，-m|--memory可以单独设置--memory-swap * 限制swap内存 必须先设置-m|--memory –memory-swap –memory 功能 正数S 正数M 容器可用总空间为S,其中ram为M,swap为(S-M),如果S=M，则无可用swap资源 0 正数M 相当没有设置swap(unset) unset 正数M 若主机(docker host)启用swap,则容器可用的swap为2*M 1 正数M 若主机(docker host)启用了swap,则容器可使用最大至主机上的所有swap空间的swap资源 注:在容器使用free命令可用看到swap空间并不具有 其所展现出空间的指示意义 设置–memory-swap必须大于–memory 12345--memory-swapiness 限制容器的虚拟内存控制行为0~100间整数--memory-reservation 限制预留空间大小--kernel-memory 核心内存的限制--oom-kill-disable 如果容器重要，禁止oom被kill掉--oom-score-adj 容器被OOM killer杀死的优先级，范围[-1000,1000]默认为0 CPU默认情况下每个容器，可以使用CPU的资源.大多数系统，系统在调度时候使用CFS调度 (CFS完全公平调度器) 在docker1.13后，可以设置实时调度 1234567--cpus=&lt;value&gt; #设置CPU使用几核心，如果容器只设置了--cpus = 2，那么该容器只能使用200%的cpu--cpu-period=&lt;value&gt; #最多使用多长时间--cpu-quota=&lt;value&gt; #指定周期内--cpuset-cpus #设置容器只能运行在那核心CPU上,如果4核心这里是0~3 如果上面设置--cpus=2 --cpuset-cpus 1,2 意思是使用2核心，只在cpu2和cpu3上面使用--cpu-shares #设置cpu权重，按比例切分，默认权重是1024，CPU是资源共享(因为可以压缩)，只有在系统cpu繁忙时候才体现出来，比如1核心的CPU，两个容器，其中一个A容器设置1024，另一个B设置512，当cpu都需要使用cpu的时候，就按比例分2:1(a是b的两倍) (a使用66% b使用33%)#当512的权重空闲的时候，1024的容器可以吃掉所有CPU。#如果3核心CPU，三个容器，a设置2048，b设置512，c设置1024，当三个都繁忙的时候比例是(4:1:2) (a使用56%,b使用14%,c使用28%) docekr-stress-ng压缩1234567docker run --rm lorel/docker-stress-ng --helpdocker run --name stree1 -it --rm -m 256 lorel/docker-stressng --vm 2docker run --name stree2 -it --rm -cpus 2 lorel/docker-stress-ng --cpu 8docker run --name stree2 -it --rm --cpu-shares 1024 lorel/docker-stress-ng --cpu 8docker top stree1 查看stree1的进程运行情况docker stats 查看容器状态 小结 这些主要是针对CentOS7.4，对于其他平台或者版本可能实现方式略有不同。 如：在macOS下面对于 网络 和 卷 都有不同的地方。 网络在macOS中没有docker0桥，无法ping通容器，只能使用-P 或者-p映射端口的形式访问容器，或者通过host.docker.internal特殊DNS，解析为主机使用的内部IP地址。 卷的话如果要绑定User以外的目录，则需要修改权限让容器内部可以访问该目录，不然直接挂载会提示权限不足情况 暂时遇到这么多，感谢志哥让我遇到这么多坑。 主要是讲解一下Docker基础方面，后期的Dockerfile和Docker Registry在慢慢总结，如果本文有错误，还请大牛指出，谢谢:)]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
