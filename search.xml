<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Ansible]]></title>
    <url>%2F2018%2F12%2F12%2FAnsible%2F</url>
    <content type="text"><![CDATA[前言 早期我们运维工作大致工作如下： 系统安装（虚拟机，物理机） 程序包安装，配置，维护 业务程序包发布，回滚 监控（服务，端口，配置等各项指标） 这几类工作如果只是靠人去做，那就很繁琐。如果规模不大，可以通过人去做，但是也会产生一些误操作。 规模大的情况下，靠人肉去运维那么就会是中灾难。比如数百台虚拟机如何安装？数千个服务如何部署？业务发布如何发布？监控怎么去监控？ 很多开源软件已经实现了此类重复性的工作： 操作系统安装： 物理机：Cobbler(PXE) 虚拟机：Image Template(镜像模板) 批量部署： Puppet：Ruby开发，工作于master/agent， Chef：Ruby开发 Saltstack：Python开发 Ansible：Python开发 程序发布类： Capistrano：Ruby开发 fabric：Python开发 func：Python开发 监控类： Zabbix：服务端C开发，WEB端php Nagios&amp;Cacti 在业务发布时主要注意几点： 发布过程（预发布验证）：新版本代码发布到服务器（跟生产环境配置完全相同，只是未接入调度器。 在此期间不能影响用户体验，不能停机，不能导致系统故障或者系统完全不相同。 灰度发布： 需要有三个版本，app-1.1为老版本，app-1.2为新版本，在发布只是将app指向了app-1.2，为了方便回滚 /webapp/app-1.1 /webapp/app /webapp/app-1.2 自动化灰度发布机制：（脚本/发布平台） 运维工具分类 通过Agent：比如puppet，func，saltstack，这类需要部署agent 通过Agentless：比如ansible，fabric，这类直接通过SSH（如果网络抖动通常会很慢） Ansible VS Saltstack： Ansible基于SSH协议传输，Saltstack基于ZeroMQ消息列队传输，Saltstack速度比Ansible快 Saltstack需要安装客户端，但是saltstack下的salt-ssh可以解决此类问题 Ansible通过SSH，对网络依赖性较大。 Ansible Ansible是一个运维批量配置，部署，管理系统，是实现DevOps思想的一个工具。 主要功能： 模块化，特定的模块完成特定的任务。 基于python实现，由paramiko连接至其他主机，PyYAML模块和Jinja2三个模块构建 部署简单，无需Agent，无需服务端。 支持自定义模块，支持Playbook，支持幂等性（重复执行多次）。 Ansible安装 下载安装epel源 123wget https://mirrors.tuna.tsinghua.edu.cn/centos/7/extras/x86_64/Packages/epel-release-7-11.noarch.rpm`rpm ivh epel-release-7-11.noarch.rpmyum install ca-certificates 安装ansible 1yum install python python-devel python-pip ansible 安装完成后生产文件大致如下： 123456rpm -ql ansible /etc/ansible/ansible.cf #主配置文件 /etc/ansible/hosts #主机清单 /etc/ansible/roles #角色清单 /usr/bin/ansible #ansible主程序 /usr/bin/ansible-playbook Ansible简单用法 ansible通过ssh实现配置管理，应用部署，执行任务等功能，因此实现配置ansible端基于秘钥认证方式联系各被管理节点（也可以使用在户籍清单写入账号密码，但是这种方式暴露密码不安全） 12345678910111213141516171819202122232425262728#ansible基本语法： ansible &lt;host-pattern&gt; [-f forks] [-m module_name] [-a args] host-pattern #主机清单 -f forks #一批几个，默认五个 -m module #指定模块，默认为command -a args #参数man ansible #可查看帮助命令ansible-doc #ansible模块文档ansible-doc -l #列出ansible支持模块ansible-doc -s #指定模块名称，查找模块属性/参数#如：ansible-doc -s command #查看command模块用法#ansible基本用法：#如果想看远程主机192.168.2.163~192.168.2.165的ip可使用下面方法vi /etc/ansible/hosts[webserver]192.168.2.163192.168.2.164192.168.2.165ansible 192.168.2.163 -m command -a 'ifconfig'ansible webserver -m command -a 'ifconfig'#简写ansible webserver -a 'ifconfig' Ansible常用模块ping模块12ansible webserver -m ping#测试webserver组内主机网络是否正常 user模块12345678910111213141516ansible-doc -s user#查看帮助ansible webserver -m user -a 'name=USERNAME state=&#123;present|absent&#125; system='#示例：ansible webserver -m user -a 'name=zhuxy state=persent'#在webserver组内主机添加zhuxy用户ansible webserver -m user -a 'name=zhuxy state=absent'#删除用户ansible webserver -m user -a 'name=zhuxy state=persent system=yes'#创建系统用户，默认没有system=yesansible webserver -m user -a 'name=zhuxy state=persent system=yes home=/home/zhuxy'#创建用户，指定家目录/home/zhuxy group模块1234ansible-doc -s groupansible -m group -a 'name=sadmin gid=500 system=&#123;persent|absent&#125;'#指定组名，指定组id，类似user模块 crond模块12345678910111213141516ansible-doc -s cron name #指定任务名称 job #指定任务 minute #分 hour #时 day #天 month #月 weekday #星期 state=&#123;persent|absent&#125; #添加或者删除#示例：ansible webserver -m cron -a 'name=sync time from ntpserver" minute="*/10" job="/sbin/ntpdate 192.168.2.1 &amp;&gt;/dev/null"'#每十分钟执行ntpdate 192.168.2.1ansible webserver -m cron -a '"name=sync time from ntpserver" state=absent'#删除名称为sync time from ntpserver名称定时任务 copy模块1234567891011ansible-doc -s copy dest #目标路径 src #源路径 directory_mode #递归赋值，为目录设置权限 mode=xxx group #属组 follow #是否复制链接文件#示例:ansible webserver -m copy -a 'src=/etc/fatab dest=/tmp/fstab.tmp mode=600'#复制本地文件/etc/fstab到webserver组内组件/tmp/fstab.tmp下,权限为600 file模块12345678910111213141516ansible-doc -s file path #远程路径 state #指定类型&#123;file|directory|links|hard|touch|absent|persent&#125; src #如果是links必须指明源文件 force #force=yes 如果links的文件不存在也创建 #示例：ansible webserver -m file -a 'path=/tmp/testdir state=directory'#在webserver组中创建目录/tmp/testdiransible webserver -m file -a 'path=/tmp/testing state=links src=/etc/fstab'#将webserver组中创建连接文件/tmp/testing源文件为/etc/fstab，这里的源文件值的是webserver组里面的文件ansible webserver -m file -a 'path=/tmp/testing state=links src=/etc/fstab1 force=yes'ansible webserver -m file -a 'path=/tmp/testing force=yes state=absent'#不管连接文件是否存在都删除 yum模块1234567ansible-doc -s yum conf_file #指定yum文件 name #yum包名称，可指定多个name安装多文件 state #persent|installed|latest或者absent|reoved #示例:ansible webserver -m yum -a "name=nginx state=installed" service模块1234567ansible-doc -s service name #指定启动服务名称 state #执行状态&#123;started|stopped|restarted&#125; enable #是否开启启动yes|true#示例ansible webserver -m service -a 'name=nginx state=started enable=yes' shell模块12345678ansible-doc -s shell#示例ansible webserver -m command -a "useradd zhuxyid"#这里可以通过-m command创建，但是如果设置密码怎么办？-m command不能识别管道ansible webserver -m shell -a "echo 'helloworld' | passwd --stdin zhuxyid"#通过-m shell，可以设置密码 script模块1234567891011ansible-doc -s script#示例ansible webserver -m script -a 'PATH'more /opt/test.sh#!/bin/bashecho "$(hostname) ansible is god" &gt; /tmp/ansible.logansible webserver -m script -a '/opt/test.sh'#这里需要注意，枝江将本地/opt/test.sh 传送webserver执行，test.sh无需执行权限 setup模块1234567891011ansible-doc -s setup示例:ansible webserver -m setup#查看所有主机信息ansible webserver -m setup -a "filter=ansible_default_ipv4"#查看webserver组ipansible webserver -m setup -a "filter=ansible_memory_mb"#收集内存 playbookplaybook核心元素如下 12345Tasks #任务Variables #变量Templates #模板Handlers #触发Roles #角色 playbook使用YAML编写 YAML格式如下: 12345678---- name: deploy web server user: foouser sudo: True host: all tasks: - name: install httpd - yum: name=nginx state=latest]]></content>
      <categories>
        <category>Automation Service</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML-2.DIV+CSS]]></title>
    <url>%2F2018%2F12%2F12%2FHTML-2-DIV-CSS%2F</url>
    <content type="text"><![CDATA[CSS （Cascading Style Sheets）层叠样式表。用于控制网页数据的表现，实现网页的表现与数据内容分离 通过（标签选择器）找到标签。 通过（element）操作标签对象。 CSS引入方式行内式 行内式是标记的style属性中设定的css样式，这种方式没有体现出CSS优势，不推荐使用 CSS很多的时候，如果全写在行内的话，耦合性过强 实例： &lt;p style=&quot;background-color:red&quot;&gt;this is p title&lt;/p&gt; 导入式 在其他文件写好CSS文件，然后使用@import导入样式。 导入式属于CSS代码范畴，数量有限制，有顺序，从上往下，如果文件大，则导入慢。通常用的也不多 实例： 新建test.css文件 12345h1 &#123; background-color: red; color:white; font-size:2px&#125; 在&lt;head&gt;标签中导入 123456&lt;head&gt; &lt;style&gt;@import "/path/test.css";&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;this is h1 title&lt;/h1&gt;&lt;/body&gt; 链接式 类似导入式，在&lt;head&gt;中使用&lt;link&gt;引入样式 链接式属于HTML代码范畴，不限引入次数，通常用于第三方css样式 实例： 新建test.css文件 在&lt;head&gt;中引入 1234567&lt;head&gt; &lt;link href="/path/test.css" rel="stylesheet"&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;this is h1 title&lt;/h1&gt;&lt;/body&gt;#href指定css路径，rel告知游览器是个css文件stylesheet层叠样式 嵌入式 嵌入式就是将css样式集中写在网页中的&lt;head&gt;标签下 示例： 1234567891011121314&lt;head&gt; p&#123; background-color: red; color: green; font-size: 40px; &#125; a&#123; text-decoration: none; &#125;&lt;/head&gt;&lt;body&gt; &lt;p&gt;this is p tilte&lt;/p&gt; &lt;a href="www.zhuxyid.com"&gt;zhuxyid&lt;/a&gt;&lt;/body&gt; CSS选择器 css选择器（selector） 选择器指明{ } 中的“样式”作用对象，也就是”样式”作用于网页中的那些元素 基本选择器1234* 普通元素选择器，匹配任何元素E 标签选择器，匹配任何使用E标签的元素element#id id选择器，style里面需要加#id，这里是唯一idclass class选择器，style需要加classname来调用，class用的最多 基本选择器示例 123456789101112131415161718192021222324252627282930&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;css选择器&lt;/title&gt; &lt;style&gt; *&#123; #通用，所有 color:red; &#125; p&#123; #标签选择，凡是p标签 color:red; &#125; #url &#123; #id选择 color:red; &#125; #sina &#123; color:red; &#125; .ppp&#123; #class标签 color:red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;lalal&lt;/p&gt;&lt;div&gt;lalal&lt;/div&gt;&lt;br&gt;&lt;a id='url' href="www.baidu.com"&gt;baidu&lt;/a&gt; #id名称唯一，这里url其他地方则不能使用&lt;br&gt;&lt;a id='sina' href="www.sina.com"&gt;sina&lt;/a&gt;&lt;p class="ppp"&gt;噗噗噗&lt;/p&gt;&lt;/body&gt; 组合选择器123456E,F 多元素选择器，同时匹配E元素或者F元素，E和F之间用逗号分隔E F 后代元素选择器，匹配素有属于E元素后代的F元素，E和F之间空格分隔，这里查找后代，包含子代，孙子代E&gt;F 子元素选择器，匹配所有E元素的子元素F，这里只匹配儿子带E+F 毗邻元素选择器，匹配所有紧随E元素之后的同级元素F通常E,F 和 E F用的较多 嵌套规则 1234块级元素可以包含内联元素或某些块级元素，但内联元素不能包含块级元素，他只能包含其他内联元素注意:有几个特殊的块级元素只能包含内联元素，不能包含块级元素 如h1~h6,p,dtli内可以包含div块级元素与块级元素并列，内联元素与内联元素并列 组合选择器示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546通常E,F 和E F 用的多&lt;head&gt; &lt;style&gt; div &#123; color:green; &lt;!--将div标签颜色换成green--&gt; &#125; div.id&#123; &lt;!--将div的class为id的颜色换成red--&gt; color:red; &#125; #id,div.id&#123; &lt;!--将id为id和div的class为id的颜色换成salmon--&gt; color:salmon; &#125; div,p&#123; &lt;!--将div和p标签都颜色换成aquamorine--&gt; color:aquamarine; &#125; .div1 .div2&#123; &lt;!--匹配class为div1的下的div2颜色换成red，这里在嵌套中体现--&gt; color:red; &#125; .div1 .div2&gt;p&#123; &lt;!--匹配class为div1下的class为div2的p标签--&gt; color: red; &#125; .div3 + div&#123; &lt;!--匹配class=div3后div设置颜色为red，如果class为div3的后面有其他标签，那么则不生效--&gt; color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="id"&gt;div id&lt;/div&gt;&lt;div class="name"&gt;div name&lt;/div&gt;&lt;p id="id"&gt;p id&lt;/p&gt;&lt;h6&gt;标题&lt;/h6&gt;&lt;div class="div1"&gt;div1 &lt;div class="div2"&gt;div2 &lt;a href="www.baidu.com"&gt;baidu&lt;/a&gt;&lt;br&gt; &lt;div&gt;div&lt;/div&gt; &lt;p&gt;p&lt;/p&gt; &lt;div class="div4&gt;&lt;p&gt;pp&lt;/ppp&gt;&lt;/div&gt; &lt;/div&gt; &lt;p&gt;ppp&lt;/p&gt; &lt;div class="div3"&gt;div3 &lt;/div&gt;&lt;/div&gt;&lt;div class='div4'&gt;div4444 &lt;/div&gt;&lt;div&gt;div&lt;/div&gt;&lt;div&gt;divvvv&lt;/div&gt; 属性选择器1234567[attr] #属性为attr[attr=value] #属性为attr值为valuediv[attr=value] #div标签的attr值为value[attr~=value] #取多个attr中的一个value[attr^=value] #attr属性必须开头为value[attr$=value] #attr属性必须为结尾的value[attr*=value] #attr属性为*value都可以 属性选择器示例 1234567891011121314151617181920212223242526272829&lt;head&gt; &lt;style&gt; [zhuxy] &#123; &lt;!--属性为zhuxy的设置颜色为red--&gt; color:red; &#125; [zhuxy="hello"] &#123; &lt;!--属性为zhuxy并且值为hello设置颜色为red--&gt; color:red; &#125; p[zhuxy] &#123; &lt;!--p标签的zhuxy属性设置颜色为red--&gt; color:red; &#125; [zhuxy~="sb"] &#123; &lt;!--zhuxy属性取一个sb值，这里zhuxy中有多个值--&gt; color:red; &#125; [zhuxy^="sdg"] &#123; color:red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;div1&lt;/div&gt;&lt;div zhuxy="shuaige"&gt;div2&lt;/div&gt;&lt;div zhuxy="cool"&gt;div3&lt;/div&gt;&lt;div zhuxy="hello"&gt;div4&lt;/div&gt;&lt;p zhuxy&gt;pppp&lt;/p&gt;&lt;div zhuxy="sb sdg"&gt;div5&lt;/div&gt; &lt;!--这里的sb能找到他，sdg也能找到他--&gt;&lt;div zhuxy="sdg sb"&gt;div5&lt;/div&gt;&lt;/body&gt; CSS伪类1234link 点击前显示的颜色visited 点击后显示的颜色hover 鼠标触摸时的颜色active 鼠标点击时的颜色 CSS伪类示例 12345678910111213141516171819&lt;head&gt; &lt;style&gt; a:link &#123; color:red; &#125; a:visited &#123; color:blue; &#125; a:hover &#123; color:green; &#125; a:active &#123; color:yellow; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;a href="www.zhuxyid.com"&gt;zhuxyid&lt;/a&gt;&lt;/body&gt; CSS优先级 通常优先级顺序如下： 行内式(style) &gt; id &gt; class &gt; div &gt; * style优先级：1000 id 优先级：100 class优先级：10 div优先级：1 示例1 123456789101112131415161718192021&lt;head&gt; &lt;style&gt; .div1 &#123; color:red; &#125; #id1 &#123; color:yellow; &#125; div &#123; color:green; &#125; * &#123; color:blue; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="id1" class="div1" style="color:salmon"&gt;优先级&lt;/div&gt;&lt;/body&gt; 示例2 123456789101112131415161718192021222324252627&lt;head&gt; &lt;style&gt; .div1&#123; color: red; &#125; .div2&#123; color: blue; &#125; .div3&#123; &lt;!--这里class为10--&gt; color: red; &#125; .div1.div3&#123; &lt;!--这里两个class，那就是这里优先级高--&gt; color: green; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="div1"&gt;div1 &lt;div class="div2"&gt;div2 &lt;div class="div3"&gt;div3 &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 如果加 important 就不属于优先级，直接用important属性 12345&lt;style&gt; .div &#123; color:red!important &lt;!--优先级最高--&gt; &#125;&lt;/style&gt; 优先级总结 文内样式优先级为1000 ,所以优先级高于外部定义。 这里文内样式执行 如&lt;div style=&quot;color:red&quot;&gt;blah&lt;/div&gt;的样式，而外部定义指定由&lt;link&gt;或者&lt;style&gt;卷标定义的规则 有!important声明规则高于一切 如果!important声明冲突，则比较优先级 如果优先级一样，则按照在源码中出现的顺序决定，后来者居上 由继承而得到的样式没有specificity的计算，他低于一切其他规则，比如全局选择符*定义的规则 CSS继承 继承是css一个主要特性，它是依赖于祖先-后代的关系。继承是一种机制，它允许样式不仅可以应用于某个特定的元素 它可以应用于它的后代，例如一个BODY定义了的颜色值也会应用到段落的文本中 示例： 1234567891011121314151617181920212223242526&lt;head&gt; &lt;style&gt; body &#123; color:red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;hello&lt;/p&gt;&lt;/body&gt;&lt;!--这段文字都继承了由`body color:red；样式定义的颜色，然而css继承性的权重是非常低的，是比普通元素的权重要到低的0--&gt;&lt;style&gt; body &#123; color: red; &#125; p &#123; color:green; &#125;&lt;/style&gt;&lt;body&gt; &lt;p&gt;hello&lt;/p&gt;&lt;/body&gt;&lt;!--发现只需加个颜色值就能覆盖掉它继承的样式颜色，由此可见;任何显示什么的规则都可以覆盖其他继承样式此外继承是css重要一部分，我们不需要考虑为什么能这样，但css继承也是有限制的，有些属性不能被继承如border,margin,padding,backgroud等不能被继承--&gt; CSS属性颜色属性1234style=color:red;style=color:#ffee33style=color:rgb(255,0,0) #红绿蓝style=color:rgba(255,0,0,0.5) #红绿蓝 透明 字体属性12345font-size:20px|50%|larger #大小font-family:&apos;lucida Bright&apos; #字体font-weight:lighter|bold|border #细|粗|正常font-style:oblique #字体风格,斜体..&lt;h1 style=&quot;font-style: oblique&quot;&gt;&lt;/h1&gt; 背景颜色属性12345background-color:red #背景颜色background-img:url(&apos;PATH/namg.jpg&apos;) #设置背景图片background-repeat:no-repeat #不平铺满，默认是repeat 铺满,repeat-x 横向铺满,repeat-y 纵向铺满background-position:top left #顶部左边|center center|中部中部 botton right|底部右边 或者(x% y%) 或者(xpx,ypx)background:red no-repeat top left url(&apos;PATH/name.jpg&apos;) #可以直接定义上面三个 文本属性12345678font-size: 10px; #字体大小text-align: center: #横向排列line-height: 200px; #文本行高,文字高度加上 上下文的空白区域高度，基于字体大小百分比vertical-align: -4px; #设置元素内容的垂直对其方式，只对行内元素有效，对块级无效text-indent: 150px; #首行缩进letter-spacing: 10px #字符之间空隙10pxword-apacing: 20px #单词于单词之间距离text-transform: capitalize; #单词首字母大写 capitalize|lower 边框属性1234567border-style:solid; #边框风格solid直线，dashed虚线，none无(默认)dotted点边框,groove凹槽边框，ridge垄装，inherit继承border-color:charreuse; #边框颜色border-width:20px #边框大小border-bootom-width #下边框 border-top-width上边框 border-left-width左边框 border-right-width有边框#可以简写成border:solid chartreuse 20px; 列表属性12list-style-type:none #无标记 disc 实心圆 circle空心圆 square实心方块 decimal实心数字....list-style-image:url #图像列表标记 none无图像 inherit继承 display属性1234display:none 层不显示,用的很多display:block 块状显示，在元素后面换行,显示下一个块元素 用于内元素转换块元素display:inline 内联显示，多个块可以显示在一行内 用于块元素转换内元素display:inline-block 既有内联属性，又有块级属性 DIV &lt;div&gt;在整个HTML标记中，没有任何意义，它的存在只是为了引用CSS样式，有一个叫&lt;span&gt;也是类似 不过&lt;span&gt;是内联元素，&lt;div&gt;是块级元素 示例1234567891011121314151617&lt;html&gt;&lt;head&gt; &lt;title&gt;div+css布局(div+span) &amp;copy;&lt;/title&gt; &lt;meta charset="utf-8"&gt; &lt;style type=""&gt; div&#123; background-color:RGB(0,0,0); color:RGB(0,255,0)&#125; span&#123; background-color:RGB(0,0,0); color:RGB(0,255,0) &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt;python 学习 div&lt;/div&gt; &lt;div&gt;python 学习 div&lt;/div&gt; &lt;hr&gt; &lt;span&gt;python 学习 span&lt;/span&gt; &lt;span&gt;python 学习 span&lt;/span&gt;&lt;/body&gt;&lt;/html&gt; 盒子模型 盒子模型 1234margin 外边距，控制元素与元素之间距离,margin的最基本用途就是控制元素周边空间的间隔，从视觉上达到相互隔开的目的padding 用于控制内容与边框之间的距离border 边框围绕在内边距和内容外的宽度content 内容，盒子的内容，显示文本图像 盒子属性12height 盒子高度width 盒子宽度 margin 外边距属性12345678910margin-leftmargin-bottonmargin-rightmargin-top#可以简写margin: 10px 20px 30px 40px; 上，右，下，左margin: 10px 20px 30px; 上，右左，下margin: 10px 20px; 上下，左右margin: 10px 上下左右都是10px border 内边距属性1234567padding-leftpadding-bottonpadding-rightpadding-top简写可以设置同上padding: 10px 20px 30px 40px 示例12345678910111213141516171819&lt;style&gt; .div1 &#123; width:100px; height:100px; background-color:antiquewhite; border:20px solid red; padding-left: 20px; margin-bottom:20px; opacity:100;&lt;!--透明度--&gt; &#125; .div2 &#123; width:100px; height:100px; background-color: lightblue; border:1px solid orangered; margin-top:40px; &lt;--如果div1设置20px，div2设置40px,name他们直接距离多少？40px，谁的值大,以谁为准--&gt; &#125;&lt;/style&gt; margin collapse margin collapse边界塌陷或者说边界重叠 外边距的重叠只产生在普通流文档的上下外边距之间，这个看起来有点奇怪的规则，其实有其现实意义。 设想，当我们上下排列一系列规则的块级元素（如段落P）时，那么块元素之间因为外边距重叠的存在，段落之间就不会产生双倍的距离。又比如停车场 兄弟div：上面div的margin-bottom和下面div的margin-top会塌陷，也就是会取上下两者margin里最大值作为显示值 父子div：如果父级div中没有 border，padding，inline content(文本)，子级div的margin会一直向上找，直到找到某个标签包括border，padding，inline content中的其中一个，然后按此div 进行margin，当然如果border为0px，或者inline content是空字符也不行 float属性block和inline对比 block：块级元素 block元素通常被显示为独立的一块，独占一行，多个block元素会各自新起一行，默认block元素宽度自动填充满父元素宽度,block元素可以设置width，height，margin，padding属性 常见块级元素有&lt;div&gt; &lt;form&gt; &lt;p&gt; &lt;pre&gt; &lt;h1~h5&gt; &lt;dl&gt; &lt;ol&gt; &lt;ul&gt;等 inline：内联元素 inline元素不独占一行，多个相邻的行内元素会排列在同一行，知道一行排列不下，才会新换一行，其宽度随元素的内容而变化， inline元素设置width,height无效,inline元素的margin和padding属性，水平方向的padding-left,padding-right,margin-left,margin-right都会产生边距效果 但是竖向的padding-top，padding-bottom，margin-top，margin-botton不会产生效果 常见内联元素有&lt;a&gt; &lt;span&gt; &lt;strong&gt; &lt;em&gt; &lt;lable&gt; &lt;input&gt; &lt;select&gt; &lt;textarea&gt; &lt;img&gt; &lt;br&gt;等 文档流和脱离文档流 所谓文档流，值得是元素排版布局过程中，元素会自动从左往右，从上往下流式排列 脱离文档流，也就是将元素从普通的布局排版中拿走，其他盒子在定位的时候，会当做脱离文档流的元素不存在而定位 只有绝对定位absolute和浮动float才会脱离文档流。 ​ 部分无视和完全无视的区别?需要注意的是,使用float脱离文档流时,其他盒子会无视这个元素，但其他盒子内的文本依然会为这个元素让出位置，环绕在周围(可以说是部分无视) ​ 对于使用absolute postition脱离文档流的元素，其他盒子与其他盒子内的文本都会无视他(完全无视) 浮动的表现 浮动的框可以向左向右移动，知道他的外边缘碰到包含框 或 另一个浮动框 的边框位置，由于浮动框不在文档的普通流中，所以文档的普通流中的浮动框之后的块框 表现的就像浮动框不存在一样(注意这里是块框，不是内联元素；浮动框只对她后面的元素造成影响) 当初float被设计的时候就是用来完成文本环绕效果，所以文本不会被挡住，这里float的特性，即float是一种不彻底的脱离文档流方式，无论多么复杂的布局，其基本出发点均是:”如何在一行显示多个div元素” 浮动清除 清楚浮动 123456789clear语法clear:none 默认值，允许两边都可以有浮动clear:left 不允许左边有浮动对象clear:right 不允许右边有浮动对象clear:both 不允许有浮动对象注意:1.clear属性只对自身起作用，而不会影响其他元素，2.如果一个元素的右侧有一浮动对象，而这个元素设置了不允许右边有浮动对象，即clear:right，则这个元素会自动下移一格，达到本元素右边没有浮动对象的目的。 浮动示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;float&lt;/title&gt; &lt;style&gt; /*a&#123;*/ /*padding-left: 40px;*/ /*margin-left: 20px;*/ /*&#125;*/ .div1 &#123; width:100px; height: 100px; background-color: red; float:left; &#125; .div2 &#123; width:200px; height: 100px; background-color: blue; float:left; clear:left; &#125; .div3 &#123; width:100px; height: 200px; background-color: green; float:left; &#125; .div4 &#123; width:200px; height: 200px; background-color: yellow; float:left; clear:left; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class=&quot;div1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;div2&quot;&gt;&lt;/div&gt; &lt;div class=&quot;div3&quot;&gt;&lt;/div&gt; &lt;div class=&quot;div4&quot;&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; postition属性position定位属性 static 默认值，无定位 relative 相对定位 absolute 绝对定位 fixed 固定定位 属性说明1234567891011121314static#默认值，无定位，不能当做绝对定位参照物体，并且设置标签对象的left，top不起作用relative#relative相对定位，相对定位是相对于该元素在文档流中的原始位置，索引自己原始位置作为参照物,有趣的是 即使设定了元素的相对定位以及偏移值，元素还占有原来的位置，即占据文档流的空间#对象遵循正常文档流，但将依据top，right，bottom，left等属性在正常文档流中偏移位置，而其层叠通过z-index属性定义absolute#绝对定位，设置为绝对定位的元素框从文档流完全删除，并相对最近的已定位祖先元素定位，如果元素没有已定义的祖先元素，那么他的位置相对最初的包含快即(body元素)#元素原先在正常文档流中所占用的空间会关闭，就像该元素原来不存在一样，元素定位后生成一个块级框，而不论原来他正常流生成任何类型的框fixed#固定定位，对象脱离正常文档流，使用top,right,bottom,left等属性以窗口为参考点进行定位，当出现滚动条时，对象不会随着滚动。#而其层叠通过z-index属性定义，注意:一个元素若设置position:absolute|fixed;则该元素就不能设置float，这是一个常识性的只是，因为这两个不同流，一个浮动流，一个是"定位流",但是relative却可以，因为他原本所占用空间仍然占据文档流 注意 仅使用margin属性布局绝对定位元素 此情况，margin-bottom 和margin-right的值不再对文档流中的元素产生影响，因为该元素已经脱离了文档流。 另外，不管它的祖先元素有没有定位，都是以文档流中原来所在的位置上偏移参照物]]></content>
      <categories>
        <category>Front Basic</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML-1.基础]]></title>
    <url>%2F2018%2F12%2F11%2FHTML-1-%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[HTML（Htyper Text Markup Language）超文本标记语言 超文本：就是指页面可以包含图片，连接，音乐，程序等非文字元素 标记语言：标记(标签)构成语言，凡是用&lt;&gt;标记的都是标签语言 网页就是HTML文档，由游览器解析，用来展示的 静态页面：静态资源，用xxx.html 动态页面：html代码由某种开发语言根据用户请求动态生成 HTML文档结构： 根元素html—&gt;html元素—&gt;{meta元素，title元素} 根元素html—&gt;body元素—&gt;{div元素} HTML基本语法结构12345678910&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 注意: &lt;!DOCTYPE html&gt;标签 表示标准模式渲染,W3C标准 渲染模式有两种：BackCompat，CSS1Compat。 BackCompat：怪异模式，游览器使用自身怪异模式解析渲染 CSS1Compat：标准模式，游览器使用W3C标准解析渲染页面 如果页面没有DOCTYPE声明，那么compatMode默认就是BackCompat 在html使用&lt;script&gt;alert(window.top.document.compatMode)&lt;/script&gt;来查看当前游览器渲染模式 HTML标签 表示标签，通常标签不区分大小写。 标签分为两部分（开始标签 和结束标签），两个标签之间的部分叫标签体。 有些标签功能简单，使用一个标签就可以，叫自闭合标签。如&lt;br/&gt; &lt;hr/&gt; &lt;input/&gt; &lt;img/&gt;。 标签可以嵌套，但不能交叉嵌套。如&lt;a&gt;&lt;b&gt;&lt;/a&gt;&lt;/b&gt;这样是错误的，&lt;a&gt;&lt;b&gt;&lt;/b&gt;&lt;/a&gt;这样才正确。 HTML属性 通常是键值对 形式出现，如name=’zhuxy’ 属性只能出现在开始标签，或自闭合标签中 属性名字全部小写，”属性值” 必须使用双引号或单引号 如：name=”zhuxy”，name=’server’ 如果属性值和属性名一样，直接写属性名就可以。如：readonly=readonly ===&gt; readonly 属性通常有自定义属性，和内在属性 基本标签&lt;head&gt;标签 通常这个标签只是解释性标签，不做显示用。 &lt;meta&gt;标签 &lt;meta&gt;标签组成有两个属性分别是name属性和http-equiv属性 name属性：主要用于描述页面与之对应的属性为content，content内容主要便于搜索引擎机器人查找信息和分类信息用 例子： &lt;meta name=&#39;keywords&#39; content=&#39;meta总结，html meta，meta属性，meta跳转&#39;&gt; 主要是用于搜索后出来的描述信息 http-equiv属性：相当于http文件头作用，它像游览器传回一些有用信息，以帮助正确和精确显示网页内容，属性值也是content 例子： &lt;meta http-equiv=&quot;Refresh&quot; content=&quot;2;URL=https://www.baidu.com&quot;&gt; 刷新属性，2秒后刷新到百度，如果没有URL表示2秒刷新 例子: &lt;meta http-equiv=&quot;content-Type&quot; charset=&quot;UTF8&quot;&gt;可以简写成&lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=EmulateIE7&quot;&gt; 如果想适应IE7 就可以兼容IE7 &lt;title&gt;标签 用于游览器显示的标题。 例子： 123&lt;link rel="icon" href="http://www.zhuxyid.com/favicon.ico"&gt; #引入图标&lt;link rel="stylesheet" href="css.css"&gt; #引入css&lt;script src="hello.js"&gt;&lt;/script&gt; #引入js &lt;body&gt;标签 显示正文信息，在body里面定义的都可以在页面上显示。 其他标签123456789101112&lt;hN&gt; #h1~h6 表示标题&lt;b&gt;&lt;strong&gt; #加粗标签&lt;strike&gt; #删除线&lt;em&gt; #斜体,或者&lt;i&gt;&lt;sup&gt;&lt;sub&gt; #上角标，下角标&lt;br&gt; #换行，通常就一个标签&lt;p&gt; #段落差，包裹的内容被换行,并且上下内容之间也有空白&lt;hr&gt; #水平线&lt;tt&gt; #打印字体标记&lt;cite&gt; #引用方式标记，也是斜体&lt;big&gt; #大型字体&lt;u&gt; #下划线标记 特殊字符12345678910111213141516&amp;nbsp; 空格&amp;lt; 小于 &lt;&amp;gt; 大于 &gt;&amp;amp; 和号 &amp;&amp;quot; 引号“&amp;apos; (ie不支持)撇‘&amp;cent; 分¢&amp;pound; 磅£&amp;yen; 日元￥&amp;euro; 欧元€&amp;sect; 小节§&amp;copy; 版权©&amp;reg; 注册商标®&amp;trade; 商标™&amp;times; 乘&amp;divide; 除 标签种类块级标签（block） 块级标签独占一行，如： &lt;p&gt; &lt;h1&gt; &lt;table&gt; &lt;ol&gt; &lt;ul&gt; &lt;form&gt; &lt;div&gt; 块级标签特点： 总是在新行上开始 宽带默认是他容器的100%,除非设定一个高度 可容纳内联元素和其他块元素 块可以嵌套内联和块标签 内联标签（inline） 内联标签不占，如： &lt;a&gt; &lt;input&gt; &lt;img&gt; &lt;sub&gt; &lt;sup&gt; &lt;textarea&gt; &lt;span&gt; 内联标签特点 inline(内联)元素特点 和其他元素都在一行上 宽度就是他的文字或图片的高度，不可改变 内联元素只能容纳文本或者其他内联元素 内联可以嵌套内联 常见标签&lt;img&gt;标签 通常设置图片信息，如宽度，大小，来源等信息 属性如下： 123456&gt; src #图片路径&gt; width #图片宽度 单位:px像素 %百分比(根据游览器)&gt; height #图片高度 单位同上&gt; alt #没有加载成功提示&gt; title #鼠标悬浮时提示&gt; 示例： 12&gt; &lt;img src="../file/grafana.png" alt="grafana" title="grafana1111" width="100%" height="100%"&gt;&gt; &lt;a&gt;标签 通常文字的信息，如连接，跳转方式等 属性如下 123456789101112&gt; href #要链接的资源路径&gt; target="_self" #当前游览器打开被链接文档&gt; name #定义页面书签&gt; id #表示每个标识的id，不能一样,每个标签都可以添加id&gt; id通常用于跳转 href="#id" 锚&gt; &gt; #target其他方式跳转，默认是_self，&gt; # _self 在相同的游览器打开被链接文档&gt; # _blank 在新窗口打开被链接文档&gt; # _parent 在父游览器集中打开被连接文档&gt; # _top 在整个窗口打开被连接文档&gt; 示例： 12&gt; &lt;a href="http://www.zhuxyid.com" target="_blank" name="zhuxyid" &gt;跳转zhuxyid.com&lt;/a&gt;&gt; 定义锚点： 1234&gt; &lt;a id="head" href="#tail"&gt;返回底部&lt;/a&gt;&gt; &lt;img src="../file/grafana.png" height="100000px"&gt;&gt; &lt;a id="tail" href="#head"&gt;返回顶部&lt;/a&gt;&gt; 可以嵌套，比如点击图片跳转响应页: 1234&gt; &lt;a href="http://www.zhuxyid.com" target="_blank" name="zhuxyid"&gt;&gt; &lt;img src="../file/grafana.png" alt="截图" title="grafana1111" width="100%" height="100%"&gt;&gt; &lt;/a&gt;&gt; 列表标签&lt;ul&gt;无序列表 &lt;ul&gt; (unordered list)无序列表 格式: 123456&gt;&lt;ul&gt;&gt; &lt;li&gt;标签1&lt;/li&gt;&gt; &lt;li&gt;标签2&lt;/li&gt;&gt; &lt;li&gt;标签3&lt;/li&gt;&gt;&lt;/ul&gt;&gt; &lt;ol&gt;有序列表 &lt;ol&gt; (order list)有序列表 格式 123456&gt; &lt;ol&gt;&gt; &lt;li&gt;标签1&lt;/li&gt;&gt; &lt;li&gt;标签2&lt;/li&gt;&gt; &lt;li&gt;标签3&lt;/li&gt;&gt; &lt;/ol&gt;&gt; 有序列表显示类型如下： &lt;ol type=[1|A|a|I|i]&gt; 1 阿拉伯数字1, 2, 3等，默认type A 大写字母A，B，C a 小写字母a，b，c I 大写罗马数字Ⅰ，Ⅱ，Ⅲ，Ⅳ，Ⅴ i 小写罗马数字i，ii，iii ，iv，v 列表嵌套 无序列表可以嵌套有序，有序也可以嵌套无序 1234567891011121314151617181920&lt;ul&gt; &lt;li&gt;linux运维&lt;/li&gt; &lt;ol type="1"&gt; &lt;li&gt;nginx&lt;/li&gt; &lt;ol type="a"&gt; &lt;li&gt;安装nginx&lt;/li&gt; &lt;li&gt;配置nginx&lt;/li&gt; &lt;/ol&gt; &lt;li&gt;apache&lt;/li&gt; &lt;/ol&gt; &lt;li&gt;python开发&lt;/li&gt; &lt;ol type="1"&gt; &lt;li&gt;python语法&lt;/li&gt; &lt;ol type="a"&gt; &lt;li&gt;python类型&lt;/li&gt; &lt;li&gt;python函数&lt;/li&gt; &lt;/ol&gt; &lt;li&gt;python面向对象&lt;/li&gt; &lt;/ol&gt;&lt;/ul&gt; 定义型列表 通常用对列表条目进行简短说明。 格式： 12345678910111213141516&gt; &lt;dl&gt;&gt; &lt;dt&gt;&lt;/dt&gt;&gt; &lt;dd&gt;&lt;/dd&gt;&gt; &lt;dd&gt;&lt;/dd&gt;&gt; &lt;dt&gt;&lt;/dt&gt;&gt; &lt;/dl&gt;&gt; &gt; #实例&gt; &lt;dl&gt;&gt; &lt;dt&gt;软件说明：&lt;/dt&gt;&gt; &lt;dd&gt;简单介绍软件功能1&lt;/dd&gt;&gt; &lt;dd&gt;简单介绍软件功能2&lt;/dd&gt;&gt; &lt;dt&gt;软件界面：&lt;/dt&gt;&gt; &lt;dd&gt;用于选择软件外观&lt;/dd&gt;&gt; &lt;/dl&gt;&gt; 表单标签&lt;from&gt;标签 表单标签，通常用于接受不同类型的用户输入，用户提交表单时想服务器传输数据，从而实现用户与web服务器的交互，表单标签，要提交的所有内容都应该在该标签中 表单能够包含&lt;input&gt;元素，比如文本字段，复选框，单选框，提交按钮等 表单还可以包含&lt;textarea&gt; &lt;select&gt; &lt;fieldset&gt; 和 &lt;label&gt;元素 &lt;from&gt;属性 123456789&gt; action 表单提交到哪，一般指向服务端一个程序，程序接受表单提交过来的数据(即表单元素值)，做响应处理&gt; method 表单提交方式POST/GET 默认取值就是GET&gt; enctype 上传文件&gt; #enctype="multipart/form-data" #分段上传&gt; &gt; #method方式特点:&gt; GET特点: 提交键值后放在url后面,安全性差。对提交内容有长度限制1024&gt; POST特点: 提交键值后不放在url后,安全性高。对提交内容长度不限制ls&gt; &lt;input&gt;标签 表单输入，用户输入类型有文本，密码，多选，单选，上传，提交等 &lt;input&gt;属性 123456789101112131415161718192021222324252627&gt; type #输入类型&gt; name #定义标签名称&gt; value #定义标签值(有name就有value，传入后端)&gt; placeholder #占位符，显示输入点击的内容，默认鼠标点击该标签是空白&gt; readonly #表示只读,这里是缩写形式,可以写成readonly='readonly'&gt; checked #表示默认选择,这里也是缩写形式,checked=‘checked’&gt; disabled #表示禁用，类似readonly,这样也是缩写形式&gt; &gt; #type类型如下：&gt; type = "text" #普通文本&gt; type = "password" #密码文件,输入都是以.表示&gt; type = "checkbox" #多选&gt; type = "radio" #单选&gt; type = "botton" #只是一个点击按钮，通常用作绑定一个事件&gt; type = "reset" #重置&gt; type = "submit" #提交，默认显示submit按钮，如果添加了value那就显示对应的value。&gt; type = "file" #上传文件，需要在from标签添加enctype属性，必须是post不能get形式&gt; &gt; #在django中处理文件代码如下:&gt; for item in request.FILES:&gt; fileObj = request.Files.get(item)&gt; f = open(fileObj.name,'wb')&gt; iter_file = fileObj.chunks()&gt; for i in iter_file:&gt; r.write(line)&gt; f.close()&gt; &lt;select&gt;标签 下拉框选择器，可以单选可以多选 &lt;select&gt;属性 123name #指定name，后端接受,默认是单选multiple=&apos;multiple&apos; #多选size #多选情况下显示多少个 &lt;optgroup&gt;标签 定义在&lt;select&gt;内部 属性有： 12&gt; label #定义一个名称&gt; &lt;option&gt;标签 定义在&lt;select&gt;内部，&lt;select&gt;下拉的内容 属性有： 123&gt; value 指定值&gt; select 默认选中，这里是缩写，select=&quot;select&quot;&gt; &lt;textarea&gt;标签 定义一个文本域 属性有: 1234&gt; name 表单提交的键&gt; cols 文本域默认多少列&gt; rows 文本域默认多少行&gt; 其他标签&lt;label&gt; 标签 带有两个输入字段和相关标记的简单html表单。 通常&lt;label&gt;标签为&lt;input&gt;元素定义标注，&lt;label&gt;元素不会想用户呈现效果，如果您在 label 元素内点击文本，就会触发此控件，当用户选择该标签时，浏览器就会自动将焦点转到和标签相关的表单控件上，&lt;label&gt;标签的 for 属性应当与相关元素的 id 属性相同。 12&lt;label for='www'&gt;name&lt;/label&gt;&lt;input id='www' type='text&gt; &lt;fieldset&gt;标签 一个简单的特性用的不多 1234&lt;fieldset&gt; &lt;legend&gt;&lt;/legend&gt; &lt;input type="text"&gt;&lt;/fieldset&gt; 表单示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;表单标签&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="http://127.0.0.1:8888/index/" method="POST"&gt;&lt;p&gt;注册页面&lt;/p&gt;&lt;p&gt;用户名：&lt;input type="text" name="username"&gt;&lt;/p&gt;&lt;p&gt;出生日期：&lt;input type="date" name="birthday"&gt;&lt;/p&gt;&lt;p&gt;密码： &lt;input type="password" name="password"&gt;&lt;/p&gt;&lt;p&gt;爱好：&lt;input type="checkbox" name="xh" value="yy"&gt;音乐 &lt;input type="checkbox" name="xh" value="dy"&gt;电影 &lt;input type="checkbox" name="xh" value="sf"&gt;书法 &lt;input type="checkbox" name="xh" value="ys"&gt;艺术&lt;/p&gt;&lt;p&gt;性别：&lt;input type="radio" name="gender" value="1"&gt;男 &lt;input type="radio" name="gender" value="0"&gt;女&lt;/p&gt;&lt;p&gt;年纪:&lt;input type="text" name="age" value="20"&gt; &lt;/p&gt;&lt;p&gt;上传文件:&lt;input type="file" name="put_file"&gt;&lt;/p&gt;&lt;p&gt; 省份： &lt;select name="province"&gt; &lt;option value="heib" select&gt;江苏&lt;/option&gt; &lt;option value="jiangs" select&gt;安徽&lt;/option&gt; &lt;option value="hein"&gt;河南&lt;/option&gt; &lt;option value="zhej"&gt;浙江&lt;/option&gt; &lt;/select&gt; 城市: &lt;select name="city" size="10"&gt; &lt;option value="nj" select&gt;南京&lt;/option&gt; &lt;option value="ha"&gt;淮安&lt;/option&gt; &lt;option value="cz"&gt;常州&lt;/option&gt; &lt;option value="sz"&gt;苏州&lt;/option&gt; &lt;/select&gt; 区级: &lt;select name="zone"&gt; &lt;option value="jn"&gt;江宁&lt;/option&gt; &lt;option value="qh"&gt;秦淮&lt;/option&gt; &lt;option value="xw"&gt;玄武&lt;/option&gt; &lt;option value="bx"&gt;白下&lt;/option&gt; &lt;/select&gt; 省份： &lt;select name=""&gt; &lt;optgroup label="江苏"&gt; &lt;option value=""&gt;南京&lt;/option&gt; &lt;option value=""&gt;淮安&lt;/option&gt; &lt;option value=""&gt;无锡&lt;/option&gt; &lt;option value=""&gt;苏州&lt;/option&gt; &lt;optgroup&gt; &lt;/select&gt;&lt;/p&gt;&lt;p&gt;简介:&lt;/p&gt; &lt;p&gt;&lt;textarea name="jj" cols="50" rows="10"&gt;&lt;/textarea&gt;&lt;/p&gt; &lt;label for="www"&gt;姓名&lt;/label&gt; &lt;input id="www" type="text"&gt;&lt;p&gt;&lt;input type="button" value="注册"&gt;&lt;/p&gt;&lt;p&gt;&lt;input type="reset"&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;input type="button" value="注册"&gt;&lt;/p&gt;&lt;p&gt;&lt;input type="reset"&gt;&lt;/p&gt; &lt;!--/?username=assss&amp;password=ssss&amp;xh=dy&amp;xh=sf&amp;gender=0--&gt; &lt;!--后端接受的内容--&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 表格标签&lt;table&gt;标签 通常定义一个表格。 &lt;table&gt;属性 12345&gt;border 表格边距&gt;cellpadding 表格内边距&gt;cellspacing 表格外边距&gt;width 表格宽度，默认单位为像素,width="100%"可以为百分比&gt; &lt;thead&gt;标签 通常定义表格头信息 &lt;thead&gt;属性 1234&lt;tr&gt; 表格行rowspan=&quot;2&quot; 占几行colspan=&quot;2&quot; 占几列&lt;th&gt; 加粗 &lt;tbody&gt;标签 定义表格内容 &lt;tbody&gt;属性 12&lt;tr&gt; 表格行&lt;td&gt; 普通元素 表格示例12345678910111213141516171819202122232425262728293031323334353637383940&lt;table border="1px" cellpadding="5px" cellspacing="5px"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;id&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;age&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;0001&lt;/td&gt; &lt;td colspan="2"&gt;zhuxuyue&lt;/td&gt; &lt;!--&lt;td&gt;18&lt;/td&gt;--&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--&lt;td&gt;0002&lt;/td&gt;--&gt; &lt;td&gt;ykw&lt;/td&gt; &lt;td&gt;18&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt;-----------------------简写--------------------&lt;table border="1px" cellpadding="5px" cellspacing="5px"&gt; &lt;tr&gt; &lt;th&gt;id&lt;/th&gt; &lt;th&gt;name&lt;/th&gt; &lt;th&gt;age&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan="2"&gt;0001&lt;/td&gt; &lt;td colspan="2"&gt;zhuxuyue&lt;/td&gt; &lt;!--&lt;td&gt;18&lt;/td&gt;--&gt; &lt;/tr&gt; &lt;tr&gt; &lt;!--&lt;td&gt;0002&lt;/td&gt;--&gt; &lt;td&gt;ykw&lt;/td&gt; &lt;td&gt;18&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;]]></content>
      <categories>
        <category>Front Basic</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-3.高阶函数(高级篇)]]></title>
    <url>%2F2018%2F12%2F10%2FPython-3-%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0-%E9%AB%98%E7%BA%A7%E7%AF%87-%2F</url>
    <content type="text"><![CDATA[高阶函数函数作为返回值 或者 函数作为参数 这类函数就是高阶函数。上节博文有说过闭包，递归都是属于高阶函数。 函数作为返回值：通常用作闭包的场景，需要封装一些变量，后面的面向对象会有类来封装，通常用返回作为返回值很少 函数作为参数：通常用于大多数逻辑固定，少部分逻辑不固定的场景 通常 函数作为参数 用的比 函数作为返回值 多，函数返回值封装通常用面向对象来使用 标准库中函数作为参数用的很多。 python中函数式一等对象（first class），函数也是一种对象，并且和普通对象一样赋值，作为参数作为返回值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#实例：def counter(i): base = i def inc(x=1): nonlocal base base += x return base return incinc = counter(3)inc(3)#如果实现sort排序？def sorts(it): ret = [] for i in it: for k,v in enumerate(ret): if i &gt; v: ret.insert(k,i) break else: ret.append(i) return retsorts([2,4,1,24,5,12,4,5])out&gt;[24, 12, 5, 5, 4, 4, 2, 1]#这里enumerate是指枚举，如果列表是[2,3,4,5],枚举后就是[(0,2),(1,3),(2,4),(3,5)]#第一次循环,i是2,k,v是0,0,将2插入(0,2)#第二次循环,i是4,k,v是0,2,这里4&gt;2,将0的位置给4,#第三次循环,i是1,k,v是0,4,这里就往后添加#是个逆序排序#如果想实现，需要输入参数reverse=False,就从小到大排序,reverse=True就反过来def sorts(it,reverse=True): ret = [] for i in it: for k,v in enumerate(ret): if reverse: if i&gt;v: ret.insert(k,i) break else: if i&lt;v: ret.insert(k,i) break else: ret.append(i) return ret#如果不输入reverse默认是从大到小排序sorts([1,2,3,4,5,6])#如果输入reverse=False就是从小到大排序sorts([1,2,3,4,5,6],reverse=False)##这个sorts排序并不是高阶函数，只是一个逻辑处理，如何写成高阶函数呢？def sorts(lst,cmp=lambda a,b:a&gt;b): ret = [] for i in lst: for k,v in enumerate(ret): if cmp(i,v): ret.insert(k,i) break else: ret.append(i) return retsorts([4,2,3,1,23,4,12])out&gt;[23, 12, 4, 4, 3, 2, 1]sorts([4,2,3,1,23,4,12],cmp=lambda a,b:a&lt;b)out&gt;[1, 2, 3, 4, 4, 12, 23]#这就是高阶函数。 内置函数匿名函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566def fn(x): return x+1print(fn)out&gt;&lt;function fn at 0x7f95e965bea0&gt;lambda x:x+1out&gt;&lt;function __main__.&lt;lambda&gt;(x)&gt;#函数和匿名函数调用def fn(x): return x+1fn(3)out&gt;4(lambda x:x+1)(3)out&gt;4#匿名函数#使用lambda来定义，#参数列表不需要括号#跟函数不一样，:不是用来开启新的语句块#最后一个表达式没有return(lambda x:x+1)(3)#第一个括号是定义一个匿名函数，第二个括号是函数调用f = lambda x:x+1f(3)out&gt;4#可以将匿名函数赋值给一个变量，#通过这个变量来调用这个函数#匿名函数限制#匿名函数(也叫lambda表达式)只能写一行，也叫单行函数(global不可用和nonlocal不可用)#匿名函数只有一个表达式#下面几个实例感受下lambda(lambda:0)()out&gt;0#没有参数也可以(lambda x,y:x+y)(5,3)out&gt;8#可使用位置参数(lambda x=3,y=2:x-y)()out&gt;1(lambda x=3,y=2:x-y)(5,2)out&gt;3#也可以是用默认参数lst=[1,2,3](lambda *args:args)(*lst)#可以使用可变位置参数dic=&#123;'a':1,'b':2&#125;(lambda **kwarg:kwarg)(**lst)#也可以使用可变关键字参数lst=[1,2,3]dic=&#123;'a':1,'b':2&#125;(lambda *arg,**kwargs:print(arg,kwargs))(*lst,**dic)#也可以一起使用,规则跟函数一样，参数可以解构#lambda判断(lambda x,y:x if x&lt;y else y)(1,2) 其他内置函数map123456789101112131415161718192021222324help(map) map(func, *iterables) --&gt; map object#将func应用到序列上个每一个元素上，返回一个值，不管这个序列原来是什么类型#事实上，根据函数参数多少，map可以接受多个组序列，将其对应的元素作为参数传入函数#例子[1,2,3][2,3,4]两个列表想加def fn(x,y): return x + ya = [1,2,3]b = [1,2,3]map(fn,a,b)&gt;&gt;&gt;2,4,6#map源码def map_(fn,it): return (fn(x) for x in it)#如果用lambda写会更爽a = [1,2,3]b = [1,2,3]list(map((lambda a,b:a+b),a,b)) filter12345678910111213141516help(filter) filter(function or None, iterable) --&gt; filter object #filter和map类似，filter也接受一个函数和一个序列，和map()不同的是，filter()把传入的函数依次作用每个元素，#根据返回值是ture还是false决定保留还是丢弃例子list(filter(lambda x:x%2==0,range(10)))&gt;&gt;&gt;[0,2,4,6,8]list(filter(lambda x:x and x.strip(),['a','','c’,None,'']))&gt;&gt;&gt;[‘a’,’c’]#filter源码def fiter_(fn,it): return (x for x in it if fn(x)) reduce在python3中，reduce函数从全局空间中移除，防止在了functools模块中，需要引入 reduce就是把一个函数 用在一个列表序列上，这个函数必须接受两个参数，reduce把结果继续和下一个序列的下一个元素累计运算 12345678910111213141516171819202122232425262728293031323334from tunctools import reducehelp(reduce) reduce(function, sequence[, initial])#例子#计算一个列表的和lst = [1,23,4,5,12,3]def fn(x,y): return x+yreduce(fn,lst)out&gt;48lst = [1,2,3,4,5]def fn(x,y): return x*10+yreduce(fn,lst)out&gt;12345#实例：#将字符转换成数字def fn(x,y): return x*10+ystr2num =&#123;str(x):y for x,y in enumerate(range(11))&#125;def s2n(s): return str2num[s]reduce(fn,map(s2n,'1987'))#改成lambda表达式def str2num(z): def s2n(s): dic = &#123;str(x):y for x,y in enumerate(range(11))&#125; return dic[s] return reduce((lambda x,y:x*10+y),map(s2n,z)) 装饰器 顾名思义就知道是一种装饰作用，装饰有很多种，比如计算函数时长，在函数结果前或者结果后做一些装饰。 装饰器其实只是高阶函数的一种，分为不带参数的装饰器，带参数的装饰器。 高阶函数：函数作为返回值 或者 函数作为参数 这类叫高阶函数 装饰器：函数即作为返回值 又 作为参数，这叫装饰器（装饰器的参数必须是函数，返回值必须也是函数） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#例子#如何计算一个函数执行的时长import timedef func(): time.sleep(2)def counter(fn): def inner(): start = time.time() fn() return time.time()-start return innerf = counter(func)f()out&gt;2.0002...#python提供一个语法糖@,可以这么来写def counter(fn): def inner(): start = time.time() fn() return time.time()-start return inner@counterdef func1(): time.sleep(2)func1()out&gt;2.0020...#这里的@counter相当于func1=counter(func1)#函数添加参数def counter(fn): def inner(x): start=time.time() ret = fn(x) print(time.time()-start) return ret return inner@counterdef add(x): x += 1 time.sleep(2) return xa = adda(2)2.002060651779175out&gt;3#函数添加多个参数def counter(fn): def inner(*arg): start=time.time() ret = fn(*arg) print(time.time()-start) return ret return inner@counterdef add(x,y): add = x+y time.sleep(2) return adda = adda(2,5)2.002060651779175out&gt;7#counter接受fn函数，inner接受fn函数参数，函数fn式具体实现功能，只不过函数fn被counter装饰了#这里counter接受add的函数。inner接受add参数，函数add实现了功能，不过add被counter装饰了#执行流程:首先是一层层传进去再一层层返回出来:#counter(add(2,5))===&gt;inner(2,5)===&gt;add(2,5)===&gt;inner(2,5)===&gt;counter(add(2,5))#装饰器参数，比如计算一个函数，如果超过3秒打印超时，如果没超过就显示正常import timedef logg(timeout): def counter(fn): def inner(*arg): start=time.time() ret = fn(*arg) end = time.time() if (end-start) &gt;= timeout: return '函数执行超时'.format(timeout),ret else: return ret return inner return counter@logg(2)def foo(x): time.sleep(x) return xfoo(1)out&gt;1foo(5)out&gt;('函数执行超时', 5) 总结 装饰器本质就是一个函数，接受一个函数作为参数，并返回一个函数 装饰器通常会返回一个封装函数，这个封装在传入的函数前后作一些事情 装饰器本身肯定必须是高阶函数 装饰器所装饰的函数就是装饰器所接受的参数 函数属性如何保留123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#看个简单实例:def timeit(fn): def wrap(*args,**kwargs): start = time.time() ret = fn(*args,**kwargs) print(time.time() - start) return ret return wrap@timeitdef func(x): time.sleep(x) return xfunc.__name__out&gt;'wrap'#这里发现本身func是个函数为啥这里变成了warphelp(func) wrap(*args, **kwargs)#如何保存原来的属性呢？def timeit(fn): def wrap(*args,**kwargs): start = time.time() ret = fn(*args,**kwargs) print(time.time() - start) return ret wrap.__name__ = fn.__name__ return wrap@timeitdef func(x): time.sleep(x) return xfunc.__name__out&gt;'func'help(func)#这里只是简单的改了函数__name__help(func) wrap(*args, **kwargs)#如何修改所有的属性呢？from functools import wrapsdef timeit(fn): @wraps(fn) def wrap(*args,**kwargs): start = time.time() ret = fn(*args,**kwargs) print(time.time() - start) return ret return wrap@timeitdef func(x): time.sleep(x) return xfunc.__name__func(x) 装饰器实例实现cache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354from functools import wrapsimport timedef cache(instance): def dec(fn): @wraps(fn) def wrap(*args,**kwargs): pos = ','.join((str(x) for x in args)) kw = ','.join('&#123;&#125;=&#123;&#125;'.format(k,v) for k,v in sorted(kwargs.items())) key = '&#123;&#125;::&#123;&#125;::&#123;&#125;'.format(fn.__name__,pos,kw) ret = instance.get(key) if ret is not None: return ret ret = fn(*args,**kwargs) instance.set(key,ret) return ret return wrap return decclass DictCache: def __init__(self): self.cache = dict() def get(self,key): return self.cache.get(key) def set(self,key,value): self.cache[key] = value def __str__(self): return str(self,cache) def __repr__(self): return repr(self,cache) cache_instance = DictCache()#字典保存cache@cache(cache_instance)def long_time_fun(x): time.sleep(x) return xlong_time_fun(3)out&gt;3 #第一次执行保存3slong_tiem_fun(3)out&gt;3 #第二次就直接返回不需要等待#通常这种功能不需要写，python3标准库提供该模块from functools import lru_cachehelp(lru_cache) lru_cache(maxsize=128,type=False) #定义最大值，如果超出128就，使用少就剔除@lru_cache()def long_time_fun(x): time.sleep(x) return xlong_time_fun(3)long_time_fun(3)#跟上面类似，第一次需要3s，第二次直接返回 监控123456789101112131415161718192021222324252627def mertic(prefix,instance):#prefix是发送的前缀,instance发送监控信息 def timeit(fn): @wrap(fn) def wrap(*args,**kwargs): start = time.time() ret = fn(*args,**kwargs) key = '&#123;&#125;.&#123;&#125;.&#123;&#125;'.format(prefix,fn.__module__,fn.__name__) instance.send(key,time.time()-start) #send发送到那边 return ret return wrap return timeitimport loggingclass LogginMetric: import logging def send(self,key,value): logging.warning('&#123;&#125;=&gt;&#123;&#125;'.format(key,values))@mertic(perfix='tomcat',instance=LoggingMetric())def long_time_fun(x): time.sleep(x) return xlong_time_fun(1)1#statsd放到influxdb，前段用grafana 身份验证12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def auto_func(func): def wrapper(*args,**kwargs): user = input('please username:').strip() passwd = input('please password:').strip() if user == 'zhuxuyue' and passwd == '123': rest = func(*args,**kwargs) return rest else: print('用户名密码错误') return wrapper def index(): print('欢迎访问taoboa.com') @auto_func def home(name): print('欢迎&#123;&#125;来到taobao.com'.format(name)) @auto_func def shopping_car(name): print('&#123;&#125;的购物车有&#123;&#125;&#123;&#125;'.format(name,'mike','computer')) index() home('朱旭悦') shopping_car('朱旭悦')#每次执行都需要登录，如何提供session功能嫩？#这里需要将输入的密码存储起来。user_dict = &#123;'username':None,'Login':False&#125; def auto_func(func): def wrapper(*args,**kwargs): if user_dict['username'] and user_dict['Login']: rest = func(*args,**kwargs) return rest user = input('please username:').strip() passwd = input('please password:').strip() if user == 'zhuxuyue' and passwd == '123': user_dict['username'] = 'zhuxuyue' user_dict['Login'] = True rest = func(*args,**kwargs) return rest else: print('用户名密码错误') return wrapper def index(): print('欢迎访问www.taoboa.com') @auto_func def home(name): print('欢迎&#123;&#125;来到taobao.com'.format(name)) @auto_func def shopping_car(name): print('&#123;&#125;的购物车有&#123;&#125;&#123;&#125;'.format(name,'mike','computer')) index() home('朱旭悦') shopping_car('朱旭悦') 获取最大值123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#模拟数据源不断产生数字，求一段时间内，最大的元素import random #随机数模块import time #时间戳模块import datetime #时间模块def data_source(): while True: yield random.randint(0,100) time.sleep(0.1)ds = data_source()for _ in range(10): print(next(ds))#模拟数据源代码#求一段时间最大元素,top kdef top_k1(k,time=3): start = datetime.datetime.now() lst = [] while True: lst.append(next(ds)) current = datetime.datetime.now() if (current - start).total_seconds() &gt;= time: start = current lst.sort() ret = [] for _ in range(k): ret.append(lst.pop()) yield retg = top_k1(10)for _ in range(3): print(next(g))#效率比较慢,需要全部加入列表后才能算出结果.#如何使用堆实现import datetimeimport randomimport timedef heap(): data = [] def add(e): idx = len(data) data.append(e) parent_idx = (idx - 1) // 2 while parent_idx &gt;= 0: if data[idx] &gt; data[parent_idx]: data[parent_idx],data[idx] = data[idx],data[parent_idx] idx = parent_idx parent_idx = (idx - 1) // 2 else: break def pop(): if not data: return None if len(data) == 1: return data.pop() idx = 0 ret = data[idx] data[idx] = data.pop() left_idx = 2 * idx + 1 rigth_idx = left_idx + 1 while left_idx &lt; len(data): child_idx = left_idx if rigth_idx &lt; len(data) and data[rigth_idx] &gt; data[left_idx]: #存在有子节点,并且又子节点大于左子节点 child_idx = rigth_idx if data[idx] &lt; data[child_idx]: data[idx],data[child_idx] = data[child_idx],data[idx] idx = child_idx left_idx = 2*idx+1 rigth_idx = left_idx + 1 else: break return ret return add,popdef data_source(): while True: yield random.randint(0, 100) time.sleep(0.1)ds = data_source()def top_k3(k,time=3): start = datetime.datetime.now() add,pop = heap() while True: add(next(ds)) current = datetime.datetime.now() if (current - start).total_seconds() &gt;= time: start = current ret = [] for _ in range(k): ret.append(pop()) yield retg3 = top_k3(10)for _ in range(3): print(next(g3))#堆是优先队列。先进先出]]></content>
      <categories>
        <category>Python Basic</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-2.函数(进阶篇)]]></title>
    <url>%2F2018%2F12%2F07%2FPython-2.%E5%87%BD%E6%95%B0(%E8%BF%9B%E9%98%B6%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[前言 上节记录了一些函数的基础，如函数的参数，函数的返回值，参数结构，函数的作用域等概念 这节说下函数的几个特性，比如闭包，应用传递，函数执行流程，生成器 下节课说下高阶函数和装饰器 闭包很多无编程基础的小伙伴在刚学python时，说到闭包概念就开始晕(包括我)，从而搞不懂后面的高阶函数，装饰圈等概念。 看看下面写的内容希望有帮助。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#上一篇我们知道作用域的概念LEGB，下面我们来看个代码def outer(): y = 10 def inner(): #inner是一个内部函数 print(y) #inner函数调用y(这个变量是上级变量E) return innerouter()()#这个其实就是一个闭包啦。#什么是闭包:#条件一:函数体内部有个函数。#条件二:并且内部函数如果调用上级变量#满足上面两个条件就是一个闭包啦。#上面为什么使用outter()()来调用？def outer(): y = 10 def inner(): print(y) return inner #这里只是返回一个函数，并没有调用f = outer() #这个只是调用outer函数，outer函数返回inner函数f() #这里才是调用inner函数，注意这里是调用#所以使用outter()()需要两个括号来调用inner()函数#那么可能会说为什么使用return inner()在函数内部调用？def outer(): y = 10 def inner(): print(y) return inner()outer()#这样也能将y显示出来#想个问题，如果当我们写一个程序，每当执行这个程序都会计数加1，如何实现？def time(): global x x = 0 def func(): global x x += 1 return x return func()f = time()fout&gt;1fout&gt;1#为什么这样？#当调用time()函数的时候返回是func()的返回值(return x)#这里只是将0+1返回了，所以一直都是1.def time(): global x x = 0 def func(): global x x += 1 return x return funcf = time()f()out&gt;1f()out&gt;2#这时候才实现了当调用函数时候累计加1，for _ in range(10): print(f())#返回1，2，3，..12x = 100f()out&gt;101#为什么会这样，因为使用了global，#当执行f()就是直接调用了函数内部的func()函数.global就是100，然后x+=1就是101#所以说了，在使用global时候一定要知道干了什么。#改如何优化呢？#python2中def counter(): x = [0] def inc(): x[0]+=1 return x[0] return incc = counter()c()out&gt;1c()out&gt;2x = 100c()out&gt;3####这是在python2中实现闭包的唯一方式#python3中def count(): x = 0 def inc(): nonlocal x x += 1 return x return incc = count()c()out&gt;1c()out&gt;2x = 100c()out&gt;3#可以看出nonlocal关键字用于表示一个变量由上级作用于定义，通过nonlocal标记变量，对上级可读可写##如果上级没有定义(函数体内的上级)会抛出SyntaxError语法错误,x = 1def fn(): nonlocal x x += 1 return x&gt;&gt;&gt;SyntaxError 小结 闭包：函数内部有函数，并且该函数调用上级函数变量，函数已经接受，但是函数部分变量引用还在这就是闭包。 引用传递123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def fn(x=[]): x.append(1) print(x)fn() #打印[1]fn() #打印[1,1]#为什么会这样?#这里的x.append(1)只是增加，并不是赋值#python的参数是通过值来传递的，如果变量是是可变对象，如列表，在返回到调用程序后，对象会出现被修改状态fn.__defaults__out&gt;([1,1],)#fn的值都存在defaults下，是个元祖类型，不可变#在python中一切皆对象#函数也是对象，参数是函数对象的属性，函数参数的作用域会伴随整个生命周期，如果函数存在则函数参数也存在#对于定义全局作用域的函数: 重新定义，del，程序退出时#对于定义局部作用域的函数: 重新定义，del，上级作用域被销毁#当使用可变类型作为参数默认值的时候需要注意#在看个例子def fn(x=1,y=2): x = 3 #在函数体内，赋值即定义 y = 4 return x,yfn.__defaults__out&gt;(1,2)#如何使 函数体内 数字是不可变类型?#使用不可变类型作为函数值，如元祖#函数体内不改变默认值，这里可以在函数体加个判断#实例def fn(lst=[]): lst = lst[:] #相当于拷贝(影子拷贝) lst.append(1) print(lst)fn.__defaults__out&gt;([],)fn() #返回1fn([1,2]) #返回1,2,1 1,2传到lst，然后在添加了一个append#实例2def fn(lst=None): if lst is None: lst = [] else: lse = [:] lst.append(1) print(lst)fn.__defaults__out&gt;(None,)fn() #打印1fn.__defaults__out&gt;(None,)#通常如果使用可变类型作为默认参数时候会使用None来代替.#通常 值保持在栈空间，引用是在堆空间 函数执行流程函数执行过程，函数执行过程可视化地址。 在内存空间的划分： 123456&gt; *堆 随机访问，用于保存数据，变量&gt; *栈 先进后出，用于保存现场&gt; *指令 顺序访问，用于存储程序指令&gt; *静态区&gt; *保留区&gt; 堆(heap)，队列优先，先进先出（FIFO-First in First out） 栈(stack)，先进后出（FILO-First-in/Last-out） ​ #先入后弹出，后入先弹出。类似弹夹，先放进去的最后出来，最后放进来的先出去 假设程序是单进程,单执行流,在某一时刻，能运行的程序只能有一个,但函数调用会打开新的执行上下文,因此为了确保main函数可以恢复现场 在main函数调用其他函数时,需要先把main现场保存下来,放一边,即栈中，这时候被调用的函数即可执行，且完成后可加到调用者，’回到’调用 者main，main可以继续向前运行. 12345678910执行流程:main #主流程认为是全局作用域f1() #进入f1函数 开启新的作用域，单核cpu只能执行一个指令(单核)，需要保存现场（压栈），执行f1完成后，还原现场f2() f3() f4()main#当调用函数的时候，解释器会把当前的现场压栈，压栈完成后开始执行被调函数，被调函数执行完成后，解释器弹出当前栈顶恢复现场，没次调用函数都有压栈，出栈操作。#压栈的时候叫保存现场，会保存当前各种变量的地址#出栈的时候叫恢复现场，也是恢复当前各种变量的地址 注：严格来说 引用真正的数据保存在堆里面，数据的引用地址保存在栈里面。 所有语言都是这么实现的 递归函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#什么是递归函数？#递归函数总是涉及到压栈和出栈的过程，一直到有退出条件才出栈#函数内部调用自身，递归必须有退出条件，否则会出现死循环，#求个阶加#1+2+3+4+5+6+N#公式：#(N+1)*(N)/2#这里不需要调用函数本身def sum(x): return (x+1)*x/2sum(100)out&gt;5050.0#求个阶乘：#1*2*3*4*n#公式：#g(0)=1#g(1)=1#g(x)= x*g(x-1)#代码如下def g(x): if x == 0 or x == 1: return 1 return x*g(x-1)g(10)out&gt;3628800#在求个斐波那契#1+1+2+3+5+8+13+21+N#公式：#f(0)=1#f(1)=1#f(x) = f(x-1)+f(x-2)def f(x): if x == 0 or x == 1: return 1 return f(x-1)+f(x-2)f(10)out&gt;89#这样一个递归是不是很容易计算出数学中的公式呢？是不是很快捷?#注意：一定要有退出条件，否则会成死循环。#在python内部，为了保护解释器，python对最大递归深度有限制，默认为1000，函数返回只能调用1000次import syssys.getrecursionlimit() #查看递归深度out&gt;1000sys.setrecursionlimit(5000) #设置递归深度为5000.(需要注意如果设置值小于26则抛出recursionError)#不过虽然很快捷，但是通常不会使用递归。#因为 运行起来很慢 (计算时深度很深时要压栈直到有退出条件才出栈,这样及其消耗资源)#拿阶乘的例子来说#可以这样def g(n): ret = 1 for x in range(1,n+1): ret *=x return retg(1000)#可以这样def g(n): ret = 1 for _ in range(1,n+1): ret * = g(n-1) return retg(1000)#pyton可以完全不用递归，小问题可以使用很方便，比如树的处理#但是：冯诺依曼模型本质就是递归，还有erlang对递归依赖很大#在python中还可以使用生成器来取代递归。#需要注意点def f(): g()def g(): f()#当执行f()时候，解释器都会挂掉，通常很容易出现这种情况，#这种并不是递归，但是类似递归 ####生成器 在介绍生成器前，需要介绍下生成式。 生成式列表生成式，字典生成式，集合生成式 123456789101112131415161718192021222324252627282930313233#列表生成式#如何将列表[1,2,3,4,5]每个值*2l = [x*2 for x in [1,2,3,4,5]]print(type(l)) #打印出&lt;class 'list'&gt;lout&gt;[2, 4, 6, 8, 10]#这个就是一个列表生成器#在列表内部进行计算#字典生成式#字典生成式假设有10个学生，筛选出60分以下的学生import randomstuInfo = &#123;'student&#123;&#125;'.format(i):random.randint(0,100) for i in range(10)&#125;d = &#123;stu:score for stu,score in stuInfo.items() if score &lt; 60 &#125;print(type(d)) #打印出&lt;class 'dict'&gt;dout &gt;&#123;'student1': 40, 'student7': 11, 'student9': 49&#125;#这个就是字典生成式#集合生成式#看个例子s = &#123;x+1 for x in range(2)&#125;print(type(s)) #打印出 &lt;class 'set'&gt;sout&gt;&#123;1, 2&#125;#这些生成式只是一个生成式，不会改变他们的类型，效率比那些map，reduce高。#那么有元祖生成式么？问的好。元祖生成式就是生成器啦，#既然你这么厉害，为何不打个赏 在字典，列表，集合中创建一个生成式，但是受内存的限制，容量肯定是有限的，比如一个包含100万个元素字典或者列表，只需要访问几个元素，这样不仅仅占用很大空间，而且绝大部分空间都浪费了。 生成器 在生成式中可以通过某种方式推算出来，那就可以在循环的过程中不断去推算出后续的元素，这样就不需要直接创建完整的元素，从而省去大量空间以及空间浪费等问题。 python中这一种循环的过程推算后续的元素 叫生成器 生成器的特性就是：惰性求值。 123456789101112131415161718#还是看刚才的例子，将列表[1,2,3,4,5]每个值*2#生成器实现(x*2 for x in [1,2,3,4,5])out&gt;generator object &lt;genexpr&gt; at 0x7f5cfc54c468&gt;a = (x*2 for x in [1,2,3,4,5])print(type(a))out&gt;&lt;class 'generator'&gt;#可以看出这里就是generator类型了。#如何调用呢？next(a) out&gt;2next(a) out&gt;4next(a) out&gt;6next(a) out&gt;8next(a) out&gt;10#可以看出使用next()直接调用，(在python2中，使用a.next()来调用)next(a) 抛出异常StopIteration#当生存器执行完成时候抛出StopIteration异常 生成器函数什么是生成器函数？ 一个函数返回的是yield，name这个函数就是生成器函数 需要next调用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138#实例def gen(): yield 1 yield 2 return 3g = gen()g&lt;generator object gen at 0x7fe0086d7360&gt;#当调用函数时，并没有执行里面的内容next(g)out&gt;1#next调用函数时候，第一个yield 1停止next(g)out&gt;2#再次调用执行第二个yield 2停止next(g)StopIteration:3#当没有yield出现时候抛出异常，并返回3next(g)StopIteration#再次next调用时候，抛出异常，没有返回值#通常带yield语句的函数我们称之为生成器函数，#生成器函数返回值是生成器#特性：#1.生成器函数执行时，不会执行函数体 g = gen() 不会执行#2.当next生成器的时候，会从当前代码执行到yield，会弹出值，并且暂停函数#3.当next再次执行，会从上次暂停出往下执行#4.当没有多余yield的时候抛出StopIteration异常，异常的value是函数返回值，如果没有返回值则返回空#需要注意函数体里面如果yield和return并存def fn(): yield 1 return 1 yield 2f = fn()next(f) #out&gt;1next(f) #StopIteration: 1next(f) #StopIteration: #return后的yield不会执行。return依然可以中断生成器#next(f)始终是往下执行，不可逆序#还需要注意的是def fn(x): if x == 0: yield xnext(fn(0)) #out&gt;0id(fn(0)) #out&gt;140600190793072next(fn(0)) #out&gt;0id(fn(0)) #out&gt;140600190793336#这里并不等价#f = fn() next(f) ====不等于===&gt; next(fn())#f = fn() #相当于将fn函数赋值了，每次next(f)的时候都是调用这个函数之后的#next(fn()) #则表示每次都是重新执行该函数#利用yield写个计时器def count(): c = 0 while True: c += 1 yield ccountime = count()next(countime) #out&gt;1next(countime) #out&gt;2#思考一个问题，如何统计并发？#单线程没有必要考虑#如果在多线程情况下，可以加锁来统计并发#每次要调用next方法才能计数，如何直接调用这个函数就能计时呢？#想想看怎么办？#调用上一个函数不就行了么def count(): c = 0 while True: c += 1 yield cdef counter(): c = count() return next(c)coun = counter()coun #out&gt;1coun #out&gt;1#为什么这样，因为将counter赋值给了coun，然而里面定义了c = count()#当执行coun每次都会重新赋值，每次执行coun都会从新赋值返回这个next(c)#之前貌似遇过，我们使用闭包这个概念来进行计数#可以改写def count(): c = 0 while True: c += 1 yield cdef counter(): c = count() def func(): return next(c) return funcc = counter()c() #out&gt;1c() #out&gt;2#如何写在一起呢？def counter(): def count(): c = 0 while True: c += 1 yield c c = count() def func(): return next(c) return funccoun = cunter()coun() #out&gt;1coun() #out&gt;2#问题又来了。#python肯定是个优雅的语言，使用lambda简写def counter(): def count(): c = 0 while True: c += 1 yield c c = count() return lambda:next(c)coun = counter()coun() #out&gt;1coun() #out&gt;2#关于lambda只是个匿名函数，我们下面就会说 迭代器 说到迭代器，大家可能会想到可迭代对象。 什么是可迭代对象？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172for i in [1,2,3,4,5]: print(i)#[1,2,3,4,5]就是一个可迭代对象,凡是可迭代对象都可以循环它def gen(x): for i in range(x): yield ig = gen(10)for x in g: print(x) #这里打印0~9 #for也可以循环生成器函数。#list,tuple,dict,set,str这些都是可迭代对象。#定义了"yield生成器函数"也可以被迭代。#等等，这里for调用后为什么没有抛出异常？#for循环内部做了三件事 #调用可迭代对象iter方法，返回可迭代对象 #调用迭代器的next方法 #处理Stopiteration异常while True: try: x = next(g) print('g',x) except StopIteration as e: print('Generator return value:',e.value) break#如何判断一个数据是否是可迭代对象呢？#判断迭代器和迭代对象需要导入collections模块里面的Iterator,Iterable方法#Iterable可迭代对象，Iterator迭代器from collections import Iterator,Iterablel = [1,2,3,4]a = iter([1,2,3,4])isinstance(l,Iterable)out&gt;Trueisinstance(a,Iterable)out&gt;Trueisinstance(l,Iterator) #可以看出list不是迭代器out&gt;Falseisinstance(a,Iterator)out&gt;Trueisinstance还可以判断是否是list，str，dict等类型isinstance([1,2,3,4],list)out&gt;Trueisinstance([1,2,3,4],dict)out&gt;False#但list、dict、str虽然是Iterable(可迭代对象),却不是Iterator（迭代器）#把list、dict、str这些可迭代对象 变成 迭代器 可使用iter()函数：#例子a = iter([1,2,3,4])isinstance(a,Iterator)#只要函数里面定义了yield那么该函数就是迭代器#例子def fn(): yield 1isinstance(fn(),Iterator)isinstance(fn(),Iterable)help(fn())#可以看出fn()里面有__iter__()和__next__()方法#通常迭代器满足两个条件#有iter方法#有next方法 总结 生成器都是迭代器，但是迭代器并不一定是生成器 生成器生成迭代器就是生成器本身。 通常我们叫迭代器也叫生成器。 生成器高级用法是用在协程上 协程： 是用户空间的轻量线程，跑在一个线程内，由用户空间调度 进程和线程是操作系统来调度 调度：由调度器来决定哪段代码来占用cpu时间） 内核态到用户态进行调度需要消耗时间跟资源，用户态跟用户态之间调度消耗资源小 协程也叫轻量线程非抢占式调度 生成器用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#生成器send()用法#看例子def gen(x): while True: n = yield x print(n)g = gen(10)next(g)out&gt;10next(g)Noneout&gt;10#这里的n = yield x 是赋值的意思么？#第一次执行next时候 返回 10 可以理解#第二次为毛有None？难道说在yield之前有个None？,#send是传递？传递给None么？g.send(2)2out&gt;10#还真是。。。def gen(x): while True: n = yield x print(n)g = gen(10)g.send(100000)TypeError: can't send non-None value to a just-started generator#为什么为报错呢？#g.send(100) (第一次执行这个，并不能给n赋值，因为找不到n)#当第一次执行#next(g)的时候执行yield x,这里x就是10，n就为10，yield结束后，n就在这个函数体里面存在#在此next(g)的时候，打印刚才10，到yield 10结束#如果这是g.send(1000),这里n就变成1000了，而yield 10还是刚才你传入的值#如果没有传参数，那么就会显示刚才的 打印None,返回10#协程例子#看个示例：def gen1(): while True: yield 'gen1'def gen2(g): for x in range(10): yield 'gen2' print(next(g))g = gen2(gen1())next(g) #out&gt;'gen2'next(g) #打印‘gen1' out&gt;'gen2'#生产者消费者模型import timedef consumer(pro): print('&#123;&#125;开始消费'.format(pro)) while True: con = yield print('&#123;&#125;生产完成，&#123;&#125;消费结束'.format(con,pro))def producer(pro): c1 = consumer('C1') c2 = consumer('C2') next(c1) next(c2) print('&#123;&#125;准备生产'.format(pro)) for i in range(1,5): time.sleep(1) print('&#123;&#125;生产两个'.format(pro)) c1.send(i) c2.send(i)producer('server')#打印如下C1开始消费C2开始消费server准备生产server生产两个1生产完成，C1消费结束1生产完成，C2消费结束server生产两个2生产完成，C1消费结束2生产完成，C2消费结束server生产两个3生产完成，C1消费结束3生产完成，C2消费结束server生产两个4生产完成，C1消费结束4生产完成，C2消费结束]]></content>
      <categories>
        <category>Python Basic</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-1.函数(入门篇)]]></title>
    <url>%2F2018%2F12%2F06%2FPython-1.%E5%87%BD%E6%95%B0(%E5%85%A5%E9%97%A8%E7%AF%87)%2F</url>
    <content type="text"><![CDATA[函数什么是函数： 在python中函数是组织代码的最小单元 可重用，功能单一 输入（参数）===&gt; 输出（返回值） python的函数，并不是数学中函数，python也可以使用math模块和cmath模块实现数学中的函数，也可以使用abs,cmp,exp,mod,max,min等方法实现数学中的函数，详见 定义函数 以下操作建议使用Jupyter来执行，部署jupyter步骤 123456789101112131415161718192021222324def funcname(): print(1) return 1funcname()1out&gt;1#def表示定义一个函数，funcname是函数名,函数后面括号是参数列表(可不定义),最后使用:开始函数体#print(1+2) 函数体是正确的python语句，可以包含任意结构。#return语句表示函数返回值.返回结束#函数有输入(参数)和输出(返回值),函数式一个代码单元，将输入转换成输出#实例def funcname(a): return afuncname('zhuxuyue')out&gt;'zhuxuyue'#funcname使用函数名来调用#函数 调用传入的参数 必须和 函数定义时参数 匹配，如果不匹配则抛出TypeError错误#定义函数的时候不会执行函数体里的内容，调用时才执行其中语句块 函数参数函数参数包含：位置参数，关键字参数，默认参数，可变参数，可变关键字参数，参数结构，命名关键字参数(keyword-only) 位置参数和关键字参数123456789101112131415161718192021222324252627282930def add(x,y,z): return (x+y-z)add(10,20,30)out&gt;0add(20,30,10)out&gt;40#在定义函数时，如果有多个参数，参数间使用空格#调用时参数 按照 顺序 传入定义时参数的顺序#在位置参数中 调用传入参数非常重要，直接影响结果#如果调用时传入的参数 多于/少于 定义时的参数，都会抛出TypeError错误def add(x,y,z): return (x+y-z)#关键字参数add(z=20,x=10,y=30)out&gt;20#调用参数时，可使用定义时的变量名称传入，这种传参也叫关键字参数，关键字参数和顺序没有关系，只要能对应定义时参数就可以了add(10,y=30,z=20)out&gt;20#位置参数可以和关键字参数一起使用。add(10,y=30,20)out&gt;TypeError#一起使用时，一旦关键参数在位置参数前，则会抛出TypeError异常 默认参数123456789101112131415161718def add(x,y,z=100): return (x-y+z)add(10,20,110)out&gt;100add(10,20,z=20)out&gt;10add(x=20,z=30,y=20)out&gt;30add(z=20,10,20)SyntaxError#定义参数是如果有默认值，在调用时如果不传递参数，会使用默认值，#在调用时修改了默认参数，则调用参数值会覆盖默认参数值#在调用时默认参数必须在位置参数之后，否则会抛出SyntaxError异常 位置可变参数和可变关键字参数12345678910111213141516171819202122232425262728293031323334353637383940def sum(x,y) return x+y#在调用时只能输入一个个的数值才能一个个去计算，假设要对多个值求值怎么办？#例子def sum(lst): print(type(lst)) ret = 0 for x in lst: ret +=x return retsum([1,2,3,4,5])&lt;class 'list'&gt;out&gt;15#这种可以实现，但是不优雅，通常在python中使用下面的方法实现，#参数加*表示位置可变参数，def sum(*lst): print(type(lst)) ret = 0 for x in lst: ret += x return retsum(1,2,3,4,5)&lt;class 'tuple'&gt;out&gt;15#*lst参数加星号，表示该参数是可变参数，构成一个元祖，此时只能通过位置参数进行传参。def connect(**kwargs): for k,v in kwargs.items(): print(k,v)connect(host='127.0.0.1',user='root',port=3306)port 3306user roothost 127.0.0.1#**kwargs加两个星号，表示参数是可变的，可以接受任意多个参数，这些参数构成一个字典，需要通过关键字传参#位置可变参数 参数前加一个*号，构成元祖，传参只能以位置参数传参#关键字可变参数 参数前加两个**号，构成字典，传参只能以关键字参数传参 注意事项1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162def fn(**kwargs,*args): print(kwargs,args)SyntaxErrordef fn(*args,**kwargs): print(kwargs,args)#定义参数时 位置可变参数可以和关键字可变参数一起使用#但是关键字可变参数必须在位置可变参数之后，否则会抛出SyntaxErrordef fn(x,y,*args,**kwargs): print(x,y,args,kwargs)fn(1,2,3,4,5,y=2,a=2,b=3)TypeErrorfn(1,2,3,4,5,a=2,b=3)1 2 (3,4,5) &#123;'a':2,'b':3&#125;#普通参数可以和可变参数一起使用#但是传参必须匹配，同一个参数不可以出现两次def fn(*args,x): print(args) print(x)fn(1,2,3,4,5):TypeErrorfn(1,2,3,4,x=5):1,2,3,45#位置可变参数可以在普通参数之前#但是在位置可变参数之后的普通参数变成keyword-only参数#keyword-only 只能以关键字方式传输叫keyword-onlydef fn(**kwargs,x): print(kwargs) print(x)syntaxError#当默认参数和可变参数一起出现的时候，默认参数相当于普通参数#关键字参数不允许在普通参数之前-----------------------------------------------------------#总结：#默认参数靠后#可变参数靠后#默认参数可变参数不能同时出现#如果既想有默认参数，又有可变关键字参数怎么办#示例def connect(host='127.0.0.1',port=3306,user='root',passwd='',db='test',**kwargs): passdef connect(**kwargs): host = kwargs.pop('host','127.0.0.1)#字典可以用pop方法,需要指定默认值，如果不指定默认值的话会，如果找不到会抛出异常 参数解构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#示例:def add(x,y): ret = x+y return reta = [1,2]#这如何将a里面列表传入到add定义的参数里面？add(a[0],a[1])out&gt;3#这种方式不是很优雅，python是个优雅的语言:)add(*a)out&gt;3#在位置参数中，加星号，可把一个可迭代对象结构成位置参数#拿刚才可变位置参数来说def sum(*lst): print(type(lst)) ret = 0 for x in lst: ret +=x return retsum(*range(1,101))out&gt;5050#需要注意的是#参数结构，是发送在调用的时候才结构#可变位置参数，发生在函数定义的时候#既然可变参数可以参数结构,那么我们试试可变关键字参数是不是也可以#可变关键字参数结构需要加**def add(x,y,z): return x,y,zdic = &#123;'x':1,'y':100,'z':1000&#125;add(**dic)(1, 100, 1000)def add(**kwarg): for k,v in kwarg.items(): print(k,v)dic = &#123;'x':1,'y':100,'z':1000&#125;add(**dic)x 1y 100z 1000#总结：#参数解构两种形式：可变位置参数解构，可变关键字参数解构#* 结构对象是可迭代对象，结构的结果是位置参数#** 结构对象是字典,解构结果是关键字参数#注：#再次强调一定要区分 参数解构 和 可变参数。#参数解构 是发生在函数调用#可变位置参数 是发送在函数定义def sum(*lst): #这里(*lst) 表示可变位置参数， print(type(lst)) ret = 0 for x in lst: ret +=x return retsum(*range(1,101)) #这里(*range(1,101)) 表示参数解构out&gt;5050#解构限制在哪？#实例def fn(**kwargs): print(kwargs)fn(**&#123;'a':1&#125;)&#123;'a':1&#125;fn(**&#123;1:1&#125;) TypeError#关键字参数结构，key必须是str类型,否则抛出TypeError#参数结构也可可以是set类型def funcname(*arg): return argfuncname(*&#123;5,12,3,4,5,12,34,3,4,0&#125;)out&gt;(0, 34, 3, 4, 5, 12)#通常用的不多 命名关键字参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#命名关键字参数，也叫(Keyword-only) 是在python3新增的一个特性def fn(*,x): return xfn(x=3)out&gt;3fn(1,x=2) TypeError#在加星号之后的参数只能通过关键字参数传递，叫keyword-only参数：）#可变位置参数之后的参数也是keyword-only参数，必须以关键字方式传入#实例：def fn(x,*,y): return x,yfn(1,y=2)out&gt;(1,2)fn(x=1,y=2)out&gt;1,2fn(y=3,x=1)out&gt;1,3fn(x=1,2) SyntaxError#在函数定义时候，可以跟普通参数使用，但是在keyword-only后必须用关键字方式传参#通常我们使用keyword-only参数必须有默认值#类似：def fn(x,*,y=10): return x,yfn(12)out&gt;(12, 10)fn(y=11,x=20)out(20,11)fn(x=20,20) SyntaxError #练习#写个函数连接mysql数据库，必须输入用户名、密码，但是主机,字符集,端口可以使用默认的localhost,utf-8,3306def mysqlconnect(host='localhost',characterset='utf-8',port='3306',*,user,passwd): print(''' user:&#123;&#125; password:&#123;&#125; host:&#123;&#125; port:&#123;&#125; characterset:&#123;&#125; '''.format(user,passwd,host,port,characterset))mysqlconnect(user='root',passwd='zhuxyzuishuai') user:root password:zhuxyzuishuai host:localhost port:3306 characterset:utf-8 函数返回值12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#----------------------python返回值return------------------------#实例1：def fn(x,y): print(x,y) return x,yfn(1,2)1,2out&gt;1,2def fn(x,y): return x,y print(x,y)fn(1,2)out&gt;1,2#可以看出 return 可以返回返回值，return之后语句不会执行#实例2：def fn(x,y): if x &gt; y: return x return yfn(3,2)out&gt;3fn(2,3)out&gt;3#一个函数体可以定义多个return语句，执行到哪个return语句就返回那个return结果,并结束函数#实例3def fn(x): for i in range(x): if i &gt; 3: return i return '小于3'fn(10)out&gt;'小于3'def fn(x): for i in range(x): if i &gt; 3: return i return '小于3'fn(10)out&gt;4#return 也可提前结束循环体#实例4def fn(x): x = 100fn(1)func = fn(1)#如果一个函数没有返回值，隐藏式返回Nonetype(func)out&gt;NoneType#可使用type查看函数def fn(x): pass#==等效==&gt;def fn1(x): return #==等效==&gt;def fn2(x): return None#--------------------python返回值return作用-----------------------def fn(): return 3,5 #封包ret = fn()type(ret)out&gt;tuple#当函数需要返回多个值的时候,可以将返回值封装成元祖，封装在return中x,y = fn()xout&gt;3yout&gt;4#return可以通过解构获取多个返回值#return不要跟print混为一谈，print不可用结束返回体，不可用封包，仅仅只是打印作用，#return是返回，Ipython中out后都是return出来的 函数嵌套之前函数定义时说过，函数体里面可以包含任意结构，当然也可以包含函数 123456789#实例def outter(): def inner(): print('inner') print('outter') #上面inner定义结束，没被调用，先打印outter inner() #现在在调用inner里面的函数体，才打印inneroutter()'outter''inner' 函数作用域作用于是一个变量的可见范围，叫做这个变量的作用于。规则就是LEGB LEGB（Local，Enclosing，Glob，Builtin）：局部本地域，父级域，全局域，系统内置 优先级顺序：局部本地域 &gt; 父级域 &gt; 全局域 &gt; 系统内置 作用域可通过：global进行转换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141#例子1：a = 1def inc(): a = 2 print(x)inc() #打印22aout&gt;1#例子1.1：def inc(): b = 2 print(b)inc() #打印2bout&gt;NameError: name 'b' is not defined#这里函数体里面定义了a,只针对函数体里生效，不影响函数体之外的#例子2：def fn(): c = 3 print(c) def fn1(): print(c) fn1()fn() #打印3，3#函数体内父级作用域对下级域可见。#例子3:def fn(): e = 1 print(e) def inner(): e = 2 #这里重新定义了，定了就是赋值 print(e) inner() print(e)fn() #打印1，2，1#说明函数体内父级作用于对下级域 “只读可见“ 的关系#关于“只读可见“在看个例子x = 1def inc() print(x)inc() #打印1x=1def inc(): x = 2 x += 1 print(x)inc() #打印3x = 1def inc(): x = x + 1 print(x)inc()UnboundlocalError#为什么会报错，这里只是上级对下级只读可见，但不能直接修改，除非重新定义x = 1def inc(x): x = x + 1 print(x)inc(x)#可能会有人问这为什么正常？这里只是将x传入这个函数里面运算。 #实例4:x=3y=4 #这里是全局作用域变量def swap(x,y): x,y = y,x #这里是局部变量 print(x) print(y)swap(1,2) #打印2,1xout&gt;3yout&gt;4#不同作用域变量不可变，但是下级作用域可以对上级作用的变量只读可见,有什么方法对全局可见呢，可使用global#------------------------global------------------------#gobal作用是：将局部变量转换成全局变量#通过global关键字进行修改#实例x = 3def fn(): global x x += 1 print(x)fn() #打印4#global关键字可以提升变量作用域，为全局变量def fn(): global y y = 100 print(y)fn() #打印100yyout&gt;100#global不管外层有没有定义都可以提升def fn(): global yfn() #返回空yNameError:'y'is not defined#global只是提升，并没有定义变量，def fn(): global zz zz = 2zz #这里直接使用zz，并没有调用fn()函数#通常不建议在函数体内使用全局变量，在后期开发除非你很清楚global会带来什么。除了global没有其他方法的时候才使用global#还有这里的全局变量和全局作用域是两回事。#函数之外都是全局作用域，在函数之外定义的变量都是全局变量#------------------------locals------------------------#locals用来列出当前作用于范围内的所有变量#locals()在函数 外部执行 会显示全局作用域#locals()在函数 内部执行 会显示局部作用域def fn(): x=1 print(locals())fn() #打印&#123;'x':1&#125;def fn(x): x=1 print(locals())fn(3) #打印&#123;'x':1&#125;#这里只是显示函数体内定义的变量 小结 函数之外 在全局作用域 参数列表里面：参数列表作用域是在全局作用域里面，但是只能在函数作用域里面，只能在函数作用域内部用，因为在全局作用域不知道名字叫什么 总结1234567891011121314151617181920212223242526272829303132333435#函数的定义参数 普通参数 默认参数 可变参数(可变位置参数，可变关键字参数) keyword-only参数 需要注意的是: 普通参数在前面 默认参数在后面 可变参数在后面 可变参数尽量不和默认参数同时出现函数调用 位置参数 关键字参数 参数解构(位置参数解构，关键字参数解构)函数返回值 return个数 单个return语句 多个return语句 没有return语句 返回值个数 单值 多值(元祖封包返回多值) 无值(return None) 函数作用域: 作用域遵循LEGB规则 优先级顺序：局部本地域 &gt; 父级域 &gt; 全局域 &gt; 系统内置 提升作用域使用global]]></content>
      <categories>
        <category>Python Basic</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pyenv+Ipython+Jupyter]]></title>
    <url>%2F2018%2F12%2F05%2FPyenv%2F</url>
    <content type="text"><![CDATA[Pyenv通常在我们所使用的系统上，如Linux或者macOS上Python默认版本是2.x。如果想让系统保持原有Python的又想使用新版本怎么办？ Pyenv就是一个Python版本管理器，使多个Python版本共存。 Pyenv项目地址 Pyenv工作原理其实就是利用系统的环境变量，PATH优先级。根据用户所在环境或者目录，使用不同版本的Python。 Pyenv作用：自动安装python解释器，管理python版本，管理python虚拟环境 部署Pyenv1234567891011环境CentOS7.Pyenv使用shell编写(膜拜大神)，安装前需要安装git（需要在github上拉取代码）#curl -L https://raw.githubusercontent.com/pyenv/pyenv-installer/master/bin/pyenv-installer | base执行该命令可用自动安装pyenv环境安装完毕后配置环境变量#cat ~/.bash_profileexport PATH="~/.pyenv/bin:$PATH"eval "$(pyenv init -)"eval "$(pyenv virtualenv-init -)" Pyenv参数说明12345678910#python --helppyenv &lt;command&gt; [args]command: commands 列出参数 virtualenv 建立一个虚拟环境，python包管理器基于site(java打war包基于project) install 安装python版本 uninstall 卸载虚拟环境 local 切换当前目录以及其子目录的python版本 global 切换全局默认的python版本，建议不要使用。会覆盖原来的python版本(一旦覆盖一些依赖的程序将会出错，如yum) versions 查看系统已经安装的python软件包 安装Python3.5.2123456789101112131415161718192021222324252627282930313233343536#安装前需要安装python所依赖的软件包yum install -y gcc make patch gdbm-devel openssl-devel sqlite-devel zlib-devel bzip2-devel readline-develpyenv install --list#查看仓库中python版本pyenv install 3.5.2#安装python-3.5.2版本pyenv versions #查看pyenv中的python版本* system #当前使用python版本，system表示系统的python版本，通常是2.6+ 3.5.2pyenv local 3.5.2#切换成python-3.5.2版本pyenv versions system* 3.5.2#给虚拟环境命名#格式:pyenv virtualenv VERSION NAME#实例pyenv virtualenv 3.5.2 zhuxyid#创建名为zhuxuyue的python3.5.2的环境pyenv local zhuxyid#设置当前目录的python版本环境是zhuxyid所指向的python版本#一旦切换过来在当前目录下会生成.python-version文件，内容为zhuxyid#删除该文件环境就会指向默认python版本，文件可以手动创建，内容必须是已经创建的命名pyenv uninstall zhuxuyue#卸载zhuxuyue虚拟环境pyenv uninstall 3.5.2#卸载python 3.5.2环境 PIP pip是一个python中包管理器，提供对python工具包的查找，下载，安装，卸载等功能， pip也是easy_pip的改进版(老版本的python包管理器是easy_pip)。 pip类似CentOS的yum，perl中的cpan，ruby中的gem 常用命令：1234567891011121314151617181920212223242526272829303132333435pip install PACKAGE_NAME#安装最新版软件包pip install PACKAGE.NAME -i http://mirrors.aliyun.com/pypi/simple/#安装软件包使用阿里pip源pip install PACKAGE_NAME==VERSION#指定安装那个版本软件包pip uninstall PACKAGE_NAME#卸载软件包pip search 'PACKAGE_NAME'#查找软件包pip install -U PACKAGE_NAME#升级软件包pip install -f PACKAGE_NAME#查看软件包信息pip install -r requirements.txt#安装requirements.txt定义的软件包#requirements.txt可以使用pip freeze &gt; requirements.txt生成:)pip freeze#列出已安装软件包默认pip官方源太慢，可使国内阿里云的pip源mkdir ~/.pipvi ~/.pip/pip.conf[global]timeout = 6000 index-url = http://mirrors.aliyun.com/pypi/simple/ trusted-host = mirrors.aliyun.com Ipythonipython是python最好用的交互式软件，是python标准解释器增强版，具有tab补全，对象自省，强大历史机制，内嵌源代码编辑，集成python调试器，%run机制，宏，创建多个环境以及系统调用shell的能力。 Ipython可通过python3自带的pip安装。 安装Ipython安装Ipython很简单，只需要执行pip install ipython即可安装ipython。 Jupyterjupyter notebook Jupyter是一个开源web应用服务器，允许创建包含实时的代码，方程式，可视化，支持40多种语言如（Python，R等），支持分享笔记，互动输出，主要作用就是方便学习，如：数值模拟，数据可视化，统计建模，机器学习等。 安装Jupyterpip install jupyter 这里我们使用jupyter向后台的Ipython的服务器发送请求，并显示结果，在浏览器的界面中使用单元Cell保存各种信息。Cell有多种类型，经常使用的有表示格式化文本的Markdown单元，和表示代码的Code单元。需要安装MarkDown使用：pip install markdown 启动jupyter12345678910111213141516jupyter notebook#从命令行启动notebook服务器，启动后可使用http://localhost:8888访问，需要输入token，退出使用ctrl+cjupyter notebook project.ipynb#启动project.ipynb笔记本jupyter notebook --port 8000#以8000端口启动notebookjupyter notebook --no-browser#无需打开web游览器启动notebookjupyter notebook --ip=0.0.0.0 --port 80 --no-browser#绑定本地所有接口使用80端口启动notebook#部署完成后就可以使用游览器与Ipython进行交互啦。 如果每次启动jupyter都需要输入token，如何使用密码方式登录呢？ 在jupyter 5.5版本才支持密码方式登录 1234jupyter notebook --generate-config#生成jupyter_notebook_config.py配置文件jupyter notebook password#设置登录密码，需要输入两次 Jupyterk notebook快捷键编辑模式：允许输入代码/文本到单元格，通过绿色单元格表示 命令模式：结合系统的版本，如果是Linux可使用VI，并通过灰色单元格带有蓝色左边距 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#命令模式，按ESCF: #查找和替换Ctrl-Shift-P: #打开命令面板Enter: #进入【编辑模式】Shift-Enter: #运行(当前)单元，选中下一单元 #Tips：cell 单元(就指每一行的语句)Ctrl-Enter: #仅运行(当前)单元Alt-Enter: #运行(当前)单元，在下面插入一单元Y: #单元转入代码状态(Code)M: #单元转入标记状态(markdown)R: #单元转入原始状态（raw）1: #设定 1 级标题 #Tips：数值越大字体越小2: #设定 2 级标题3: #设定 3 级标题4: #设定 4 级标题5: #设定 5 级标题6: #设定 6 级标题K: #选择单元以上 #Tips：类似VIM里面命令模式下的“k”功能Up: #同上Down: #选择单元以下 #Tips：类似VIM里面命令模式下的“j”功能J: #同上Shift-K: #扩展选择单元以上(选择多行）Shift-Up: #同上Shift-Down: #扩展选择单元以下(选择多行）Shift-J: #同上A: #向(当前单元位置）上插入一个单元B: #向(当前单元位置）下插入一个单元X: #剪切所选择的单元C: #复制所选择的单元Shift-V: #粘贴所选择的单元到(当前单元位置）上面V: #粘贴所选择的单元到(当前单元位置）下面Z: #撤销一次单元的删除动作D,D: #删除一个单元(配合shift-K or UP、shift-J or Donw可以删除多行）Shift-M: #合并选中的行Ctrl-S: #文件存盘S: #文件存盘L: #显示当前单元的【行号】O: #转换（折叠）输出Shift-O: #转换输出为有滚动条的H: #查看快捷键的帮助信息I,I: #中断Notebook内核0,0: #重启Notebook内核Esc: #关闭页面Q: #关闭页面Shift-Space: #向上回滚内容Space: #向下回滚内容#编辑模式，按EnterTab: #代码缩进，【代码补全】Shift-Tab: #向前缩进，显示提示信息Ctrl-]: #缩进Ctrl-[: #恢复缩进Ctrl-A: #选择全部Ctrl-Z: #撤销Ctrl-Shift-Z: #恢复撤销Ctrl-Y: #同上Ctrl-Home: #移动光标到单元开头Ctrl-Up: #移动光标上移一次(行) #Tips：多行的时候使用一次仅移动一行Ctrl-End: #移动光标到单元结尾Ctrl-Down: #移动光标下移一次(行)Ctrl-Left: #向左移动一个单词Ctrl-Right: #向右移动一个单词Ctrl-Backspace: #删除当前光标位置之前的单词Ctrl-Delete: #删除当前光标位置之后的单词Ctrl-M: #进入命令(Command Mode)模式Ctrl-Shift-P: #打开命令面板（和命令模式一样）Esc: #进入命令(Command Mode)模式Shift-Enter: #运行单元内容，选择下一单元Ctrl-Enter: #仅运行(当前)单元内容Alt-Enter: #运行(当前)单元内容，插入一个新单元Ctrl-Shift-Minus: #水平分割当前单元内容为新单元 #Tips:Minus =（减号&quot;-&quot;分隔符） Ctrl-Shift-“-”]]></content>
      <categories>
        <category>Python Basic</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx-uWSGI-Django]]></title>
    <url>%2F2018%2F12%2F05%2FNginx-uWSGI-Django%2F</url>
    <content type="text"><![CDATA[前言：在生产环境中，如果需要部署一个Python 的web框架，通常不会直接使用web框架中自带的轻量级web服务。 比如在Django中执行python manage.py runserver这只是纯粹用python编写的轻量级web服务，它包含在Django中，因此可以快速开发，只是在开发时候使用，Django是注重Web框架，并不注重Web服务器。详见地址 此时如果我们想要将django所开发的网站放入生成环境改如何实现？ uWSGI是什么？uWSGI是一个Web服务器，实现了WSGI，uwsgi，HTTP协议。 uwsgi是一种线路协议（不是通讯协议，用于uWSGI与其他服务数据通讯），类似于fastcgi。 WSGI（Web Server Gateway Interface）顾名思义：web服务器网关接口，它只是一个规范，描述Web服务器如何与Web应用程序通讯，以及Web应用程序如何连接在一起处理一个请求。可参考PEP-3333 这里实现HTTP协议我们可以使用Nginx。 客户端请求django流程大致过程： Client &lt;=====&gt; Nginx &lt;======&gt; socket (uwsgi)&lt; ======&gt; uWSGI &lt; ====== &gt; Django 安装uWSGI安装并测试123456789101112131415161718192021#uwsgi是实现uWSGI的软件，可以安装uwsgi软件$pip install uwsgi$uwsgi --http :8080 --chdir /www/blog/ --wsgi-file blog/wsgi.py --master --processes 4 --threads 2#--http 启用http端口#--chdir 执行运行目录#--wsgi-file 载入wsgi-file目录#--master 允许主进程存在#--processes 开启进程数量#--threads 运行线程个数#--pidfile 指定PID#--vacuum 当服务器退出时，自动清理环境,删除unix socket文件和pid#--daemonize 使进程在后台运行,并将日志打印到指定文件或者udp服务器中#tree -d blog├── blog ├── wsgi.py├── static├── Template└── web#此时可以直接访问8080端口看是否可以访问到django所创建的blog项目,如果正常访问说明正常 配置文件 参考地址 1234567891011121314151617181920212223#实例#more /etc/uwsgi.ini[uwsgi]#http = 192.168.0.10:8888 #uwsgi http端口#socket = 192.168.0.10:8000 #uwsgi socket端口,本机地址,如果nginx在其他机器可以使用此方式来访问socket = /var/run/uwsgi.sockmaster = trueprocesses = 4max-requests = 1000 #每个进程请求上限limit-as = 512 #限制虚拟内存单位Mbuffer-size = 30000 #包解析缓存区大小,默认4kchdir = /www/blog/wsgi-file = blog/wsgi.pyhome = /root/.pyenv/versions/zhuxuyue #如果有不同python根据需求指定环境变量static-map = /static=/www/blog/staticuid = wwwgid = wwwvacuum = trueharakiri = 30#stats = 127.0.0.1:8001 #状态信息也可以使用端口访问stats = /var/run/uwsgi.statusdaemonize = /var/log/uwsgi.logpidfile = /var/run/uwsgi.pid uwsgi常用命令123456uwsgi --ini /etc/uwsgi.iniuwsgi --stop /var/run/uwsgi.piduwsgi --reload /var/run/uwsgi.pid#uwsgi --connect-and-read 127.0.0.1:8002uwsgi --connect-and-read /var/run/uwsgi.status Nginx配置12345678910111213141516171819202122232425#more vhost.confuwsgi_cache_path /data/nginx/cache/blog levels=1:2 keys_zone=blog:20m max_size=1g;#uwsgi_cache_path /data/nginx/cache/image levels=1:2 keys_zone=image:20m max_size=1g;server &#123; listen 81; server_name www.zhuxyid.com; add_header X-Cache $upstream_cache_status;# location /static &#123; #如需开启nginx处理静态资源请求需注释## alias /www/blog/static;# expires 90d;# uwsgi_cache image;# uwsgi_cache_key $request_uri;# uwsgi_cache_valid 200 302 30m;# uwsgi_cache_valid any 1h;# &#125; location / &#123; include uwsgi_params; uwsgi_pass unix:///var/run/uwsgi.sock; #如果uwsgi在本地运行可以直接使用sock文件通讯，效率高 #uwsgi_pass 192.168.0.10:8000; #如果uwsgi在其他机器使用sock地址通讯 uwsgi_cache blog; uwsgi_cache_key $request_uri; uwsgi_cache_valid 200 302 30m; uwsgi_cache_valid any 1h; &#125;&#125;]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Nginx</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Systemd]]></title>
    <url>%2F2018%2F12%2F05%2FSystemd%2F</url>
    <content type="text"><![CDATA[SystemdSystemd是Linux系统中最新的初始化系统（init），如CentOS 7。它主要解决CentOS7之前的System V init的缺点，提高系统启动速度，Systemd的概念来自于MacOS上的Launchd System V介绍 Linux系统类似Windows一样可以自启动和禁止一些服务程序，在Syst V init的管理体系中，这些服务脚本程序存放在/etc/init.d文件下，在/etc存放rc0~rc6等目录指向init.d下的相应目录，这些目录下的文件即为不同运行级别需要启动或者禁止的服务。 System V有7个级别：runlevel0~runlevel7 级别 说明 0 关机状态，默认系统启动级别不能设置0，否则不能正常启动 1 单用户，无网络，用于系统维护，类似windows下的安全模式 2 多用户 3 完整多用户模式。 4 自定义，通常保留不用 5 图形模式，如果系统有安装GUI软件，XWindows会进入图形模式 6 重启系统，默认系统启动级别也不能设置6，否则不能正常启动 标准运行级别是3和5，可在/etc/inittab 下的id:{$levelnum}:initdefault:修改启动级别，如修改为3级别id:3:initdefault，下次启动后生效，Linux系统init进程会根据inittab配置文件确定当前运行级别并执行相应级别rc3 的服务脚本程序。 rc3目录下存放两种文件，一种S开头：表示启动服务，一种K开头：表示禁止服务，字母后面的数字表示启动顺序，按小到大执行 System V基本工具System V主要用chkconfig,service,命令管理服务，在使用命令前需要将相应服务脚本放在/etc/init.d目录下。 123456789101112131415161718192021222324#chekconfig格式chkconfig --add | --del | --list | --level &lt;levelnum&gt; &lt;servicename&gt; &lt;on|off|reset&gt; | &lt;servicename&gt;#实例:chkconfig --add httpd #添加httpd服务chkconfig --list #查看所有服务的启动级别chkconfig --del httpd #删除httpd服务chkconfig --level 35 httpd on #将httpd服务运行在3,5级别模式下，下次开机后生效#service格式service &lt;servicename&gt; start|stop|restart#实例service httpd startservice httpd stopservice httpd restart#如果需要修改启动优先级可以使用如下方法ln -s /etc/init.d/httpd /etc/rc.d/rc3.d/S60httpd #将httpd服务在init3级别下的开机启动优先级为60，值越大启动顺序越低#在ubuntu下可使用update-rc.d命令update-rc.d -f httpd removeupdate-rc.d httpd start 2 3 5 . stop 60 0 1 6 .#在235级别启动，优先级016级别关闭，优先级60，值越大启动顺序越低 Systemd介绍Systemd是Linux最新的初始化系统。取代了之前Unix时代一直使用的init系统，兼容Syst V init 和 LSB init script，而且在进程启动过程中更有效的引导加载服务。 在Systemd管理体系中，老的运行级别(runlevel)的概念被新的 运行目标(target) 所取代。 target命名类似multi-user.target这种形式。 old new runlevel3 multi-user.target runlevel5 graphical.target 在新版的CentOS上默认target是通过软连接形式实现 ln -s /lib/systemd/system/runlevel3.target /etc/systemd/system/default.target 在/lib/systemd/system/下面定义的runlevelX文件目的主要是为了兼容以前运行levelrunX的管理方式，实际是被链接到了multi-user.target Systemd特点 兼容SysVinit和LSB init scripts 更快的启动速度，以并发启动的原理 尽可能启动更少进程 尽可能将更多进程并行启动 提供按需启动能力 采用Linux的CGroup特性跟踪和管理进程的生命周期 启动挂载点自动挂载管理 实现事务性依赖关系管理 能够对系统进行快照和恢复 日志服务 能够向后支持SysV的服务脚本 特点说明： 按需提供能力 当Sysinit系统初始化的时候，它会将所有可能用到的后台服务进程全部启动运行，并且系统必须等待所有服务都启动就绪后才可以运行用户登录。 这种方式的缺陷启动时间过长，系统资源浪费。如果某些服务可能很长一段时间内或者运行期间没有被使用过的服务，如CPUS，如果花费在启动这些服务上的时间完全没有必要，对系统资源也是一种浪费。 Systemd可以按需启动，在某个服务被真正请求的时候才启动它，当服务结束时，systemd可以关闭它，在下次需要的时候在启动它 采用Linux的CGroup特性跟踪和管理进程的生命周期 init系统的一个重要职责就是负责跟踪和管理服务进程生命周期，它不仅可以启动一个服务，也必须也能停止一个服务，看上去没特别的，但是在真正用到代码实现的时候，获取就会发现停止服务比一开始想的要困难。 服务进程一般都会作为daemon在后台运行，为此服务程序有时会派生fork两次。在UpStart中，需要在配置文件中正确配置expect,这样Upstart通过对fork系统调用进行计数，从而获得真正的daemon PID 如果Upstart找错了，则会出现误杀死情况 还有特殊的情况，比如一个CGI程序会派生两次，从而脱离了和apache的父子关系，当apache进程被停止后，该CGI程序还继续运行，而我们希望服务停止后，所有由它所启动的相关进程也会被停止。为了处理这类问题，UpStart通过strace来跟踪fork和exit等系统调用，但是这种方式简单粗暴，且扩展性弱。Systemd则利用Linux内核CGroup特性来完成跟踪任务，当服务停止后，查询CGroup，Systemd可以确保找到所有相关的进程，从而干净停止服务。 CGroup提供能类似文件系统的接口，使用方便，主要实现系统资源配额管理。当创建子进程时，子进程会继承父进程的CGroup，因此无论服务如何启动新的子进程，所有这些相关的进程都会属于同一个CGroup。Systemd只需要简单的遍历指定的CGroup，即可正取找到所有相关进程，将它逐步停止 启动挂载点自动挂载管理 传统Linux系统中，用户可以用/etc/fstab文件来维护固定文件系统挂载点，这些挂载点在系统启动的过程中被自动挂载，一旦启动过程结束，这些挂载点会确保存在。挂载点是对系统运行至关重要的文件系统，如home目录。和SysVinit一样，Systemd管理这些挂载点，以便在系统启动时自动挂载它们，有时候用户还需要动态挂载，比如打算访问DVD内容时，才临时执行挂载一遍访问其内容，而不访问光盘时候，该挂载点被卸载umount以便节约资源，SysVinit依赖autofs服务来实现这种功能，Systemd内建自动挂载服务，无需额外安装autofs服务，可以直接用systemd提供的自动挂载管理能力来实现autofs功能。另外Systemd也兼容/etc/fstab文件，可以继续使用该文件管理挂载点 实现事务性依赖关系管理 系统启动过程是由很多独立组件共同组成，这些组件存在依赖关系，如果挂载一个NFS文件系统必须依赖网络才能正常工作，System虽然能够最大限度的并发执行很多依赖关系的工作，但是类似挂载NFS和启动网络这两个工作还是存在先后关系，无法并发执行，对于这些任务，Systemd维护一个’事物一致性‘’的概念，保证所有相关服务都可以正常启动而不会出现互相依赖，以至于死锁情况 能够对系统进程快照和恢复 Systemd支持按需启动，因此系统的运行状态是动态变化的，无法确定和准确知道系统当前运行了哪些服务，System快照提供了一种将当前系统运行状态保存并恢复的能力。 如系统当前正运行服务APP1和APP2，可以使用Systemd命令对当前系统运行状况创建快照，然后将APP1停止，或者做其他任意对系统的改变（如启动新的程序APP3），在改变后运行Systemd的快照恢复命令，即可立即将系统恢复到创建快照时候的状态，即只有APP1和APP2运行。常见场景：比如服务器出现一些异常，为了调试用户当前状态保存快照，然后可以任意操作，比如停止服务等，当调试完成后，恢复操作即可。（注意：改功能并不完善，使用时需要慎重） 日志服务 简单性：代码少，依赖少，开销最小 零维护：日志是排错和监控系统的核心功能，因此它自己不能再产生问题，比如自动管理磁盘空间，避免由于日志不断产生的磁盘空间耗尽 移植性：日志文件在所有类型的Linux系统可用 性能：添加 和 游览日志 非常快 最小资源占用：日志数据文件小 统一化：各种不同日志存储应该统一，将所有可记录事件保存在同一个数据存储中，所以日志内容的全局上下文都会被保存并且可供日后查看，如一条固件记录后通常会跟随一条内核记录，最终还有一条用户态记录。重要的是当保存到硬盘上时这三种关系不会丢失。早期Syslog会将不同信息保存到不同文件中，分析时候很难确定哪些条目是相关的 扩展性：日志使用范围广，嵌入式或者超级计算群集都可以满足 安全性：日志文件可以验证 Systemd基本概念Systemd单元概念系统初始化需要做很多事情。需要启动后台服务，如sshd服务，需要做配置工作，比如挂载文件系统，这个过程中每一步都被systemd抽象成一个配置单元，即unit，可以认为一个服务就是一个配置单元；一个挂载点是一个配置单元，一个交换分区配置是一个配置单元。systemd将配置单元归纳为以下不同的类型。 配置单元常见类型 类型 扩展名 说明 service unit .service 定义系统类服务 target unit .target 实现模拟“运行级别” device unit .device 定义实现内核识别设备 mount unit .mount 定义文件系统挂载点，利用logind服务，为用户会话进程分配CGroup资源 socket unit .socket 定义表示进程间通信的socket文件 snapshot unit .snapshot 管理系统快照 swap unit .swap 表示swap设备 automount unit .automount 文件系统自动挂载设备 path unit .path 定义文件系统中 timer unit .timer 定时器配置单元，用来定义触发用户定义的操作，取代了atd，crond等传统定时服务 Target和运行级别对应关系 Sys V init Systemd target 说明 0 poweroff.target 关机 1，s，single rescue.target 单用户 2，4 multi-user.target 用户定义，默认等同于3 3 multi-user.target 多用户，非图形化 5 graphical.target 多用户，图形模式 6 reboot.target 重启 emergency emergency.target 紧急shell Systemd并发启动原理 解决socket依赖 绝大多数的服务依赖是套接字依赖。比如服务 A 通过一个套接字端口 S1 提供自己的服务，其他的服务如果需要服务 A，则需要连接 S1。因此如果服务 A 尚未启动，S1 就不存在，其他的服务就会得到启动错误。所以传统地，人们需要先启动服务 A，等待它进入就绪状态，再启动其他需要它的服务。Systemd 认为，只要我们预先把 S1 建立好，那么其他所有的服务就可以同时启动而无需等待服务 A 来创建 S1 了。如果服务 A 尚未启动，那么其他进程向 S1 发送的服务请求实际上会被 Linux 操作系统缓存，其他进程会在这个请求的地方等待。一旦服务 A 启动就绪，就可以立即处理缓存的请求，一切都开始正常运行。 那么服务如何使用由 init 进程创建的套接字呢？Linux 操作系统有一个特性，当进程调用 fork 或者 exec 创建子进程之后，所有在父进程中被打开的文件句柄 (file descriptor) 都被子进程所继承。套接字也是一种文件句柄，进程 A 可以创建一个套接字，此后当进程 A 调用 exec 启动一个新的子进程时，只要确保该套接字的 close_on_exec 标志位被清空，那么新的子进程就可以继承这个套接字。子进程看到的套接字和父进程创建的套接字是同一个系统套接字，就仿佛这个套接字是子进程自己创建的一样，没有任何区别。 这个特性以前被一个叫做 inetd 的系统服务所利用。Inetd 进程会负责监控一些常用套接字端口，比如 Telnet，当该端口有连接请求时，inetd 才启动 telnetd 进程，并把有连接的套接字传递给新的 telnetd 进程进行处理。这样，当系统没有 telnet 客户端连接时，就不需要启动 telnetd 进程。Inetd 可以代理很多的网络服务，这样就可以节约很多的系统负载和内存资源，只有当有真正的连接请求时才启动相应服务，并把套接字传递给相应的服务进程。 和 inetd 类似，systemd 是所有其他进程的父进程，它可以先建立所有需要的套接字，然后在调用 exec 的时候将该套接字传递给新的服务进程，而新进程直接使用该套接字进行服务即可。 ###### 解决D-bus依赖 D-Bus 是 desktop-bus 的简称，是一个低延迟、低开销、高可用性的进程间通信机制。它越来越多地用于应用程序之间通信，也用于应用程序和操作系统内核之间的通信。很多现代的服务进程都使用D-Bus 取代套接字作为进程间通信机制，对外提供服务。比如简化 Linux 网络配置的 NetworkManager 服务就使用 D-Bus 和其他的应用程序或者服务进行交互：邮件客户端软件 evolution 可以通过 D-Bus 从 NetworkManager 服务获取网络状态的改变，以便做出相应的处理。 D-Bus 支持所谓”bus activation”功能。如果服务 A 需要使用服务 B 的 D-Bus 服务，而服务 B 并没有运行，则 D-Bus 可以在服务 A 请求服务 B 的 D-Bus 时自动启动服务 B。而服务 A 发出的请求会被 D-Bus 缓存，服务 A 会等待服务 B 启动就绪。利用这个特性，依赖 D-Bus 的服务就可以实现并行启动。 解决文件系统依赖 系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。但是 systemd 发现这种依赖也是可以避免的。 Systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open()系统调用作用在”/misc/cd/file1”的时候，/misc/cd 尚未执行挂载操作，此时 open()调用被挂起等待，Linux 内核通知 autofs，autofs 执行挂载。这时候，控制权返回给 open()系统调用，并正常打开文件。 Systemd 集成了 autofs 的实现，对于系统中的挂载点，比如/home，当系统启动的时候，systemd 为其创建一个临时的自动挂载点。在这个时刻/home 真正的挂载设备尚未启动好，真正的挂载操作还没有执行，文件系统检测也还没有完成。可是那些依赖该目录的进程已经可以并发启动，他们的 open()操作被内建在 systemd 中的 autofs 捕获，将该 open()调用挂起（可中断睡眠状态）。然后等待真正的挂载操作完成，文件系统检测也完成后，systemd 将该自动挂载点替换为真正的挂载点，并让 open()调用返回。由此，实现了那些依赖于文件系统的服务和文件系统本身同时并发启动。 当然对于”/“根目录的依赖实际上一定还是要串行执行，因为 systemd 自己也存放在/之下，必须等待系统根目录挂载检查好。 不过对于类似/home 等挂载点，这种并发可以提高系统的启动速度，尤其是当/home 是远程的 NFS 节点，或者是加密盘等，需要耗费较长的时间才可以准备就绪的情况下，因为并发启动，这段时间内，系统并不是完全无事可做，而是可以利用这段空余时间做更多的启动进程的事情，总的来说就缩短了系统启动时间 服务的循环依赖 Systemd 能保证事务完整性。Systemd 的事务概念和数据库中的有所不同，主要是为了保证多个依赖的配置单元之间没有环形引用，存在循环依赖，那么 systemd 将无法启动任意一个服务。此时 systemd 将会尝试解决这个问题，因为配置单元之间的依赖关系有两种：required 是强依赖；want 则是弱依赖，systemd 将去掉 wants 关键字指定的依赖看看是否能打破循环。如果无法修复，systemd 会报错。Systemd 能够自动检测和修复这类配置错误，极大地减轻了管理员的排错负担 基于path激活机制 判断一个文件在不在， 如果在可以立即激活一个进程或服务 System V init 和 Systemd命令对比 Sys V init Systemd 作用 service NAME start systemtl start NAME.service 启动 service NAME stop systemctl stop NAME.service 停止 service NAME restart systemctl restart NAME.service 重启 service NAME status systemtl status NAME.service 查看状态 service NAME condrestart systemctl condrestart NAME.service 条件重启 service NAME reload systemctl reload NAME.service 重载 不支持 systemctl is-active NAME.service 查看服务当前激活状态 chkconfig –list systemctl list-units -t service 查看所有已激活服务 不支持 systemctl list-units -t service -a 查看所有服务(包括未激活) chkconfig NAME on systemctl enable NAME.service 设置开机启动 chkconfig NAME off systemctl disable NAME.service 禁止开机启动 chkconfig –list NAME systemctl is-enabled NAME.service 查看服务是否开机启动 不支持 systemctl mask NAME.service 禁止服务设置开机启动 不支持 systemctl unmask NAME.service 取消禁止服务设置开机启动 不支持 systemctl list-dependencies NAME.service 查看服务依赖关系 修改/etc/inittab文件 systemctl set-default NAME.target 修改默认运行级别 init RUNLEVEL systemctl isolate NAME.target 切换系统运行级别 runlevel，who -r systemctl get-default 查看运行级别 Systemd 电源管理 命令 操作 systemctl reboot 重启 systemctl poweroff 关机 systemctl suspend 挂起 systemctl hibernate 休眠 systemctl hybrid 混合休眠模块（快照并挂起） Service unit file配置说明Systemd的相关配置文件路径 /etc/lib/systemd/system /run/systemd/system /etc/systemd/system 文件通常由三个部分组成 [Unit]： 定义与unit类型无关的通用选项，用于提供当前unit描述信息，unit行为以及依赖关系等 [Service]：定义与此处类型相关的专用选项，此类为service类型 [Install]：定义由systemctl enable或者systemtl disable命令在实现服务启动或禁止用到的选项 Unit 常用选项Description： 描述信。 After： 定义unit的启动次数，表示当前unit应该晚于哪些unit启动，功能和before相反 Requies： 依赖到其他units，强依赖，被依赖的units无法激活时，当前unit即无法激活 Wants： 指明依赖到其他的units，弱依赖，依赖的units无法激活时，当前unit无影响 Conflicts： 定义units见的冲突关系 Service 常用选项Type： 用于定义影execstart及相关参数的功能的unit进程启动 Simple： 由execstart启动的命令为主进程 Forking： 由execstart启动的命令，其中一个子进程会成为主进程，父进程会退出 onehot： 功能类似simple dubs notify： 类似于simple idle environmentfile： 启动时环境配置文件，为execstart提供变量 execstart： 指明启动unit要运行的命令或脚本，execstartpre，execstartpost execreload： 指明重载unit要运行的命令或脚本 execstop： 指明要停止units要运行的命令或脚本 restart： 指明要重启units要运行命令或脚本 Install 常用选项alias： requireby： 被那些units所依赖，强依赖 wantsby： 被那些units所依赖，弱依赖 注意：当对新创建的unit文件或修改了unit文件，都需要重载配置文件 systemctl daemon-reload]]></content>
      <categories>
        <category>Linux Basic</category>
      </categories>
      <tags>
        <tag>Systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2018%2F12%2F03%2FMongoDB%2F</url>
    <content type="text"><![CDATA[MongoDB介绍官方站点 MongoDB：适用海量存储，基于文档数据库，C++编写，开源产品，遵循GNU AGPL，支持OSX，Linux，Windows，Solaris。 MongoDB：适用于web站点，cacheing，高大数据量，高扩展场景，事物要求性不高的场景。 MongoDB面向集合的数据库 ： 数据库：但数据库无须创建 集合：无须事先定义，一个文档相当于mysql中的一行，集合相当于多个文档组成的，mongodb中集合是基本的操作单位 特点: 文档存储：利用json组织数据 性能好：c++，多索引支持，不支持事物（支持原子事务），基于内存（延迟写） 支持复制：类似mysql主从复制replication(废弃) 副本集复制auto-sharding 自动分片机制 支持map/reduce.可以实现并行查询处理 分布式文件系统 支持基于位置索引(空间) 商业支持，很多公司使用mongodb MongoDB可以文档嵌套,KEY/VALUE存储，存储格式JSON，实例 12345678910&#123; Name:tomcat Age:18 Gender:male Books:&#123; first:linux second:python &#125; Birthday:1990&#125; Mongodb架构1234C/S架构：mongod server端 mongo client端 mongo&gt;use tested 创建testdb数据库 MongoDB安装配置yum源码123456vi /etc/yum.repos.d/mongodb.repo [mongodb] name=MongoDB Repository baseurl=http://downloads-distro.[mongodb.org/repo/redhat/os/x86_64/](http://mongodb.org/repo/redhat/os/x86_64/) gpgcheck=0 enabled=1 查询MongoDB软件包12345yum search mongod* mongodb-org-mongos mongodb shareding mongodb-org-server mongodb服务端 mongodb-org-shell mongod客户端 mongodb-org-tools mongodb工具 安装mongodb1yum install mongodb 添加权限12useradd mongodchown -R mongod.mongod /data/mongo 启动mongodb1234server mongod start 或者:mongod -config /etc/mongod.conf 如果想访问mongod监控端口需要启动端口27017，28017(需要开启httpinterface)访问 http://192.168.2.21:27017 监控端口，显示mongodb信息 Mongod客户端mongo [option][db address] [file name] mongo 默认连接127.0.0.1:27017 默认没有用户密码认证 例子： 123456789mongo 192.168.2.21 MongoDB shell version: 2.6.12 connecting to: 192.168.2.21/test Welcome to the MongoDB shell. For interactive help, type "help". For more comprehensive documentation, see &lt;http://docs.mongodb.org/&gt;Questions? Try the support group &lt;http://groups.google.com/group/mongodb-user&gt; MongoDB常用命令12345mongodb常用的命令mongodump mongodb备份mongorestore mongodb恢复mongoexport mongodb导出mongoimport mongodb导入 MongoDB配置文件mongodb配置文件在/etc/mongod.conf下 123456789101112131415161718192021222324252627282930313233343536373839more /etc/mongod.conflogpath=/var/log/mongodb/mongod.log #mongodb日志路径 logappend=true #是否以追加方式存储日志 fork=trueport=27017 #默认端口2701 dbpath=/data/mongo #mongodb数据存储目录 pidfilepath=/var/run/mongodb/mongod.pid #mongodb pid文件 bind_ip=127.0.0.1 #绑定地址 # Disables write-ahead journaling # nojournal=true # Enables periodic logging of CPU utilization and I/O wait # cpu=true # Turn on/off security. Off is currently the default # noauth=true # auth=true # Verbose logging output. # verbose=true # Inspect all client data for validity on receipt (useful for # developing drivers) # objcheck=true # Enable db quota management # quota=true # Set oplogging level where n is # 0=off (default) # 1=W # 2=R # 3=both # 7=W+some reads # diaglog=0 # Ignore query hints # nohints=true httpinterface=true #是否启用http监控接口，端口是28017 # noscripting=true # notablescan=true # noprealloc=true # nssize=&lt;size&gt; # replSet=setname #mongod 副本集名称 # oplogSize=1024 #oplog大小 # keyFile=/path/to/keyfile MongoDB 使用MongoDB基本使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182mongo 192.168.2.21&gt;helpdb.help() db方法 帮助db.mycoll.help() 集合方法 帮助sh.help() sharding 帮助rs.help() 复制集 帮助help admin administrative helphelp connect connecting to a db helphelp keys key shortcutshelp misc misc things to knowhelp mr mapreduceshow dbs 查看数据库名show collections 查看集合名词show users show users in current databaseshow profile show most recent system.profile entries with time &gt;= 1msshow logs show the accessible logger namesshow log [name] prints out the last segment of log in memory, 'global' is defaultuse &lt;db_name&gt; 设置使用数据库db.foo.find() list objects in collection foodb.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1it result of the last line evaluated; use to further iterateDBQuery.shellBatchSize = x set default number of items to display on shell&gt;use study #无须创建，直接使用数据库&gt;db.studycoll.insert(&#123;name:"zhuxy"&#125;) #创建studycoll集合插入数据&gt;db.zhuxy.insert(&#123;name:"zhuyue"&#125;) #创建zhuxy集合插入数据&gt;show collections #查看collectionsstudycollzhuxysystem.indexes&gt;db.getCollectionNames() #以列表方式查看collection[ "studycoll", "system.indexes", "zhuxy" ]&gt;show dbsadmin (empty)local 0.078GBstudy 0.078GBtest (empty)&gt;db.studycoll.find() #在studycoll集合中查询数据&#123; "_id" : ObjectId("5981309eceaab5cdd6507bb9"), "name" : "zhuxy" &#125;#说明(id,对象id号(唯一的，如果添加逐步+1)&gt;db.studycoll.insert(&#123;name:"yukw',age:19,books:[211,'NJAU']&#125;) #studycoll集合插入数据WriteResult(&#123; "nInserted" : 1 &#125;)&gt;db.studycoll.find().count() #查找统计2&gt;db.studycoll.stats() #查看状态&#123; "ns" : "study.studycoll", "count" : 4, "size" : 192, "avgObjSize" : 48, "storageSize" : 8192, "numExtents" : 1, "nindexes" : 1, "lastExtentSize" : 8192, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 8176, "indexSizes" : &#123; "_id_" : 8176&#125;,"ok" : 1&gt;db.studycoll.drop() #删除studycoll集合true&gt;show collections #查看集合system.indexs&gt;show dbs #虽然删除studycoll集合，但是数据库study依然存在admin (empty)local 0.078GBstudy 0.078GBtest (empty) MySQL和MongoDB语法比较INSERT插入123mysql&gt;insert into studycoll(name, age,status) value (&apos;zhuxy&apos;,&apos;19&apos;,&apos;A&apos;)mongodb&gt;db.studycoll.insert(&#123;name:&apos;zhuxy&apos;,age:19,status:&apos;A&apos;&#125;) SORT排序1234mysql&gt;select * from studycoll where age &gt; 18mongodb&gt;db.studycoll.find(&#123;age:&#123;$gt:18&#125;&#125;).sort(&#123;age:1&#125;)#查询age大于18的数据，并排序(从小到大，如果-1从大到小),显示所有字段 SELECT查询1234mysql&gt;select name, gender from studycoll where age &gt; 18 limit 5mongodb&gt;db.studycoll.find(&#123;age:&#123;$gt:18&#125;&#125;,&#123;name:1,gender:1&#125;).limit(5)#显示name和gender并且年龄大约18 UPDATE更新1234mysql&gt;update studycoll set status=&apos;A&apos; WHERE age &gt; 18 mongodb&gt;db.studycoll.update(&#123;age:&#123;$gt:18&#125;&#125;,&#123;$set:&#123;gender:&apos;body&apos;&#125;&#125;,&#123;multi:true&#125;)#如果multi不实true，只修改第一个符合条件的 DELETE删除123mysql&gt;delete from studycoll where status=&apos;D&apos; mongodb&gt;db.studycoll.remove(&#123;status:&apos;D&apos;&#125;) AND方法12345mysql&gt;select * from studycoll age &gt; 70 and age &lt; 75 mysql&gt;select name,gender from studycoll age &gt; 70 and age &lt; 75mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:70&#125;&#125;,&#123;age:&#123;$lt:75&#125;&#125;]&#125;) mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:79&#125;&#125;,&#123;age:&#123;$lt:75&#125;]&#125;,&#123;name:1,gender:1&#125;) 关系型数据库和MongoD RDBMS Mongo table.view collection row Json Document index index join embedded partition shard partition key(分区键) shard key(分片键) MongoDB高级操作批量插入123mongodb&gt;for(i=1;i&lt;=100;i++) db.studycoll.insert(&#123;name:&quot;User&quot;+i,age:i,gender:&quot;M&quot;,books:[&apos;linux&apos;,&apos;python&apos;]&#125;) mongodb&gt;db.studycoll.find()#只能显示20，如果像继续显示输入it find mongodb查询操作支持挑选机制，comparison，logical，element，javascript等几类 comparison比较运算符1234567$gt 大于&#123;filed:&#123;$gt:value&#125;&#125; $gte 大于等于 $in 挑选指定字段位于指定数组&#123;filed:&#123;&lt;value1&gt;,&lt;values2&gt;&#125;&#125; $lt 小于 $lte 小于等于 $ne 不等于 $nin 挑选指定字段的值不位于指定数组 logical逻辑运算符1234$or 或&#123;$or:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; $and 与&#123;$and:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; $not 非&#123;filed:&#123;$not:&#123;&lt;operator&gt;&#125;&#125;&#125; $nor 反&#123;$nor:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; element元素查询12345$exists #根据指定字段存在性挑选文档，语法格式&#123;filed:&#123;$exists:&lt;boolean&gt;&#125;&#125;,指定&lt;boolean&gt;的值为true，则返回存在指定字段的文档，false则返回不存在指定字段的文档 $mod #将指定字段的值进行取模运算，并返回其余数为指定值的文档,语法&#123;filed:&#123;$mod:[divisor,remainder]&#125;&#125; $type #返回指定字段的值类型为指定类型的文档，语法&#123;filed:&#123;$type:&lt;BSON tye&gt;&#125;&#125; int,str... exists用法查询有address字段的文档 1234567mongodb&gt;db.studycoll.find(&#123;address:&#123;$exists:true&#125;&#125;) mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:80&#125;&#125;,&#123;address:&#123;$exists:false&#125;&#125;]&#125;) #查询age大于80，并且没有address字段mongodb&gt;db.studycoll.update(&#123;age:&#123;$gt:70&#125;&#125;,&#123;$set:&#123;gender:&apos;F&apos;&#125;&#125;,&#123;multi:true&#125;)#将age大于70，性别改成F updateupdate参数使用格式独特，其仅能包含使用update专有操作符来构建表示式，其中大致包含‘filed’,’array’,’bitwise’ filed类常用操作 1234567$inc #增大指定字段,格式&#123;field:value&#125;,&#123;$inc:&#123;field1:amount&#125;&#125;,其中&#123;field"value&#125;用于指定挑选标准，&#123;$inc:&#123;filed:amunt&#125;&#125;指定要提升其字段及提升大小amount $rename #更改字段名,格式&#123;$rename:&#123;&lt;old name1&gt;:&lt;new name1&gt;,&lt;old name2&gt;:&lt;new name2&gt;&#125;&#125; $set #修改字段值为新指定值,格式&#123;field:value1&#125;,&#123;$set:&#123;filed1:value1&#125;&#125; $unset #删除指定字段,格式&#123;filed:value&#125;,&#123;$unset:&#123;filed1:""&#125;&#125; 总结1234567891011121314151617181920212223242526272829301，mongodb常用方法CRUD db.COLL_NAME.METHOD C:insert() R:find() U:update() D:remove() 2，用JSON格式文档:&#123;key:value,key:value&#125; insert(&#123;&#125;) find(&#123;&#125;,&#123;&#125;). limit() sort() count() skip() update(&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;multi:true&#125;) remove(&#123;&#125;) 3,删除collection db.collName.drop 4,删除database use databasename db.dropDatabase() mysql database--&gt;table--&gt;row mongodb database--&gt;collection--&gt;document 索引假设从一百万条数据，在关系型数据库中，找到一个数值改怎么办？难道全表扫描？ 推荐读:“关系型数据库索引设计与优化” 这本书介绍如何设计索引：(索引也会带来坏处)，数据库使用索引，保存的索引文件占用资源，如果数据被修改，索引也应该需要修改，降低写入性能，有利必有弊。 需要根据现有的环境来确定是否使用索引： 如果数据量小，无需索引，如果创建索引反而变慢 如果数据量多，需要根据查询的条件来决定是否创建 简单索引 或者 组合索引 如果数据量海量，创建索引没有意义 索引是什么 在关系型数据库中，索引是一种单独的，物理的对数据库表中一列或多列的值进行排序的一种存储结构，是某个表中一列或者若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单 作用相当于图书目录，可根据目录中的页码快速找到所需内容 索引优点 1，减少服务器需要扫描的数据量 2，索引可以帮助服务器避免排序或者使用临时表 3，可以将随机i/o转化成顺序i/o 索引级别 1星：索引如果能将相关的记录放置在一起，降低I/O，入门级别 2星：索引中数据的存储顺序与查找标准中顺序一致。 3星：如果索引中保护查询中所需要的全部数据，(覆盖索引)。 索引类别： 顺序索引 散列索引:将索引映射至散列桶上，映射是通过散列函数进行的 评估索引标准： 访问类型：范围查找用顺序索引，等值查找用散列 访问时长 插入时长 删除时长 空间开销 顺序索引 聚集索引。如果某记录文件中的记录顺序是按照对应的搜索码指定的顺序排序，聚集索引也叫主索引。不需要二次i/o，找到键就找到行了。 非聚集索引。搜索码中的指定次序与记录文件中的记录次序不一致，叫非聚集索引，需要找到键，在寻找指针指定的行。 有聚集索引的数据文件，也叫做索引的顺序文件。 根据索引中是否为每个记录相应的创建索引项：稠密索引 和 稀疏索引 多级索引: 一级索引指向二级索引，二级索引指向行 辅助索引必须是稠密索引 B+树索引: Balance Tree:平衡树索引 MYISAM是非聚集索引 InnoDB是聚集索引(数据文件和索引文件在一个文件中) 顺序索引的特性：全值匹配：Name=”user12” 匹配最左前缀：Name like “User1%”, 无效：Name LIKE “%User1%” 匹配列前缀：Name like “User1%”, 无效：Name LIKE “%User1%” 匹配范围值： 精确匹配某一列并范围匹配另一列 只访问索引的查询：覆盖查询 组合索引特性： 如果索引是这样的(Name,Age), 那么Age &gt; 80无效，最左查找的; 如果Age&gt;80 and Name = “user12”有效 散列索引：不适合范围查询，适合精确值查询 散列函数 分布要随机 分布要均匀 适用场景： ​ 精确匹配： =,IN(),&lt;=&gt; MySQL索引只有MyISAM存储引擎支持，可以借助sphinx,lucense实现 空间索引，必须使用空间索引函数获取相应的查询结果，MyISAM支持 主键（值不能相同，也不能为空） 唯一键（值不能相同，可以为空） mysql创建索引12345创建索引：CREATE INDEX index_name ON table (col1,...)添加索引：ALTER TABLE ADD INDEX 删除索引：ALTER TABLE DROP INDEX DROP INDEX index_name FROM TABLE查看索引：SHOW INDEXS FROM TABLE MongoDB支持的索引 简单索引 组合索引 多键索引 空间索引 全文索引 哈希索引 MongoDB索引操作1234567891011121314151617181920212223242526272829db.studycoll.find(&#123;name:&quot;User49&quot;&#125;).explain()#explain()语法说明,如果没创建索引会全表扫描db.studycoll.ensureIndex(&#123;name:1&#125;)#创建name索引db.studycoll.find(&#123;name:&apos;User49&apos;&#125;).explain()#再次查看不会全表扫描了db.studycoll.find(&#123;name:&apos;user49&apos;&#125;).hint(&#123;name:1&#125;).explain()#指定什么索引查询db.studycoll.ensureIndex(&#123;name:1,age:1&#125;,&#123;unique:true&#125;)#创建组合索引name和age. 1表示升序排序，-1表示降序排序db.studycoll.ensureIndex(&#123;name:1&#125;,&#123;background:true&#125;)#background:true表示后台执行索引(如果数据量大的情况下使用该选项)db.studycoll.getIndexes()&#123;&quot;v&quot; : 1,&quot;unique&quot; : true,&quot;key&quot; : &#123; &quot;name&quot; : 1, &quot;age&quot; : 1&#125;, &quot;name&quot; : &quot;name_1_age_1&quot;, &quot;ns&quot; : &quot;study.studycoll&quot;&#125; MongoDB复制mongodb复制架构 早期mongodb使用类似mysql复制功能，但是发现主不能故障转移 Replica Set复制集(副本集)，类似mysql复制功能，可实现故障转移功能 mongodb官方不建议使用主从方式 Replication Options 副本集相关选项： replSet #指定副本集名称 oplogsize #操作日志大小，在64位系统下，默认是可用磁盘空间的5%，如果mongodb初始化后，后期修改oplog是不生效的 fastsync #快速同步，类似后台复制 replIndexPrefetch #mongodb2.2才能实现，指定副本集的索引预取，可以让复制过程更为高效 ​ replIndexPrefetch {none | _id_only | all} non 不预取任何索引，_id_only预取id索引，all预取所有索引 副本集架构时间要同步，replset名称一致，确保mongodb能交互 部署配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687环境：192.168.2.10 主192.168.2.11 从192.168.2.12 从三台需要时间同步，需要安装mongod,配置文件需要添加#vi /etc/mongod.confbind_ip = 192.168.2.10 #监听端口，每个服务器绑定自己的ipreplSet = MyRs0 #三台保持一致,副本名称启动mongod群集，三台都需要启动192.168.2.10&gt;rs.help()&gt;rs.initiate() #初始化rs&#123;&quot;info2&quot; : &quot;no configuration explicitly specified -- making one&quot;,&quot;me&quot; : &quot;192.168.2.10:27017&quot;,&quot;info&quot; : &quot;Config now saved locally. Should come online in about a minute.&quot;,&quot;ok&quot; : 1&#125;MyRs0:PRIMARY&gt;rs.status() #查看rs状态MyRs0:PRIMARY&gt;rs.isMaster() #查看是否是主节点MyRs0:PRIMARY&gt;rs.add(&quot;192.168.2.11:27017&quot;) #添加2.11节点MyRs0:PRIMARY&gt;rs.add(&quot;192.168.2.12:27017&quot;) #添加2.12节点添加从节点后，开始插入数据，只有PRIMARY可以添加数据MyRs0:PRIMARY&gt;use studyMyRs0:PRIMARY&gt;for(i=1;i&lt;1000;i++) db.studycoll.insert(&#123;name:&apos;user&apos;+i,age:i,gender:&apos;F&apos;&#125;)192.168.2.11 注意从节点不可写MyRs0:SECONDARY&gt;rs.isMaster() #在从节点查看主从信息 &#123; &quot;setName&quot; : &quot;MyRs0&quot;, &quot;setVersion&quot; : 3, &quot;ismaster&quot; : false, #是否是主节点 &quot;secondary&quot; : true, #是否是从节点 &quot;hosts&quot; : [ &quot;192.168.2.10:27017&quot;, &quot;192.168.2.11:27017&quot;, &quot;192.168.2.12:27017&quot;], &quot;primary&quot; : &quot;192.168.2.10:27017&quot;, #主节点地址 &quot;me&quot; : &quot;192.168.2.11:27017&quot;, #从节点本身 &quot;maxBsonObjectSize&quot; : 16777216, &quot;maxMessageSizeBytes&quot; : 48000000, &quot;maxWriteBatchSize&quot; : 1000, &quot;localTime&quot; : ISODate(&quot;2017-08-04T06:26:25.430Z&quot;), &quot;maxWireVersion&quot; : 2, &quot;minWireVersion&quot; : 0, &quot;ok&quot; : 1&#125;MyRs0:SECONDARY&gt; rs.slaveOk() #如果从需要访问数据，需要输入rs.slaveOk()MyRs0:SECONDARY&gt; use studyMyRs0:SECONDARY&gt; db.studycoll.find().count()MyRs0:SECONDARY&gt; db.studycoll.insert(&#123;name:&quot;hello&quot;&#125;) #这里从不可以写WriteResult(&#123; &quot;writeError&quot; : &#123; &quot;code&quot; : undefined, &quot;errmsg&quot; : &quot;not master&quot; &#125; &#125;)注意：如果192.168.2.10下线，这里会自动选举PRIMARY,如果192.168.2.10上线，不会将其转变成PRIMARY, 上线后变成SECONDARY，需要rs.slaveOk()才可以读取数据如果需要将192.168.2.10下线后，再次上线自动提升PRIMARY需要修改优先级需要在PRIMARY修改配置文件MyRs0:PRIMARY&gt;mycnf = rs.conf() #rs.conf是配置主从的配置文件，mycnf是自定义配置文件 &#123; &quot;_id&quot; : &quot;testrs0&quot;, &quot;version&quot; : 3, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;host&quot; : &quot;192.168.2.21:27017&quot; &#125;, &#123; &quot;_id&quot; : 1, &quot;host&quot; : &quot;192.168.2.23:27017&quot; &#125;, &#123; &quot;_id&quot; : 2, &quot;host&quot; : &quot;192.168.2.25:27017&quot; &#125; ] &#125;MyRs0:PRIMARY&gt;mycnf.members[0].priority=2 #members指定_id号码，priority是优先级MyRs0:PRIMARY&gt;rs.reconfig(mycnf) #重现加载自定义配置文件mycnfMyRs0:PRIMARY&gt;rs.conf() #查看配置文件 Mongod Shardingmongod副本集 不能降低I/O的请求，只是把数据复制一份到另外一台机器，考虑到后期高并发高吞吐量场景或者数据大于物理磁盘的时候，就需要使用sharding分片 shareding只是将大数据切割成小数据分散至其他机器上。降低i/o压力 Sharding目的： 数据系统巨大和高吞吐量高 高并发的查询会耗尽cpu的资源 sharding可以降低单台服务器的I/O压力 Sharding架构 router 跟config server通讯(router可以有一个，可以有多个) config server 存储元数据(分区键)，在生产环节中建议使用三个config server，一个单点故障，两个不方便选举 share 数据 注意事项： 做sharding对写操作最好做到分散,降低写压力, 对读操作最好不要做到分散,才能降低i/o压力 所以最好做到，写尽可能离散，读尽可能不离散。选择一个合理的分区键(通常使用组合键进行切割)。 环境部署12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667环境说明：router(mongos) 1个 192.168.2.10 config server 1个 192.168.2.11 shard 2个 192.168.2.12:27017 / 192.168.2.12:27018(需要注释httpinterface,因为这里只是用做测试) 1、配置config server192.168.2.11默认监听端口27019端口，可以使用如下命令启动mongod进程#mongod --configsvr --dbpath &lt;path&gt; --port &lt;port&gt;也可以编辑配置文件#vi /etc/mongod.confdbpath = /data/mongoconfigsvr = true启动mongod后使用的端口是27019#mongod -f /etc/mongod.conf2、配置mongos实例192.168.2.10mongos属于轻量级应用，完全可以与其他服务运行同一节点，启动时，需要为mongos实例指明各config服务器访问地址默认情况下，mongos监听27017端口，可以使用如下命令启动mongos实例#mongos --configdb &lt;config server hostnames((ip|hostname):port)&gt;也可以直接编辑配置文件#vi /etc/mongod.conf#dbpath = /data/mongo #需要注释该选项，这里只是用到mongosconfigdb = 192.168.2.11:27019启动mongos, 使用27017#mongos -f /etc/mongod.conf3、配置各副本集或独立的mongod实例配置192.168.2.12:27017 192.168.2.12:270184、向分区集群中添加各shard服务器或副本集192.168.2.11mongo -host 192.168.2.114.1、添加方式使用mongo命令连入mongos实例，命令如下#mongo --host &lt;hostname of machine running mongos&gt; --port &lt;port mongos listens on&gt;&gt;sh.addShard() #方法添加各shard至群集中如果添加shard是副本集，则需要使用&gt;sh.addShard("RS_NAME/RS_SERVER:PORT") &gt;sh.addShard("MyRS/192.168.2.10:27017")如果添加shard是独立的mongod实例，则需要使用&gt;sh.addShard("RS_SERVER:PORT") &gt;sh.addShard("192.168.2.12:27017") &gt;sh.addShard("192.168.2.12:27018")&gt;sh.status() #查看状态&gt;sh.enableSharding('database') #sharding那个数据库&gt;sh.sharedCollection('database.collection',&#123;filed:1,filed1:1&#125;) #sharding那个集合,集合的索引是那个字段&gt;sh.status()&gt;for(i=1;i&lt;=100000;i++) db.collection.insert #批量插入数据(&#123;name:'user'+i,age:(i%150),address:i+"#"+"nanjing",book:['linux','python']&#125;)&gt;sh.help() #查看shared的帮助命令&gt;sh.setBalancerState() #设置均衡&gt;h.getBalancerState() #查看是否是均衡状态 总结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364重复索引： 避免重复索引选择合适的索引，比如一个表有"name,age,gender,address"，那么通常查询name和age，则可以使用组合索引name和age，不要只创建name索引在创建一个age索引覆盖索引: name,age 能在索引中直接查到数据的叫覆盖索引。查看有没有用索引mongod&gt;db.mycoll.find().hint().explain() #hint()指明什么索引，explain()分析查找 mysql&gt;explain select * from tables;通常mongod所需要做的工作#复制集群 master/slave replica /set arbiter:仅参与选举，不持有数据， 0优先级节点：持有数据，参与选举，单不能成为主节点， Replica/set群集需要注意 配置文件replSet=RsName 初始化，添加节点。 #sharding分片 目的:单个节点数据集太大 如果单个节点读写请求，并发请求量较大 读，写 读，不离散 写，离散mongodb，collection级别sharding key；colletion索引选择sharding key需要考虑的标准 应该在哪存数据？ 应该在哪得到希望的数据？ 基本法则 sharding key应该是主键 sharding key应该能尽量保证跨分片查询 chunk：64m 越小越容易迁移rebalance：重新均衡sharding:新增shard，移除shardmongodb常用的命令mongodump mongodb备份mongorestore mongodb恢复mongoexport mongodb导出mongoimport mongodb导入mongodb的监控信息mongostat\mongotopinsert query update delete getmore command vsize res faults netIn netOut conn repl timevsize虚拟内存res实际内存集 mongooplog mongodb的日志mongoperf性能评估mongofiles修改GridFS文件系统]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL简单介绍]]></title>
    <url>%2F2018%2F12%2F03%2FNoSQL%2F</url>
    <content type="text"><![CDATA[NoSQLNoSQL解决大数据处理问题： 并行数据库：水平切分，分区查询 NoSQL数据库管理系统：非关系型模型，分布式，不支持ACID数据库设计范式 关系型数据库中的ACID： Atomicity原子性，一个事物中所有操作都必须全部完成，要么全部不完成 Consistency一致性，事物在开始或结束时，数据库应该在一致状态 Isolation隔离性，事物将设定只有它自己操作数据库，彼此不知晓 Durability持久性：一旦事物完成，就不能返回 大数据分析处理： MapReduce:映射成键值，分析在集合处理 CAP:任何分布式系统只能满足两种 Consistency：一致性 Availability：可用性 Partition tolerance：分区容错性 BASE：不同ACID模型，牺牲数据一致性，获得可用性或可靠性 Basically Available：基本可用性 Soft state：软状态 状态可以有一段时间不同步，异步 Eventually consistent：最终一致性，最终一致，不是实时一致 因果一致性 会话一致性 读 自己写一致性 单调读一致性 时间轴一致性 ACID对比BASE ACID：强制一致性隔离性，采用悲观保守方法，难以变化 BASE：弱一致性，可用性优先，采用乐观的方法，适应变化，更简单，更快 数据一致性的实现技术： NRW，2PC，Paxos，Vector Clock NoSQL特点 简单数据模型（KEY，VALUE）结构 元数据和数据分离 弱一致性 高吞吐量 较高水平扩展能力 低端硬件群集 NoSQL缺点 功能太单一，没有统一查询模型 不支持ACID设计范式（对事物要求高的不要使用） NewSQL继承关系型数据库，NoSQL 比如：Clustrix，GenieDB，ScaleBase，NimbusDB，Drizzle 适用云环境都归类到NewSQL 元数据管理系统：DBaas 数据存储模型：详键：http://www.nosql-database.org 列式存储模型:hadoop/Hbase,Hypertable 文档存储模型:mongoDB ElasticSearch 键值存储模型:redis,Berkeyley DB 图形数据模型:Noe4j,Sparksee 多维数据模型:ArangoDB,OrientDB 对象数据库:Versant,db4o 网格/云数据解决方法:GridGain 列式存储模型： 应用场景：在分布式文件系统之上支持随机读写分布式数据存储 典型产品：Hbase ,Hypertable,Cassandra 数据模型：以列为中心进行存储，将同一列数据存储在一起 优点：快速查询，高可扩展性强，易于实现分布式扩展 文档存储模型： 应用场景：非强事务需求的web应用 典型产品：mongoDB,ElasticSearch(通常存储日志)，CouchDB,CounchDB Server 数据模型：键值模型，存储为文档 优点：数据模型无须实现定义 键值存储模型: 应用场景：用于内容缓冲，用于大量并行数据访问的高负载场景 典型产品：Redis，dynamoDB,Riakn,Memcachedb(不是memcached) 数据模型：基于哈希表实现的key-value模型 优点：查询/写入迅速，数据没有结构 图式存储模型： 应用场景：社交网络，推荐系统，管系统等，如位置定位 典型产品：Neo4j,infinite graph 数据模型：图式结构 优点：适用图式计算场景]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2018%2F12%2F02%2FZabbix%2F</url>
    <content type="text"><![CDATA[Zabbixzabbix是一种开源监控软件，能实现各种强大监控功能（数据采集，展示，报警）等功能。 监控的过程 数据采集—&gt;数据存储—&gt;数据显示 时间序列数据（趋式，陡式），采集点连成线会生成数据趋式图 报警:采集到的数据超出阈值（如系统应用指标，文件变化，应用状态） Zabbix监控实现zabbix可使用Zabbix-Agent，ICMP，SNMP，HTTP，JMX，IPMI来监控客户端 IPMI(interlligent platform management interface)智慧平台管理接口，原本是一种inter架构企业系统的周边设备采用的一种工业标准 IPMI也是一个开放免费标准，使用者无需支付额外费用就可以使用 通常一些服务器如DELL,IBM支持这种接口 Zabbix可监控对象设备/软件： 设备：服务器，路由交换设备，IO设备 网络设备：snmp，ssh，ipmi 软件：操作系统，网络，应用 支持操作系统有：linux，windows，freebsd，aix，solaris，hp-unix 偶发现故障: 主机down机,服务不可用,主机不可达 严重事件: 数据节点宕机,磁盘满等 主机性能指标: 趋势数据(时间序列): SNMP协议架构： C/S架构：被监控端(Agent)，监控端(NMS), udp协议：Agent：161端口，NMS：162端口 工作模式: NMS向Agent采集数据 Agent向NMS报告数据 NMS请求Agent修改配置 组件: MIB（管理信息库）management information base OID(object id) SMI（MIB表示符） NMP协议 SNMP说明​ NMS可发起对Agent操作有：GET，GETNEXT，SET，TRAP ​ SNMP中的MIB定义被管理对象的一系列信息，每个Agent都有本地MIB库 ​ Agent操作：Response ​ SNMP仅仅实现数据采集功能 SNMP协议版本snmp版本有v1，v2，v3 V1：无验证 V2C：社区，NMS-&gt;Agent 双方共享一个秘钥，认证过程明文 V3：实现认证加密和解密功能，但是用的少 Linux实现snmp是net-snmp程序包 Windows实现snmp是在控制面板中找到程序SNMP 开源监控工具对比Cactiphp实现利用SNMP收集数据即使绘图展示，报警功能不够理想 cacti仅关注数据收集，数据展示，但是对报警功能较弱 cacti利用RRD库(round robin database)环状数据库，只能保存固定时长 Nagios仅关注是否超出阈值,监控功能强大(短信,网关等),可以报警升级,也可以维护时间暂停报警,定义各组件依赖关系,不适合大规模监控 nagios只是关注超出阈值状态转换，完成报警 如果需要增加图标显示需要安装pnp4nagios插件，如果需要存数据库需要NDOUtils，如果需要分布式需要NSCA icinga是Nagios变种 Zabbix能够实现各种强大监控功能（数据采集，展示，报警等） 支持MySQL，PgSQL，Oracle，DB2，SQLite 其他监控软件 OpenNMS ZenOS GangLia 强大的集合绘图，将多个主机组成一个趋势图 Open-Falcon 小米开源监控系统 Zabbix监控功能 zabbix agent，snmp，ping，ssh，ipmi，web监控,数据库监控,内部监控,内部支持复杂计算,自定义命令监控 zabbix agent，snmp，ipmi可以监控CPU、内存、网络、磁盘、服务、日志、文件监控 web监控可以监控到 响应时间、下载速度、响应代码、获取特定要求内容、支持http/https 报警方式:email、sms、jabber、chat message、自定义命令 Zabbix组件 zabbix-server：（C） zabbix-agent：（C） zabbix-web：GUI接口设定展示zabbix（php） zabbix-proxy:分布式监控环境中专用组件(大规模才能用到) Zabbix安装配置需求 版本 平台 cpu/内存 数据库 监控主机 Small ubuntu linux PII 350MHz 256M SQLite 20 Medium ubuntu linux64 bit AMD Athlon 3200+ 2G MySQL InnoDB 500 Large ubuntu linux64 bit Inter Dual Core6400 4G RAID10 MySQL InnoDB or PostgreSQL &gt;1000 Very large RedHat Enterprise Inter Xeon 2*CPU 8G Fatst RAID10 MySQL or PostgreSQL &gt;10000 zabbix数据 配置数据：很小 历史数据：50bytes/1m 历史趋势数据：128bytes/1m 事件数据：130bytes/1m 通常五分钟采集一次，一个监控项目就是320bytes，一小时3.8KB，一年就是34M，一台机器34M zabbix数据计算公式假设，如果一个主机60个监控项，1k个主机就是6万个监控项目。zabbix database需要用到的空间，60000/60 = 1000条，默认90天，趋势图默认一年 历史数据 历史数据 = 天数 x 每秒处理数据量 x 24 x 3600 x 50Bytes 每个历史数据50bytes 90x1000x24x3600x50 三个月产生360G数据 趋势数据 趋势数据 = 天数 x 监控项数 x 24 x 128bytes 每个趋势数据大概128bytes，按小时保存，假设保存一年 365x6000x24x128 一年大概62G数据 事件数据 事件数据 = 天数 x 86400 X 130bytes 每个事件数据大概130bytes，假设保存一年 365 x 86400 x 130bytes 一年大约3G数据 每分钟取一次数据，每秒请求数据大概千次，数据库写压力巨大（建议，监控5分钟取一次） Zabbix安装yum安装1234#需要实现安装mysql or PostreSQLyum install mysql-serverrpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/6/x86_64/zabbix-release-3.2-1.el6.noarch.rpmyum install zabbix-agent zabbix-get zabbix-java-gateway zabbix-proxy-mysql zabbix-sender zabbix-server-mysql zabbix-web zabbix-web-mysql 源码安装下载zabbix源码包 123#需事先安装好LAMP平台，编译zabbix同时安装server和agent，并支持将数据放入mysql数据库中./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-ssh2make &amp;&amp; make install 安装Server端， 1./configure --enable-server --with-mysql --with-net-snmp --with-libcurl 安装Agent端 1./configure --enable-agent --with-ssh2 导入数据库 1234567#导入数据库顺序(schema.sql，images.sql，data.sql)CREATE DATABASE zabbix CHARACTER SET UTF8;GRANT ALL PRIVILEGES ON zabbix.* TO &apos;zabbix&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;zabbixpass&apos;USE zabbix;source schema.sqlsource images.sqlsource data.sql Zabbix配置文件Zabbix-Server端123456789101112131415161718192021222324#/etc/zabbix/zabbix_server.confLogFile=/tmp/zabbix_server.log #日志文件LogFileSize=0 #不做日志滚动DBHost=127.0.0.1DBName=zabbixDBUser=zabbixDBPassword=zabbixpassDBPort=3306StartPollers=5 #启动poller进程多少个,各agent拉取对应指标StartIPMIPollers=0 #启动多少ipmi的poller进程,默认空闲StartPollersUnreachable=1 #不可达的pollerStartTrappers=5 #如果经常拉取对zabbix性能又影响,agent可以自动发送数据到server端,这个Trapper就是捕获该数据StartPingers=1 #icmp探测主机是否在线StartDiscoverers=1 #启动多个自动发现进程(消耗带宽)StartHTTPPoller=1 #启动web的拉取数据进程StartTimers=1 #启动计时器JavaGateway=127.0.0.1 #启动java网关连接jmxJavaGatewayPort=10052 #使用10052端口StartJavaPollers=5 #启动多少java的poller进程StartVMwareCollectors=0 #监控vm的虚拟主机VMwareFrequency=60 #监控vm的频率AlertScriptsPath=/usr/local/zabbix/alertscripts #脚本报警路径ExternalScripts=/usr/local/zabbix/externalscripts #外部脚本路径FpingLocation=/usr/sbin/fping #fping程序路径需要事先安装,fping(并行ping) Zabbix-Agent端123456#/etc/zabbix/zabbix_agent.confServer=192.168.1.2 #服务端ip可用逗号分隔ListenPort=10050ListenIP=192.168.1.100ServerActive=192.168.1.2 #自动推送数据到监控端(默认是被动监控)Hostname=node1 #主机名,唯一 Zabbix Server Process123456789101112watchdoghowsekeeperalerterproller (拉取)httppoller (web拉取)discoverer (自动发现)pinger (探测主机)nodewatcher (监控各节点) timer (计时器) escalator (报警升级)db_config_syncer(数据库配置同步)db_data_syncer (数据库数据同步) Zabbix配置详解Zabbix术语123456789101112131415161718192021222324252627主机(host) 要监控的网络设备,由ip或dns名称指定 主机组(host group) 主机的逻辑容器,可以包含主机和模板,但同一个组内的主机和模板不能互相链接,主机组通常在给用户和用户组指派监控权限时候使用 监控项(item) 一个特定监控指标的相关数据,这些数据来自于被监控对象,对于item是zabbix进行数据收集的核心,没有item将没有数据;相对某监控对象来说,每个item都是由"key"标识 触发器(trigger) 一个表达式,用于评估某监控对像的特定item内所接受到的数据是否在合理范围内,即阈值;接受到数据量大于阈值时,触发器状态将从"ok"转变成"problem",当数据量再次回归到合理范围内从"problem"转成"ok". 事件(even) 即发生的一个值得关注的事情,例如触发器的状态转变,新的agent或重新上线的agent自动注册等 动作(action) 指对特定时间事先定义的处理方法，通过包含操作(如发送通知)和条件(何时执行操作) 报警升级(escalation) 发送报警或执行远程命令的自定义方案,如每隔5分钟发送一次报警,发5次 媒介(media) 发送通知的手段或者通道,如email,jabber或者sms 通知(notification) 通过选的的媒体向用户发送有关某事件的信息 远程命令(remote command) 预定义的命令,可在被监控主机处于某特定条件下自动执行 模板(template) 用于快速定义被监控主机的预设定条目集合,通常包含item,trigger,graph,screen,application以及**low-level discovery rule(自动发现)**;模板可以直接链接到单个主机 应用(application) 一组item的集合 web场景(web scennario) 用于检测web站定可用性一个或多个http请求 前端(frontend) zabbix的web接口 Item 监控项一个特定监控指标的相关数据，这些数据来自于被监控对象，对于item是zabbix进行数据收集的核心，没有item将没有数据；相对某监控对象来说，每个item都是由”key”标识 监控项是zabbix服务器用于监控一个特定对象上的一个特定指标,并负载针对其收集相关监控数据 如CPU每分钟平均负载可以是一个item，每五分钟平均负载是一个item 在比如特定网口接受报文速率也是一个item 每一个item都拥有相应的的类型”type” 例如”zabbix_agent”，“snmp”，“external check”，“IPMI Agent”，“SSH Agent”，“JMX Agent” Zabbix服务器会自动使用相应类型的协议或机制同时被监控端通讯 监控项Keyzabbix服务器在与被监控端通讯时就使用相应的协议或机制去询问被监控端这个key值,被监控端则调用与此key对应的监控脚本获取数据并返回给服务端 key的命名只能使用”0-9a-zA-Z_-.”等字符,且可以接受参数,其命令习惯如system.cpu.load[&lt;cpi&gt;,&lt;mode&gt;],其中括号中的内容为参数,且分别可按次序使用$1,$2,进行引用,此实例中仅有两个参数 若要使用不定数目的参数,则使用”*”表示 zabbix有需要预先定义的key，获取详细地址 https://www.zabbix.com/documentation/2.0/manual/items/itemtypes/zabbx_agent 对于每一个Item,zabbix服务器还定义了这么存储这个item数据以及数据采集频率及历史数据的保存时长等, 多个item还可归类为一个由”Application”定义逻辑组 数据库查看zabbix自定义的Key12USE zabbix;SELECT keys_ FROM items; 如何获取Key1$ZABBIX/bin/zabbix_get -s IP -p PORT -k "system.uname" 创建Item过程1configuration- - &gt; hosts - - &gt;(选择对应主机的items) - - &gt;create item Item多类型zabbix-agent：工作模式passive,active 网卡流量相关: net.if.in[if,&lt;mode&gt;] 进入 net.if.out[if,&lt;mode&gt;] 流出 net.if.total[if,&lt;mode&gt;] 总流量 if：接口 如eth0 mode: bytes,packets,erros,dropped 实例：create items key:net.if.in[eth0,bytes] 监控eth0网卡 store value:delta(speed per second)，计算上一次和这一次 端口相关 net.tcp.listen[port] #监听的端口,布尔值float net.tcp.port[&lt;ip&gt;,port] net.tcp.service[service,&lt;ip&gt;,&lt;port&gt;] net.upd.listen[port] 进程相关 kernel.maxfiles 最大文件数 kernel.maxproc 最大进程数 cpu相关 system.cpu.intr 中断次数 system.cpu.load[&lt;cpu&gt;,&lt;mode&gt;]负载 system.cpu.num[&lt;type&gt;] CPU颗数 system.cpu.switches CPU上下文切换次数 system.cpu.util[&lt;cpu&gt;,&lt;type&gt;,&lt;mode&gt;] CPU利用率 磁盘io或文件系统相关 vfs.dev.read[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] 磁盘读 vfs.dev.write[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] 磁盘写 vfs.fs.inode[fs,&lt;mode&gt;] 磁盘inode值 用户可定义item: 关键:选取一个唯一的key 命令:收集数据的命令或脚本 Trigger 触发器监控项 仅负责收集收据，而通常收集数据的目的还包括在某指标对应的数据超出合理范围时给相关人员发送告警信息,该工作就是触发器来定义用于为监控项所收集的数据定义阈值，每一个触发器仅能关联至一个监控项,但可以为一个监控项同时使用多个触发器（一个trigger只能属于一个item，但一个item可以有多个trigger） 事实上为一个监控项定义多个具有不同阈值的触发器可以实现不同级别的报警功能 一个触发器由一个表达式构成，它定义了监控项所采取的数据的一个阈值 一旦某次采集的数据超出了此触发器定义的阈值,触发器状态会转换成”problem”;而采取的数据再次回归至合理规范内时,其状态将重新返回到”ok” 触发器表达式高度灵活,可以创建出非常复杂的测试条件 触发器格式123456789101112&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt; server #主机名称 key #主机上关系的相应监控项的key function #评估采集到的数据是否在合理范围内时所使用的函数,其评估过程可以根据采集的数据,当前时间以及其他因素进行 #目前触发器所支持的函数avg,count,change,date,dayofweek,delta(增量),diff,iregexp,last,max,min,nodata,now,sum等 operator #表达式所支持的运算符及其功能如下表示 #/ * - + &lt; &gt; # = &amp; |例子:&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125;&gt;3#表示主机www.zhuxyid.com上所有cpu过去1分钟内的平均负载的最后一次取值大于3时,将触发状态变换#对last函数来说,last(0)相当于last(#1)&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125; or &#123;www.zhuxyid.com:system.cpu.load[all,avg5].last)(0)&#125; or.... 触发器依赖关系在一个网络中，主机的可用性之间可能存在依赖关系 例如当某网关主机不可达时,其背后的所有主机都将无法正常访问 如果所有主机都配置触发器并设定了相关的通知功能，相关人员将会接受到许多告警信息，这既不利于快速定位,也会浪费资源 正确定义的触发器依赖关系可以避免类似情况发生,他将使用通知机制仅发送最根本的问题相关告警 目前zabbix不能直接定义主机间的依赖关系,其依赖关系仅能通过触发器来定义 触发器等级 SEVERITY DEFINITION COLOUR Not Classified 未知级别 Grey Infromation 一般信息 Light Green Warning 警告信息 Yellow Average 一般故障 Orange Hight 高级别故障 Red Disaster 致命故障 Bright Red 触发器状态zabbix server每次接受到items的新数据时，对items当前采样值进行判断，即与trigger表达式进行比较 OK PROPLEM 触发器创建过程 Configuration - - &gt; Host - - &gt; Triggers - - &gt; Create trigger Trigger名称使用宏 ​ (HOST.HOST)，{HOST.NAME}，{HOST.IP}，{HOST.CONN}，{HOST.DNS} 触发条件一般为事件: Trigger events: ok—&gt;proplem Discovery event: zabbix的network discovery工作时发现主机 Auto registration event:主动模式的agent注册时发生的时间 Internal event:item变成不在被支持,或者trigger变成未知状态 Operations的功能:动作: send message: 发送通知手段如下 ​ EMAIL,SMS,Jabber,Scripts,EZ texting Remote command:远程命令 配置send message 定义media 定义用户 配置要发送消息;action就已经定义好 配置Remote Command 前提:执行命令需要agent开启执行远程命令zabbix_agent.conf EnableRemoteCommands=1 是否开启远程执行命令 LogRemoteCommands=1 是否将命令记录到日志中 给zabbix定义sudo规则/etc/sudoers zabbix ALL=(ALL) ALL 特别注意：Remote Command不支持active模式的agent ,不支持代理模式 ,命令长度不得超过255个字符 ,远程命令可以使用宏定义 ,zabbix server仅执行命令,不关心命令是否执行成功 注意: 如果用到以其他用户身份执行命令的话,那么命令本身要以sudo方式运行 sudo /etc/rc.d/init.d/httpd restart 注释agent上的sudoers文件,需要注释(sudo模式下需要一个真实的tty) Default requiretty 报警升级可以使用setp定义几次处理可以邮件升级。 Template 模板用于快速定义被监控主机的预设定条目集合,通常包含item,trigger,graph,screen,application以及low-level discovery rule(自动发现);模板可以直接链接到单个主机 模板是一系列配置的集合,它可以方便地快速部署在某监控对象上,并支持重复应用，此配置可通过”链接”方式应用于指定的主机 items trggers graphs applications screens(since zabbix 2.0) low-level discovery rules(since zabbix 2.0) 将模板应用至某主机上时，其定义的所有条目都会自动添加 模板的另一个好处在于,必要时,修改了模板,应用的主机都会相应作出修改 创建模板 configuration –&gt; templates 在模板上按需添加item,trigger,screen,graph,application以及发现规则 模板可以嵌套 macros 宏宏是一种抽象(abstraction),它根据一系列预定义的规则替换一定文本模式,而解释器或者编译器在遇到宏时会自动进行这一模式的替换类似,zabbix基于宏保存预设文本模式,并且调用时将其替换为其中文本. zabbix有许多内置宏 如{HOST.NAME} {HOST.IP} {TRIGGER.DESCRIPTION} {TRIGGER.NAME} {TRIGGER.EVENTS.ACK}等 ，详细信息参考文档 https://www.zabbix.com/documentation/3.0/manual/appendix/macros 为了更强的灵活性,zabbix还支持在全局,模板或者主机级别使用用户自定义宏(user macro) 用户自定义宏使用”${MACRO}”这种特殊的语法格式 宏可以应用在Item keys和descriptions,trigger名称和表达式,主机接口ip/dns以端口,discovery机制的snmp协议的相关信息中等 宏名称只能使用大写字母、数字、下划线 参考https://www.zabbix.com/documentation/3.0/manual/appendix/macros/supported_by_location 宏替换次序 首先是主机级别的宏 其次是当前主机上的上一级模板中(直接连接至主机的模板)的宏,多个一级模板按其ID号排序 再接着就是二级模板中的宏,而后以此类推 最后检查的是全局宏 zabbix如果无法查找某主机定义的宏,则不会对其进行替换操作,要使用用户自定义宏,有一下两种途径 全局宏:”administratorion” –&gt; general —&gt; macros macro:{$NGINX_PORT} value:80 主机或模板级别的宏:编辑相应主机或模板的属性即可,(只针对当前主机.主机级别最高) 总结:宏分为两类: 内建:{MACRO_NAME} 自建:${MACRO_NAME} 三个级别使用: global全局 template模板 host主机 优先级:host —&gt; template—&gt;global 在某级别找到后直接使用不会往后查找 Web Scennario web场景用于检测web站定可用性一个或多个http请求 zabbix还可对web站点可用性的可用性检测 创建web监控需要先定义一个web方案(scenarios) web方案包含一个或多个http请求或”步骤)step” ，步骤(step)的执行过程按照预先定义的顺序进行执行 通过web监控可实现获取如下信息 整个web方案中所有的步骤平均下载速度 失败的步骤号 失败的报错信息 在web方案的具体步骤中,可按需进行如下信息 该步骤的下载速度 回应时间 回应状态吗 zabbix可以检测获取到html页面中是否包含预设的字符串,可以实现登陆和页面点击 创建web方案 创建web方案前提需要创建一个使用的应用(application) 可以在”hosts”或者”templates”上创建应用 如果在”templates”上创建应用,则需要将此”templates”连接至要监控其web的主机上方能使此”application” 步骤： configuration–&gt;web(zabbix2.4) configuration–&gt;templates(host)–&gt;web(zabbix3.0) 例子： 1234567891011121314scenario name:zhuxyid.comnew application:zhuxyid.com update interval:30s agent:chrome3.8(windows) 其他默认 step name:zhuxyid.indexurl:http://www.zhuxyid.comfollow redirects:enable timeout:10 required status codes:200 monitoring--&gt;web--&gt;zhuxyid.com即可出图 Zabbix自动发现zabbix提供网络发现(network discovery)，低级发现(low level discovery) Network Discovery网络发现 HTTP,ICMP,LDAP,SSH,TCP,SNMP,Telnet,Zabbix_agent 扫描指定网络内的主机 一旦主机被发现,如果对其进行操作,由action来决定 LLD:low level discovery 低级发现 自动添加或者移除主机,链接至模板或删除链接,添加监控项,将主机添加至分组,定义触发器 执行远程脚本 Network Discovery网络发现是zabbix最具特色功能,他能够根据用户实现定义的规则自动添加监控的主机或服务 发现中的事件有如下两种: 服务:service discovered,service lost,service up,service down 主机:host discovered,host lost,host up,host down zabbix的网络发现功能可基于如下信息进行 1234IP rangftp,ssh,web,pop3,imap,tcp,etc zabbix agent snmp agent 网络发现通常包含:discovery和action discovery中的事件: service up service down host up host down service discovery service lost host discovery host lost action中网络发现中事件可以触发action,从而自动执行指定的操作 sending notifications adding/remove hosts enabling/disabling host adding hosts to a group remove hosts from a group linking hosts to/unlinking from a template executing remote scripts 这些事件的配置还可以基于设备类型,ip,状态、上线/离线等进行配置 接口添加 网络发现中添加主机时会自动创建interface the service detected,如果基于snmp检测成功,会创建snmp接口 如果某服务同时响应给了agent和snmp则两种接口都会创建 如果同一种机制(如agent)返回非唯一数据,则第一个接口被识别为默认,其他的为额外接口 即便是某主机开始时只有agent接口，后来通过snmp发现他，同样会添加额外snmp接口 不同主机如果返回了相同数据，则第一个主机将被添加，余下的主机会被当作第一个主机额外的接口 Auto Registation 自动注册配置 需要修改agnet配置 12345678&gt; ListenIP=192.168.0.100 #192.168.0.100是agent的地址,最好指定本地地址不要使用0.0.0.0&gt; ListenPort=10050&gt; Server=192.168.0.1&gt; ServerActive=192.168.0.1 #192.168.0.1是zabbixserver的ip,重要&gt; Hostname=iis&gt; HostMetadata=ariis #用于唯一标识主机,只能用于自动注册,最多255个字符&gt; #HostMetadateItem= #也可以使用item获取数据,通常使用systen.uname 发给服务端自动注册&gt; 配置自动注册 configuration—&gt;actions–&gt;Event source(Auto registration)–&gt;create action action: name: auto_reg new condition: host metadata like ariis #主机元数据 operations: default subject 自动注册 default Message 主机名称{HOST.HOST} 主机地址:{HOST.IP} 主机端口:{HOST.PORT} Operations: send message to user: 邮件通知用户 add to host groups 添加主机组 links to templates 连接模板 支持使用agent(active)类型的item key: Low Level DiscoveryLLD低级发现特定变量名称:区别不同主机应用使用items值不一样(如eth0跟em0) 1234&gt; IFNAME&gt; #FSNAME #大多数针对网络接口,文件系统 &gt; #自定义脚本实现相应功能 &gt; 添加针对对应变量的items: 返回值是json格式,方便数据交换 查看zabbix agent内置的keys 123&gt; USE zabbix&gt; select key_ from items where key_ LIKE &apos;%discovery%&apos;; &gt; 配置过程 configuration—&gt;templates(host)—&gt;discovery rules—&gt;create discovery rule 12345discovery rulename:if lldtype:zabbix agentkey:net.if.discoveryupdate interval: 30s filters 12Type of calculation Filters A &#123;#IFNAME&#125; matches em-xxx item 1key:net.if.in[#IFNAME,bytes] Zabbix报警定义发送机制(这里官方提示需要用tls/ssl认证发送，可以使用脚本发送邮件) 邮件方式:administration—&gt;media types name:zabbix_mail type:email SMTP server:exmail.com.cn SMTP helo:exmail.com.cn SMTP email:zabbix@exmail.com.cn enable:enable 脚本方式:12345678910111213141516#tail -n10 /etc/mail.rc set from=zabbix@zhuxyid.comset smtp=smtp.exmail.qq.com set smtp-auth-user=admin@zhuxyid.comset smtp-auth-password=12345 set smtp-auth=login #vi /etc/zabbix/etc/zabbix_server.conf AlertScriptsPath=/etc/zabbix/scripts #more /etc/zabbix/scripts/sendmail.sh #!/bin/bash BODY=/var/zabbix/mailtmp echo "$3" &gt; $BODY dos2unix $BODY #需要事先安装dos2unix转移,不然邮件会是附件形式/bin/mail -s "$2" $1 &lt; $BODY 创建用户以及发送报警级别邮件 administration—&gt;users—&gt;users–&gt;create user user alias:SA_OPS Name:zhuxy last name:zhuxuyue groups:zabbix administrators password: …. media type:zabbix_mail send to:admin@exmail.com.cn when active:1-7,00:00-24:00 7*24 use if severity: 定义报警级别(什么级别发给什么用户) status:enabled 定义发送内容 configuration –&gt; actions–&gt;create action Action Name:cpu problems defalt subject: {TRIGGER.STATUS}:{TRIGGER.NAME} #标题:trigger状态和trigger名称 default message: #正文 recovery message: #如果状态从proplem转换成ok发送信息 enable:enable conditions 发送条件 type of calculation:[and|or|custom expression] 类型条件,如果下列conditions都满足就发送邮件(and),满足其中一个就发邮件(or),可以自定义表达式 conditions: A Maintenace status not in maintenance 维护状态不在维护中,如果状态在维护中应该不能发报警 B Trigger value = PROBLEM C Trigger = node1:cpu too many interrupta operations default operation setp duration 300 #每次报警时长(默认1小时),最小60s action operations operation details: setp from 1 ​ to 2 #从第一步到第二步就是10分钟(1步5分钟) setp duration 0 operation type send message|remote command #如果10分钟后要么发送报警，要么执行远程命令 send to user groups #发个组 send to user #发给用户 send only to ：email #仅通过email发送信息(可以使用all就是所有报警机制都发送),如果问题严重建议使用短信,电话，微信发送信息 default message #默认信息 conditions: #条件 action： 触发条件一般为时间: trigger events: ok –&gt; proplem discovery event:zabbix的network discovery工作时发现主机 autho registration event:主动模式的agent注册时产生的时间 internal events：items变成不在被支持,或者trigger变成未知状态 用户参数zabbix 内置了许多item keys: user parameters实现自定义item key，实现特有数据指标监控 syntax语法: UserParameter=&lt;key&gt;,&lt;command&gt; UserParameter=key[*].command 需要重启agent才可以生效 实例: 1UserParameter=Nginx.active[*],/usr/bin/curl -s "http://$1:$2/status" | awk '/^Active/ &#123;print $NF&#125;' 实例：比如监控agent端的内存 1234567891011121314151617181920#zabbix-agent端#vi $zabbix_home/conf/zabbix_agentd.conf include=/usr/local/zabbix_agents/conf/zabbix_agentd/userparameter_mem.conf #more $zabbix_home/conf/zabbix_agentd/os_linux.conf UserParameter=os.memory.used,free -m|awk '/^Mem/&#123;print $3&#125;' UserParameter=os.memory.total,free -m|awk '/^Mem/&#123;print $2&#125;' UserParameter=os.memory.free,free -m|awk '/^Mem/&#123;print $4&#125;' #service zabbix-agent restart #zabbix-server端zabbix_get -s 'ip' -k "os.memory.free"#看是否能获取数据创建监控项目:host ---&gt;items---&gt;creat items name:内存使用情况 key:os.memory.used #调用agent的key就是刚才定义好的 use custom multiplier:1024000 #之前以及转换成mb,如果直接在units填写mb，超出1G就会出现1kmb,所有不设置units,让计算的值乘以1024000，这里free -m显示多大默认是以b为单位 Zabbix分布式监控分布式监控概述 proxy and node Zabbix三种架构 server-agent server-node-agent server-proxy-agent Zabbix分布式监控概述 zabbix能高效的监控分布式it架构 在大型环境中zabbix提供两种解决方案 使用代理(proxy) 使用节点(node) Proxy or Node 代理(proxy)用于本区域数据收集,并将数据发送给server 节点(node)提供完整的zabbix server用于建立分布式监控中的层级 Proxy Node Lightweight轻量级 YES NO GUI图形接口 NO YES Works idependently独立工作 YES YES EASY maintenance 易维护 YES NO Automatic DB create 数据库自动创建 YES NO Local Administration 本地管理 NO YES Ready for embedded hardware 嵌入式监控 YES NO One way tcp connections 单向TCP连接 YES YES Centralised configuration 集中配置 YES NO Generates notifications 生成通知 NO YES Proxy：高性能，可以独立工作，易于维护，支持自动创建数据库，支持嵌入式监控，只支持一路TCP连接，支持集中配置。 不支持GUI接口，不支持本地管理，不支持通知 Server-Node-Client：特性 解决host过多时单台server面临性能瓶颈问题 使用多个instance 每个instance是独立的一套zabbix,有database和frontend(optional) 支持热插拔,Node和Server的连接可以随时断开,不影响node正常运行 node定时给server发送configuration,history,event server定时给node发送configuration 所有配置变更只能node节点操作,不能在server操作 (http://www.zabbix.com/forum/showthread.php?t=20863) 支持树状结构,Node可以是个server Server-Proxy-Client工作特性 proxy不会向server同步configuration,只接受 proxy的数据库定时回将数据传送给server,proxy本地数据库只保存最近有没有发送的数据 Proxy 对比 NodeNode本身是一台server，有完整的Web页面，完整的数据库,他将数据源源不断的传送给Master proxy只有一个proxy的daemon进程,proxy也有自己的数据库,但他的数据库智慧保存一定时间的数据，他与master通信是将一批信息打包后发送给master，master将这些数据merge入master数据库 master-proxy相比master-node优点有如下几点: proxy压力小,数据库只存一定时间数据 master压力变小,数据不是源源不断获取，减小io压力 架构清晰,便于维护 Zabbix-proxy安装1234567891011121314151617181920212223#需要安装mysql#yum install zabbix-proxy zabbix-proxy-mysql mysql&gt; create database zabbix-proxy character set utf8; mysql&gt; grant all on zabbix_proxy.* to zabbix@&apos;%&apos; identified by &apos;admin123&apos; mysql&gt; flush privileges; mysql&gt; use zabbix-proxy; mysql&gt; source schema.sql; 只需要导入一个库就可以 #vi /etc/zabbix-proxy/etc/zabbix_proxy.conf Server=ZABBIX-SERVER-IP Hostname=Zabbix-Proxy-NJYFXJ HostnameItem=system.host #如果没有定义hostname,就定义item DBHOST=localhost DBName=zabbix-proxy DBUser=zabbix DBPassword=admin123 HeartbeatFrequency=60 #默认60s探测一次可用状态 ConfigFrequency=3600 #每隔1小时到服务端拉取数据 DataSenderFrequency=1 #每隔1s将数据发送给服务端 #server zabbix-proxy start #netstat -anptl | grep 10050 Server端配置Proxy administration–&gt;proxies proxy name:Zabbix-Proxy-NJYFXJ proxy mode:active|passive (拉取|主动推送) hosts proxy hosts Create host Monitored by proxy:Zabbix-Proxy-NJYFXJ Zabbix常用模板官方模板：123456789101112131415161718192021zabbix常用模板Redishttps://github.com/adubkov/zbx_redis_templateRabbitMQhttps://github.com/jasonmcintosh/rabbitmq-zabbixnginxhttps://share.zabbix.com/cat-app/web-servers/nginx-for-zabbix-3-2IIShttps://share.zabbix.com/cat-app/web-servers/iis-sites-and-application-pool-state-monitoringSSL证书https://share.zabbix.com/cat-app/web-servers/ssl-certificates-checkMS sqlserverhttps://share.zabbix.com/databases/microsoft-sql-server/template-ms-sql-2012routeOShttps://share.zabbix.com/network_devices/mikrotik/mikrotik-routeros]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F11%2F30%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis介绍Redis是一个基于BSD开源的高性能键值缓存服务，支持数据结构string，list，hash，set，sorted，bitmaps，hyperloglog。 官方站点：http://www.redis.io Redis特点: kv存储，存储在内存中， redis可以持久化周期性的存储在磁盘上(冗余作用) ​ 快照，内存数据异步传输到磁盘（RDB）。 ​ AOF，每次写操作附加在文件中。 ​ Master-Slave方式,主写，从读。 redis支持主从模式，借助哨兵（Sentinel实现一定意义上的高可用） redis3.0开始支持群集（分布式） Redis和Memcache区别 memcache是一个分布式内存对象缓存系统，且不可持久化，redis支持 持久存储 memcache是基于LRU cache(最近最少使用) ，redis有不同特性以及跟多数据类型 memcache是多线程，redis是单线程，两者的性能几乎相同 Redis优点： ​ 丰富(资料形式)操作(Hashs,Lists,Sorted,Sets,HyperLoglog) ​ 内建replication及cluster ​ 就地更新(in-place update)操作 ​ 支持持久化(磁盘)，避免雪崩 Memcache优点 ​ 多线程(善用多核cpu，更少堵塞操作) ​ 更少内存开销 ​ 更少内存分配压力 ​ 内存碎片更少 其他资料常见的存储系统分为三类: RDBMS：如Oracle，SQLServer，MySQL。 NoSQL：如Hbash，MongoDB，Redis NewSQL：分布式关系型事物系统 NoSQL四种流派： 键值NoSQL：如Redis，Memcache 列族NoSQL：如Hbash，MongoDB，Redis 文档NoSQL：MongoDB 图形NoSQL：Neo4J Redis案例: ​ 一百万的key，内存使用约100M ​ 单线程，虽然单线程，却能承受500k的并发请求 Redis安装12345678910111213141516171819#安装redis需要安装jemalloc内存管理工具(google研发)yum install tcl#下载源码地址：http://download.redis.io/releases/#安装步骤tar zxvf redis-VERSION.tar.gzcd redis-VERSIONmake#安装完成后，生成如下文件redis.conf redis配置文件sentinel.conf 主从架构配置文件src/redis-server redis服务端src/redis-cli redis客户端src/redis-check-aof redis检查工具（AOF）src/redis-check-dump redis检查工具（快照）src/redis-benchmark redis性能工具src/redis-sentinel redis主从架构提供高性能工具 Redis基本配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107cat redis.conf | grep -v "^#" | grep -v "^$"#全局设置####INCLUDE####daemonize nopidfile /var/run/redis.pidport 6379tcp-backlog 511 #tcp-backlog长度 （backlog是个队列缓冲，tcp通常会有backlog）bind 126.0.0.1 192.168.2.21unixsocket /tmp/redis.sock #如果不使用tcp方式，可以直接使用unixsocket方式,效率比tcp高timeout 0 #客户端连接超时时间(0表示不会超时)，根据需求设定tcp-keepalive 0loglevel noticelogfile "/var/log/redis/redis.log"syslog-enabled no #是否启用系统日志syslog-ident redis #日志识别syslog-facility local0 #日志设施databases 16 #redis是否支持多内部数据集合，默认放在0，在redis集群中只支持16#快照，持久化配置信息####SNAPSHOTTING#####格式 save seconds changessave 900 1 #900s（15分钟），如果有1个键值发生改变，就存储save 300 10 #300s（5分钟），如果有10个键值发生改变，就存储save 60 10000 #60s（1分钟），如果有1000个键值发生改变，就存储#save "" #取消注释表示禁用持久化功能stop-writes-on-bgsave-error yes #在RDB方式下，如果使用bgsave保存是否检查如果检查错误是否停止rdbcompression yes #RDB是否压缩，压缩会消耗cpu资源rdbchecksum yes #是否对rdb进行校验码检测dbfilename dump.rdb #DBfile文件名称dir ./ #指明文件保存目录#主从配置信息####REPLICATION#####slaveof &lt;masterip&gt; &lt;master-ports&gt; #如果这个注释，说明是master模式，如果开启需要指定master的IP和端口slave-serve-stale-data yes #是否从服务器使用过期数据slave-read-only yes #是否只读，如果slaveof注释，这里是没有用的，repl-diskless-sync no #是否给予diskess同步，如果网络快，磁盘写慢建议开启repl-diskless-sync-delay 5 #延迟时间多久repl-disable-tcp-nodelay no #tcp nodelay功能slave-priority 100 #slave优先级min-slaves-to-write 3 #从节点至少3个节点，将禁止主服务器写请求min-slaves-max-lag 10 #从节点如果相差10s，主服务器拒绝执行写入操作#安全相关配置####SECURITY#####requirepass foobared #认证密码foobaredrename-command CONFIG ""#并发相关配置####LIMITS######maxclients 10000 #最大并发数量，多少客户端连接maxmemory &lt;bytes&gt; #每个客户端内存使用量maxmemory-policy noevictionmaxmemory-samples 5#AOF持久化####APPEND ONLY MODE####appendonly no #是否使用AOF功能，yes使用，这里是禁用appendfilename "appendonly.aof" #AOF文件名appendfsync &#123;always | everysec | no&#125; #AOF追加方式&#123;always没接受一条写一条，everyse每秒写一条，no 表示根据系统调用来写&#125;no-appendfsync-on-rewrite no #如果是yes表示重写的时候对新写的操作是存在内存auto-aof-rewrite-percentage 100 #aof文件增长了100%也就是两倍，触发重写操作auto-aof-rewrite-min-size 64mb #如果重写大小达到64M就重写aof-load-truncated yes#redis加载aof文件，发现末尾命令不完整自动截掉，成功加载前面正确数据，如果设置no，遇到不完整redis启动失败，redis-check-aof修复#lua脚本设置####LUA SCRIPTING####lua-time-limit 5000#redis群集设置####REDIS CLUSTER####cluster-enabled yescluster-config-file nodes-6379.confcluster-node-timeout 15000cluster-slave-validity-factor 10cluster-require-full-coverage yes#慢查询日志设置####SLOW LOG####slowlog-log-slower-than 10000slowlog-max-len 128#监控设置####LATENCY MONITOR####latency-monitor-threshold 0#事件通知设置 跟发布订阅有关####EVENT NOTIFICATION####notify-keyspace-events ""#高级设置####ADVANCED CONFIG####hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes Redis命令123456789101112131415161718192021222324#启动redis前需要设置echo 'vm.overcommit_memory=1' &gt;&gt; /etc/sysctl.conf #内存不足的情况下，后台程序save可能失败，建议将其改成1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled#如果使用透明大页，可能导致redis延迟和内存使用问题echo 511 &gt; /proc/sys/net/core/somaxconn#tcp backlog值#启动redis-server &amp;-h HOST : 连接的主机地址或主机名-p PORT :连接的端口-s socket : 指定套接字-a password : 指定连接密码-r &lt;repeat&gt; : 指定命令运行多次overcommit_memory参数说明设置内存分配策略，可以设定0、1、20 表示内核将检查是否有足够的内存供应进程应用，如果没有足够的可用内存，内存允许申请；否则内存申请失败，并将错误返回给应用进程1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何2 表示内核允许分配超过所有物理内存和交换空间总内存注：redis在dump数据时，会fork出一个子进程，理论上child进程所占有内存和parent是一样的，如果parent占用内存为8G，这个时候同样分配8G的内存给child，如果内存无法负担，往往会造成redis服务的down机或者IO负载过高，导致效率下降，所有这里比较优化的内存策略应该为1（表示内核运行分配所有的物理内存，而不管当前内存状态) Redis基本操作1234567891011#redis-cli -h 127.0.0.1127.0.0.1:6379&gt;helpType help @&lt;group&gt; help &lt;tab&gt;127.0.0.1:6379&gt; help @connection #帮助命令 127.0.0.1:6379&gt; help @STRING #获取字符串操作帮组127.0.0.1:6379&gt; ping #测试 PONG127.0.0.1:6379&gt; echo 'hello world' #回显 "hello world" 127.0.0.1:6379&gt; QUIT #退出 server主要设置redis服务器 1234567891011121314151617181920127.0.0.1:6379&gt; CLIENT SETNAME localconn #设置名称OK127.0.0.1:6379&gt; CLIENT GETNAME #获取名称"localconn"127.0.0.1:6379&gt; CLIENT LIST #client列表"id=2 addr=127.0.0.1:38521 fd=6 name= age=272 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client"127.0.0.1:6379&gt; CLIENT KILL ip:port #剔除一个client127.0.0.1:6379&gt; INFO #获取信息127.0.0.1:6379&gt; INFO MEMORY #获取memory信息，如获取cpu，执行info cpu127.0.0.1:6379&gt; CONFIG RESETSTAT #重置所有配置信息127.0.0.1:6379&gt; CONFIG SET #设置仅在内存生效127.0.0.1:6379&gt; CONFIG REWRITE #同步到配置文件中，如果用CONFIG SET方式设置redis参数需要REWRITE同步到配置文件中 SELECT使用0的命名空间，默认是0，使用SELECT [空间名进行跳转最大16个] 同一个名称空间不能使用相同的键值 12345127.0.0.1:6379&gt;SELECT 0127.0.0.1:6379&gt;SELECT 15OK127.0.0.1:6379[15]&gt;SELECT 16(error)ERR invalid DB index SET12345678910111213127.0.0.1:6379&gt; help set格式:SET key value [EX seconds] [PX milliseconds] [NX|XX] #set key value [过期时间] [标识] [如果键值不存在才会创建|如果键值存在覆盖]127.0.0.1:6379&gt; set 01 nameOK127.0.0.1:6379&gt; set 02 name2OK127.0.0.1:6379&gt; set 01 name nx(nil)127.0.0.1:6379&gt; set 03 name nxOK127.0.0.1:6379&gt; set 04 name ex 5 设置5s过期 GET123456127.0.0.1:6379&gt; get 02&quot;name2&quot;127.0.0.1:6379&gt; get 01&quot;name&quot;127.0.0.1:6379&gt; get 04 过期后会提示nil(nil) APPEND12345127.0.0.1:6379&gt; append 01 haha (integer) 8 127.0.0.1:6379&gt; get 01 &quot;namehaha&quot; STRLEN12127.0.0.1:6379&gt; STRLEN 01 #长度(integer) 8 INCR只针对整数增加生效 12345678127.0.0.1:6379&gt; set count 0 OK 127.0.0.1:6379&gt; INCR count #增加(integer) 1 127.0.0.1:6379&gt; INCR count (integer) 2 DECR12345127.0.0.1:6379&gt; DECR count #减(integer) 1 127.0.0.1:6379&gt; DECR count (integer) 0 事物通过MULTI,EXEC,WATCH等命令实现事物功能: redis事物只是将一个或者多个命令打包一个操作服务端按顺序执行机制redis事务不支持回滚操作 123456789101112131415127.0.0.1:6379&gt; MULTT #启动一个事务OK127.0.0.1:6379&gt; SET IP 192.168.2.21QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; SET PORT 8080QUEUED127.0.0.1:6379&gt; GET PORTQUEUED127.0.0.1:6379&gt; EXEC #执行事务，一次性将事务中的所有操作执行完成后返回给客户端1) OK2) "192.168.2.21"3) OK4) "8080" 清空操作:)for _ in range(1000):print(“不要在生产使用”) 12FLUSHDB 清空当前数据库FLUSHALL 清空所有数据库0~15 WATCH 乐观锁WATCH在EXEC命令执行之前，用于监视指定数量的键，如果监视中的某任意键数据被修改，则服务器拒绝执行事务 12345678910127.0.0.1:6379&gt; WATCH IP #监控IP键OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET IP 10.0.0.1QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; EXEC #如果在MULTI之后,EXEC之前有个客户端修改了IP，这里EXEC的话，就会拒绝事务(nil) Redis认证如果使用认证功能需要编辑配置文件找到requirepass 123456789101112格式：requirepass PASS $vi /etc/redis.conf requirepass zhuxyid $redis-server /etc/redis.conf redis-cli -h 127.0.0.1 127.0.0.1:6379&gt; select 0 (error) NOAUTH Authentication required. 127.0.0.1:6379&gt; auth zhuxyid OK 127.0.0.1:6379&gt; select 0 OK Redis发布订阅频道:消息队列 123456789101112SUBSCRIBE:订阅一个或多个队列PUBLISH:向频道发布消息例子&gt;SUBSCRIBE www.zhuxyid.com #订阅www.zhuxyid.com频道&gt;PUBLISH www.zhuxyid.com hello #向www.zhuxyid.com频道发送PSUBSCRIBE:订阅多个队列&gt;PSUBSCRIBE www.zhuxy.i[to] #订阅www.zhuxy.io 和 www.zhuxy.it频道&gt;PUBLISH www.zhuxy.io hello io&gt;PUBLISH www.zhuxy.it hello it Redis持久化#####RDB和AOF RDB:snapshot，二进制格式：被事先定制的策略,如save 900 1,周期性将数据保存到磁盘:数据文件默认为dump.rdb; ​ 客户端也可以使用SAVE或者BGSAVE命令启动快照保持机制 ​ SAVE:在主线程中保存快照，此时会堵塞所有用户请求，如果数据量大，严重影响性能 ​ BGSAVE:异步，不会被堵塞，只是创建子进程，保存到临时文件，主进程依然处理客户端请求 AOF:Append Only File. 记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可通过重新执行文件中的命令，在内存中重建数据库。 ​ BGREWRITEAOF:AOF文件重写； ​ 不会读取正在使用的AOF文件，在通过将内存中的数据以命令的方式保存在临时文件中，完成后替换原来的AOF文件 RDB：配置:redis-cli可以用config get dir查看 123456789配置如下：save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir ./ AOF:AOF重写过程： redis主进程调用fork生成子进程 子进程根据redis内存中的数据创建数据库重建命令列于临时文件中 父进程继承clinet请求，并会把这些请求写操作继续追加至原来的AOF文件，额外的这些新的请求会被放置于一个缓冲队列中 子进程重写完成会通知父进程，父进程会把缓冲中的命令写到临时文件中 父进程用临时文件替换老的AOF文件 12345678配置如下：appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yes RDB和AOF注意事项：redis如果同时使用两种持久化会导致IO影响大。 需要注意的是，就算可以持久化也不要忘记备份，万一磁盘坏了持久化也没什么用，对redis持久化文件进行备份。 RDB和AOF同时使用： BGSAVE和BGREWRITEAOF不会同时执行 在redis服务器启动用于恢复数据时，优先是有AOF，因为RDB是周期性的，数据不能保证为最新的 Redis复制特点: 一个master可以有多个slave 支持链式复制：slave可以有多个slave master以非阻塞方式同步至slave master&amp;slave工作原理: 启动一个slave，会请求同步master，master启动子进程，将快照保存在文件中，将文件传送给slave，slave接受文件保存本地加载至内存，完成同步 配置过程12345678910111213141516配置master&amp;slave192.168.2.21(master)修改配置文件bind 192.168.2.21启动redis192.168.2.23(slave)修改配置文件bind 192.168.2.23slaveof 192.168.2.21 6379启动redis或者直接在redis-cli输入slaveof 192.168.2.21 6379建议master写，slave读。如果master使用requirepass开启认证功能，从服务器要使用masterauth &lt;PASSWORD&gt; 来连入服务请求使用此密码进行认证 主从复制缺点:如果redismaster离线了，怎么办？可以使用redis-sentinel(主从架构实现高可用) Redis sentinelsentinel主要作用： 用于管理多个redis服务实现HA 监控，通知，故障转移 留言协议，投票协议。 启动流程: 服务器自身初始化，运行redis-server中专用于sentinel功能代码初始化sentinel状态，根据给定配置文件，初始化监控的master服务器列表创建连向master的链接 12345依赖配置文件sentinel.confredis-sentinel /path/to/sentinel启动redis-server /path/to/sentinel --sentinel sentinel配置文件说明1234567891011121314151617port 26379dir /tmpsentinel monitor mymaster 127.0.0.1 6379 2#格式:sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;#&lt;quorum&gt;票数,sentinel至少两票启动，如果只有一个则改成1&gt; !!如果还有其他应用使用redis主从也可以做监控，改变master-name就可以sentinel down-after-milliseconds mymaster 3000#格式:sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;#判断节点离线超过多少秒认为离线的。单位毫秒,sentinel parallel-syncs mymaster 1#格式:sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;#执行故障转移时候允许多少从服务器向新的主服务器同步请求sentinel failover-timeout mymaster 180000#格式:sentinel failover-timeout &lt;mymaster&gt; &lt;failover-timeout&gt;#当主服务器出现故障时候,从服务器提升主服务器的超时时间，单位毫秒 sentinel下线机制：主观下线和客观下线 主观下线:一个sentinel实例判断出某个节点下线 客观下线:多个sentinel节点协商后判断出某节点下线 专用命令123456redis-clit -h sentinelip -p sentinelport SENTINEL masters #列出所有主服务器SENTINEL slaves &lt;master name&gt; #获取当前redis示例中的从节点信息SENTINEL get-master-addr-by-name &lt;master name&gt; #直接获取当前redis实例主节点IP地址和端口SENTINEL reset #重置SENTINEL failover &lt;master name&gt; #手动切换 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596环境如下:172.16.36.70 : redis主节点 172.16.36.71 : redis从节点 172.16.36.72 : redis从节点 172.16.36.74 : sentinel节点1 172.16.36.75 : sentinel节点2 172.16.36.76 : sentinel节点3####配置redis主节点 操作主机: 172.16.36.70 #vim /etc/redis.confbind 172.16.36.70daemonize yes #启动服务 #redis-server /etc/redis.conf####配置redis从节点 #操作主机: 172.16.36.71 #vim /etc/redis.conf bind 172.16.36.71 daemonize yes #启动服务#redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置redis从节点#操作主机: 172.16.36.72 #vim /etc/redis.confbind 172.16.36.72daemonize yes #启动服务 #redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置sentinel节点#操作主机: 172.16.36.74 #vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14)) #操作主机: 172.16.36.75 # vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14))操作主机: 172.16.36.76# vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 启动服务 redis-sentinel /etc/redis-sentinel.conf 查看服务启动状态 users:((&quot;master&quot;,2112,14)) #这里有个问题，当一个redis挂掉后，如果连接主redis？可以使用vip(虚拟ip(keepalived)来实现)$sentinel client-reconfig-script myredis /opt/notify_myredis.sh$more /opt/notify_myredis.sh#!/bin/bashMASTERIP=$6 #第六个参数是redis的ip地址LOCALIP=&apos;192.168.0.101&apos; #另外一台按需填写VIP=&apos;192.168.0.100&apos; #client连接的redisNETMASK=&apos;24&apos;INTERFACE=&apos;eth1&apos;if [ $&#123;MASTERIP&#125; = $&#123;local_IP&#125; ];then /sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #将vip绑定到服务器上 /sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else /sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #删除 exit 0fiexit 1 #如果返回1，sentinel会一致执行这个脚本]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2018%2F11%2F27%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx是什么Nginx是一个Web服务器,也是个高性能方向代理服务器，Nginx起初为了解决基于进程模型产生的C10k问题，由俄罗斯lgor sysoev研发。 Nginxy有企业版本Nginx Plus，还有二次发行版Tengine，OpenResy（淘宝研发） nginx反向代理支持两种协议 HTTP和MAIL C10K 连接超过10K ,1W个请求,1M =100万个请求 Netcraft可以查看全球服务器Web服务器占有率。 传统上基于进程或线程模型架构的web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。 在设计的最初阶段，nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 Nginx特性模块化设计，较好的扩展性，早期不支持模块的动态装载和卸载 高可靠性，基于Master/Worker模式 支持热部署（平滑升级迁移），不停机的状态下更新配置文件，跟换日志文件，更新服务器程序版本 内存消耗低，10K个keep-alive连接模式下的非活动连接只消耗2.5M内存 支持event-driven事件驱动模型，AIO驱动机制，MMAP内存映射机制 Nginx基本功能 静态资源的web服务器,自身只能简单的接收和响应http http协议的反向代理服务器 pop3,smtp imap4等邮件协议的反向代理 能缓存打开的文件(元数据缓存:文件的描述符等信息),能加快文件的打开速度 支持FastCGI(php-fpm)，UWSGI 等协议机制,实现代理后端应用程序交互 支持过滤器,例如ZIP,SSI(服务端包含) 支持SSL加密机制 模块化（非DSO机制） standard HTTP modules 标准(核心)HTTP模块:自动编译进程序不止一个Optional HTTP modules 可选http模块Mail modules 邮件模块3rd party modules第三方模块,在编译时需手动指明加载方式加载 Nginx服务相关功能虚拟主机，Keepalive，访问日志，日志缓冲（提高存取西能），URL重写，路径别名，访问控制（IP和用户），支持速率限制，并发限制 Nginx架构Master/Worker模型： 一个master进程可以生成一个或者多个worker进程，每个worker基于事件驱动，响应用户请求, 其支持sendfile,sendfile64,这两种支持的文件大小不同 事件驱动：Linux(epoll)，FreeBSD(kqueue)，Solaris(/dev/poll) 除此之外配置了缓存时还会有缓存加载器进程cache loader和缓存管理器进程cache manager等，所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。 主进程Master以root用户身份运行，而Worker、Cache Loader和Cache Manager均应以非特权用户身份运行。 Master 加载，验证配置文件 创建，绑定，关闭套接字 管理worker进程（启动，终止，维护） 平滑重启（无需终止服务重载配置） 平滑升级（启用新的二进制程序并在需要时回滚到老版本） 重新打开日志文件，实现日志滑动 其他嵌入式perl，go脚本 Worker 响应客户端请求，提供HTTP服务和代理，提供FastCGI，uWSGI，SCGI等代理 Cache Loader 检查缓存存储中的缓存对象； 使用缓存元数据建立内存数据库； Cache Manager 缓存的失效及过期检验； Nginx安装可使用yum或者源码方式安装 yum安装yum方式很简单，直接使用yum源来安装 12yum install nginx #自动安装依赖关系rpm -ql nginx #查找nginx安装生成的文件 源码安装123456789101112131415161718192021222324252627282930yum install -y pcre-devel openssl-devel zlib-develuseradd nginx -s /sbin/nologin#进入解压后的源码包路径，根据需求来定.** 注意:`--with`都是启用模块，`--without`都是禁用模块 **./configure \ --prefix=/usr \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --user=nginx \ --group=nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --with-http_ssl_module \ #使用ssl模块 --with-http_flv_module \ #使用flv流模块 --with-http_stub_status_module \ #使用监控模块 --with-http_gzip_static_module \ #使用gizp模块 --with-pcre #pcre模块启用 --with-file-aio #支持文件异步 --with-http_image_filter_module #支持图片过滤 --http-client-body-temp-path=/var/tmp/nginx/client/ \ #请求报文主体缓存目录 --http-proxy-temp-path=/var/tmp/nginx/proxy/ \ #代理临时目录 --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ #fastcgi目录，支持php框架 --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ #uwsgi目录，支持python框架 --http-scgi-temp-path=/var/tmp/nginx/scgi \ #scgi目录，类似fastcgi另外一种机制# make &amp;&amp; make install Nginx常用命令1234nginx -t #测试配置文件是否正确nginx -s reload #nginx重载文件nginx -V #nginx显示版本号,已经编译的那些模块nginx --help查看更多帮助 配置文件说明123456789/etc/nginx/nginx.conf #主配置文件 Include conf.d/*.conf/etc/nginx/mime.types #所支持的MIME类型列表/etc/nginx/fastcgi_params #fastcgi的配置文件/etc/nginx/fastcgi.conf #与fastcgi_params一般只使用一个/etc/nginx/uwsgi_params #与uwsgi框架的配置文件/etc/nginx/scgi_params #cgi的配置文件/etc/nginx/proxy.conf #代理的配置/etc/nginx/sites.conf #配置虚拟主机的 主配置文件/etc/nginx/nginx.conf 格式如下 1234567891011121314151617181920worker_processerror_loguserevents &#123; use epoll;&#125;http &#123; access_log xxx; upstream server&#123; server IP:PORT &#125; server &#123; location URI &#123; driective &lt;parameters&gt;; &#125; &#125; server &#123; ....; &#125;&#125; MAIN该段落主要是配置Nginx运行启动时候必备参数 和 性能优化 以及 调试定位问题的配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465user nginx;worker_processes 1;worker_cpu_affinity auto;worker_rlimit_nofile 10240;timer_resolution 100ms;worker_priority 20;error_log /var/log/nginx/error.logevents &#123; use epoll; worker_connections 1024;&#125;http:&#123; upstream server &#123; .....; &#125; server &#123; ...; location / &#123; ...; &#125; &#125;&#125;user USERNAME#指定nginx启动worker进程时 以什么用户启动worker_processes NUMBER|auto#启动worker个数#如果负载以CPU密集型为主(比如SSL或压缩)则worker数应与CPU数相同;如果以IO密集为主(如大量内容给客户端)，则worker数应是CPU的1.5或2倍worker_cpu_affinity auto|CPUMASK#根据物理cpu自动绑定,worker不使用进程或者线程处理请求,而是直接将worker绑定到CPU上，这样就没有进程切换这一说法#worker_processes 4;#worker_cpu_affinity 0001 0010 0100 1000;worker_rlimit_nofile NUMBER#设置worker进程打开文件数量，worker_rlimit_nofile需要大于等于woker_connections的大小timer_resolution INTERVAL#用于降低gettimeofday()系统调用的缓存时钟，默认情况下，每次从kevent(),epoll,/dev/poll,select()，poll都会执行此系统调用worker_priority [-20~19]#设置worker进程优先级，官方说明一般在-20到19之间，如果想要woker运行快优先级可调到20error_log PATHFILE#配置错误日志，改参数可用于main,http,server,已经localtion上下文中.events事件驱动I/O框架use [ kqueue | rtsig | epoll | /dev/epoll | select | poll | eventport ]#根据当前系统内核版本设置适合自己的事件模型。#kqueue freeBSD 4.1+#epoll linux2.6+#/dev/epoll solaris 7 11/99+worker_connections NUMBER#事件驱动每个worker支持的连接数,如果worker_process为2，那么服务器最大支持2048个连接#当nginx作为web服务时 最大客户端处理数max_clients = worker_processes * worker_connections#当nginx作为反向代理时 最大客户端处理数max_clients = worker_processes * worker_connections/2#这里的max_clients很多人都疑惑为什么有人认为max_clients = worker_preocesses * worker_connections/4呢？#如果max_clients指的是建立连接最大客户数,由于每个游览器默认两个并发连接,那么nginx作为反向代理是/4#如果max_clients指的是处理客户端数,那就nginx作为反向代理是/2server_tokens off;#隐藏版本号 HTTPHTTP上下文配置用于http的各模块，此类指令很多，每个模块都有专用指令，具体参考nginx官方wiki模块部分的说明。大致上这些模块所提供的配置指令还可以分为以下几个类别: 1234567客户端指令：client_body_buffer_size，client_header_buffer_size，client_header_timeout，keepalive_timeout...文件IO指令：aio，directio，open_file_cache，open_file_cache_min_uses，open_file_cache_valid，sendfile....hash类指令：用于定义Nginx为特定的变量分配多大的内存空间，如types_bash_bucket_size，server_name_hash_bucket_size，variables_hash_bucket_size套接字指令：用于定义Nginx如何处理TCP套接字相关的功能，如tcp_nodelay（用于keepalive功能启用）和tcp_nopush（用于sendfile启用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147...;http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; #send_time #; #sendfile on; #tcp_nopush on; tcp_nodeplay on keepalive_timeout 65; keepalive_requests 100; #keepalive_disable none | browser; #client_body_buffer_size SIZE(8|16K); #client_body_temp_path [LEVEL1 [LEVEL2 [LEVEL3]]]; #aio on; #directio off; #open_file_cache off; #open_file_cache errors off; #open_file_cache_valid TIME; #open_file_cache_min_uses NUMBER; upstream name &#123; server 192.168.1.10:8080 keepalive 300 &#125; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;include mine.types#指定包含文件类型,mine.type里面定义，如html,css,gif,jpeg,js,txt....default_type application/octet-stream#默认是octet-stream，如果一个文件在mime.types没定义，就使用默认的类型octet-stream，这个表示下载，#如果设置default_type text/html;则表示可以在游览器查看log_format main string#设定log日志格式以及名称，main可以随便定义，string必须是nginx可识别的变量,可以自定义变量#$remote_addr，$http_x_forwarded_for #客户端的ip地址； #$remote_user #客户端用户名称； #$time_local #访问时间与时区； #$request #请求的url与http协议； #$status #请求状态，200,302，404，500等， #$body_bytes_sent #发送给客户端文件主体内容大小； #$request_body #请求体 #$http_referer #从那个页面链接访问过来的； #$http_user_agent #客户浏览器的相关信息； access_log path format_name#设定访问日志路径，使用哪个名称日志格式。#还有设置缓存大小刷新时间间隔，以及定义缓冲提升nginx性能#open_log_file_cache max=N [inactive=time] [min_uses] [valid=time]#open_log_file cache off;#max 设置缓存中描述符最大数量，如果缓存占满，最近最少使用(LRU)的描述符被关闭#inactive 设置缓存文件描述符在多长时间内没有被访问就关闭； 默认为10秒。#min_uses 设置在inactive参数指定的时间里， 最少访问多少次才能使文件描述符保留在缓存中；默认为1。#valid 设置一段用于检查超时后文件是否仍以同样名字存在的时间； 默认为60秒。#off 禁用缓存。send_time #;#发送响应报文的超时时长，默认60ssendfile on|off#在内核完成后直接封装响应客户端(支持小文件) sendfile64(支持大文件)#普通响应步骤client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;用户空间---&gt;内核(复制)--&gt;client#senfile响应client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;client#但是如果使用file aio模块，必须禁用sendfile支持tcp_nopush on#不做推送，在开启sendfile才有效，它和tcp_nodeplay互斥，TCP_CORK是linux下tcp/ip传输的一个标准（一般情况下tcp交互中，当程序收到数据包后马上传送不等待，而TCP_CORK选项是数据包不会传送出去，等到数据包最大时一次性传输，有助于解决网络拥堵），在tcp_nopush on时候，才会设置TCP_CORK方法，该选项对于www.ftp等大文件才有帮助。在FreeBSD使用TCP_NOPUSH套接字，在Linux使用TCP_CORK套接字，详见Nagle算法tcp_nodeplay on#对于keepalive模式下连接是否使用tcp_nodelay选项，默认关闭，其功能类似tcp_nopush，将多个小报文合并成一个报文一起发送，提高宽带利用率，将发往同一个主机很小的TCP报文合并成一个,实际生产对于用户请求即使浪费带宽也不能合并请求keepalive_timeout 75 75#长链接超时时间，0表示禁用,默认为75s，请求完成后还需要保持多久连接，目的是减少创建连接过程给系统带来的耗损,通常默认足够，如果内部服务器通讯场景过大建议增大。#第一个75设置keep-alive客户端连接在服务端保持开启超时时间，第二个75可选，在客户端响应的header区域中设置一个"keep-alive:timeout=time"#当nginx作为反向代理时候，为了支持场链接#从client到nginx 和 nginx到server连接都需要设置长连接#例子http &#123; keepalive_timeout 75 upstream www &#123; server 192.168.0.1:8080; server 192.168.0.2:8080; keepalive 300; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;#upstream 中的keepalive，设置upstream服务器的空闲keepalive连接最大数量，当数量被突破时，最近使用最少连接将被关闭，keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量。#HTTP协议对长连接支持从1.1版本后才有，需要通过proxy_http_version指令设置为1.1#而Connection header应该被清理，清理从客户端过来的http header，因为即使是客户端和nginx之间是短连接，nginx和upstream之间也是可以开启长连接。所以需要清理客户端请求中的"Conection" headerkeepalive_requests #在keepalive连接上允许请求的最大资源数量，默认为100，当一个keepalive建立后，nginx就会为这个连接设置一个计数器，记录这个keepalive长链接上已经接受并处理的客户端请求数量，如果达到这个参数设置最大时，nginx会强行关闭这个长链接，使客户端重新建立新的场链接。#大多数情况下QPS不是很高，100足够，但是对一些QPS高比如(10000QPS,甚至更高)100显的太低,#QPS=10000时候，客户端每秒发送10000个请求(通常建立长链接)，每个连接最多跑100次请求，意味着每秒就有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒重新新建100个连接，从而导致大量TIME_WAIT的socket链接，因此对于QPS较高场景，很有必要加大这个设置，避免出现大量连接被生成在抛弃。#出现大量TIME_WAIT情况#nginx出现大量TIME_WAIT情况有两种#keepalive_request设置较小，高并发超过此值后nginx悔强制关闭客户端保存keepalive长连接；(主动关闭连接后导致nginx出现TIME_WAIT)#keeaplive设置比较小(空闲数小)，导致高并发nginx会平凡出现连接数抖动(超过该值会关闭连接)，不停关闭\开启和后端server保持的keepalive长连接#后端server端出现大量TIME_WAIT情况#nginx没有打开和后端长连接，即使设置proxy_http_version 1.1和proxy_set_header Connection "" ;从而导致后端server每次关闭连接，高并发出现server端大量TIME_WAIT。keepalive_disable none|browser;#禁止那些游览器不使用keepalive功能，如果keepalive_disable msie6，禁止ie6不使用keepalive功能client_body_buffer_size;#接受客户端请求报文body的缓存区大小，默认为16k，在32位系统上是8k，超出指定大小将移存在磁盘上client_body_temp_path [Level1 [level2 [level3]]]#设定与存储客户端请求body临时存放路径以及子目录结构和数量#例子client_body_temp_path /var/tmp 2 2;#说明椅子子目录使用2个字符表示,二级目录下用2字符表示,每级目录都有256个文件夹，采用16进制表示文件，1个字符最多表示16，2字符表示256 aio on;#是否启用异步IO模式,可用于HTTP,SERVER,LOCATION上下文，sendfile不能与AIO同时使用 directio SIZE|off;#当大于SIZE的时候是否直接IO操作,不存在内存缓冲,直接从硬盘加载使用，用于HTTP,SERVER,LOCATION上下文中 open_file_cache off | max=N [inactive=time];#对打开文件缓存.主要包括:文件描述符,文件大小,最近修改时间，目录结构，没有找到或者没有权限操作文件相关信息，#max=N,可缓存的最大条目上限,一旦达到上限, 则会使用LRU算法从缓存中删除最近最少使用的缓存项#inactive=time : 在此处指定的时长内没有被访问过的缓存项识别为非活动缓存项, 因此直接删除 open_file_cache errors on|off;#是否缓存找不到其路径的文件,或没有权限访问的文件相关信息 open_file_cache_valid TIME;#每隔多久检查一次缓存中缓存项的有效性,默认为60秒 open_file_cache_min_uses NUMBER;#缓存项在非活动其限内最少应该被访问的次数 UPSTREAMupstream模块可定义一个新的上下文，位于server之上http之下，包含一组upstream服务器，这些服务器可能被赋予不同权重，不同类型，设置可以基于维护原因被标记为down。 1234567891011121314151617181920212223242526272829303132333435363738http&#123; ...; upstream myserver &#123; service 192.168.1.10:8080 wight=5 max_fails=3 file_timeout=6; service 192.168.1.10:8090 wight=5 max_fails=3 file_timeout=6; service 192.168.1.20:8080 backup; service 192.168.1.30:8080 down; ip_hash; keepalive 300; &#125; service &#123; ..; location &#123; ..; &#125; &#125;&#125;upstream模块常用的指令有：round-robin#轮询发往后端默认为轮轮询ip_hash#基于客户端IP地址完成请求的分发，它可以保证来自于同一个客户端的请求始终被转发至同一个upstream服务器least_conn#最少连接调度算法keepalive#每个worker进程为发送到upstream服务器的连接所缓存的个数.server:定义一个upstream服务器的地址，还可包括一系列可选参数，如： weight： 权重； max_fails： 最大失败连接次数，失败连接的超时时长由fail_timeout指定； fail_timeout： 等待请求的目标服务器发送响应的时长； backup： 用于fallback的目的，所有服务均故障时才启动此服务器； down： 手动标记其不再处理任何请求； SERVER用于定义虚拟服务器相关的属性，位于http上下文，常见的指令有backlog、rcvbuf、bind及sndbuf等 12345678910111213141516171819202122232425262728293031323334....;http &#123; ....; upstream &#123; ...; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; root /www; location / &#123; ....; &#125;&#125;listen [:port] | [default_server] | [ssl] [http2 | spdy];#监听端口，如果有多块网卡可以使用listen 192.168.1.2:80#ssl 用于限制只能通过SSL连接提供服务，不是以端口确认其协议,需要启用SSL,需要在监听的端口后面, 添加ssl选项。#http2 支持http version2，需要在nginx编译时开启http2协议支持#spdy google研发的http协议，比http1.1性能好。全称speedy,在编译时编译了spdy模块情况下，用于支持spdy协议server_name localhost;#服务名称或者域名，支持正则表达式匹配*.baidu.com 或者 ~^.*.baidu.com$charset koi8-r;#字符集设置access_log PATH main;#日志路径，以及使用哪个日志格式root /www;#设置web资源路径映射,用于指明请求url所对应的文件目录路径,可用于server或者location中 LOCATION通常位于server上下文，用于设定某URI的访问属性，location也可以嵌套, 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657....;http &#123; ....; upstream &#123; ...; &#125; server &#123; ...; location / &#123; root html; index index.html; try_files index.html /images/test1.html; &#125; location /images/ &#123; alias /data/imgs/; &#125; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125;root html;#定义url路径，这里是绝对路径，nginx下的html目录,当访问daemon.com/时候访问的是nginx下的html目录index index.html;#定义默认主页(nginx_http_index_module模块引入),可定义在http,server,locationtry_files $uri $uri/ /index.php?$args;#可用于server和location中,尝试查找第1到最后一个文件,如果第一个不存在跳转到下一个，必须确保最后一个存在,如果不存在则会导致死循环。alias /data/imgs;#只能用于location配置段,定义路径别名root和alias区别:location /imags/ &#123; root /data/imgs/;&#125;location /imags/ &#123; alias /data/imgs/;&#125;root指令:给定的路径对应location的"/",这个URI/imags/test.jpg --&gt; /data/imgs/imags/test.jpgalias指令:路径为对应的location的"/url/"这个URI/imags/test.jpg --&gt; /data/imgs/test.jpgerror_page code $uri;#定义错误页面，根据http状态码重写向错误页面#实例:error_page 404 /404.html;如果页面返回404就以404.html页面返回，状态码是404error_page 404 = /404.html;如果页面返回404就以404.html页面返回，状态码是200 location说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354location语法格式:location [ = | ~ | ~* | ^~ ] url &#123; ...&#125;= URI的精确匹配~ 做正则表达式匹配,区分字符大小写~* 做正则表达式匹配,不区分字符大小写^~ URI的左半部分匹配,不区分字符大小写!~,!~* 区分大小写不匹配，不区分大小写不匹配#允许根据用户请求的URI来匹配定义的各location,匹配到时, 此请求将被相应的location块中的配置所处理。#简言之:用于为需要用到专用配置的uri提供特定配置，当匹配多次时,其匹配优先级为:精确匹配=,^~,~或~*,不带符号的URL, 如果优先级都一样, 就匹配最精确的规则#优先级:location = / &#123; [configuration A]&#125;location / &#123; [configuration B]&#125;location /documents/ &#123; [configuration C]&#125;location ^~ /images/ &#123; [configuration D]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; [configuration E]&#125;#例子:location ~ /\.ht &#123; deny all;&#125;#当访问.htaccess文件时候拒绝所有location ~ \.php$ &#123; root /xxx; fastcgi_pass 127.0.0.1:9000;&#125;#将所有php文件推送到php-fpmlocation ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ &#123; ...;&#125;#匹配gif|jpg|jpeg|png|bmp|swf|js|css结尾文件location 后面"/"和没有"/"的区别#看个例子如果域名是www.zhuxyid.com,访问www.zhuxyid.com/helloworl的话location /hello &#123; #这里能匹配到 root xxx;&#125;location /hello/ &#123; #这里则不能匹配 root xxx;&#125; Nginx If判断在location中使用if语句可以实现条件判断，其通常有一个return语句，且一般与有着last或break标记的rewrite规则一同,防盗链模块使用。但其也可以按需要使用在多种场景下，需要注意的是，不当的使用可能会导致不可预料的后果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#if语句中的判断条件#正则表达式匹配： ~ 与指定正则表达式模式匹配时返回“真”，判断匹配与否时区分字符大小写； ~* 与指定正则表达式模式匹配时返回“真”，判断匹配与否时不区分字符大小写； !~ 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时区分字符大小写； !~* 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时不区分字符大小写；#文件及目录匹配判断： -f, !-f 判断指定的路径是否为存在且为文件； -d, !-d 判断指定的路径是否为存在且为目录； -e, !-e 判断指定的路径是否存在，文件或目录均可； -x, !-x 判断指定路径的文件是否存在且可执行； #例子:http &#123; upstream imageserver&#123; server 192.168.0.10:80; server 192.168.0.11:81; &#125; server &#123;&#125; location / &#123; if ($request_method == “PUT”) &#123; #如果客户端方法是PUT,就代理到0.11上，有点读写分离的感觉。 proxy_pass http://192.168.0.11:8021; &#125; if ($request_uri ~ "\.(jpg|gif|jpeg|png)$") &#123; proxy_pass imageservers; break; &#125; &#125; &#125;实例:#cookie首部检测匹配if ($http_cookie ~* "id=([^;]+)(?:;l$)") &#123; set $id $1;&#125;#请求报文的请求方法是POST,返回405if ($request_method = POST) &#123; return 405;&#125;#限速if($slow) &#123; limit_rate 10k; break;&#125;#非法引用,返回403,注:也可以对非法引用到其它页面if($invalid_referer) &#123; return 403;&#125;#根据IE类型重写if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;returncode [text];returncode URLreturn URL;#return:立即停止对请求的URI的处理,并返回指定的状态码set $variable value;#set:设定变量值,或者自定义变量rewrite_log on | off;#是否将重写日志记录errorlog中,默认为关闭(调试方法:错误日志debug,并开启rewrite_log) Nginx全局变量1234567891011121314151617181920212223$args$content_length$content_type$document_root$document_uri$host$http_user_agent$http_cookie$limit_rate$request_body_file$request_method$remote_addr$remote_port$remote_user$request_filename$request_uri$query_string$scheme$server_protocol$server_addr$server_name$server_port$uri Nginx反向代理Nginx通过proxy模块实现反向代理功能。在作为web反向代理服务器时，nginx负责接收客户请求，并能够根据URI、客户端参数或其它的处理逻辑将用户请求调度至上游服务器上(upstream server)。nginx在实现反向代理功能时的最重要指令为proxy_pass，它能够将location定义的某URI代理至指定的上游服务器(组)上。 反向代理：正对外部网络，如果客户端访问某个网站，但该网站不提供页面，只把请求代理只后端，在从后端返回至代理，在响应给客户端，该代理称作反向代理。 正向代理：针对内部网络，如果客户端不能访问外网，需要设置通过某台机器代理至外网，外网结果返回至代理机，在返回给客户端，该代理称作正向代理。 透明代理：针对内部网络，不需要设置任何代理服务器地址，但是需要将网关指向代理服务器。 参考：Nginx proxy中文文档 proxy模块指令proxy模块的可用配置指令非常多，它们分别用于定义proxy模块工作时的诸多属性，如连接超时时长、代理时使用http协议版本等.下面对常用的指令做一个简单说明。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556proxy_pass [domain | ip | upstream_name]|:PORT;#将location代理到哪里，这里可以是域名,IP,upstream名称，可以加端口，应用于Location上下文#这里值得注意:#当proxy_pass后有"/"时候，相当于绝对根路径，不会将location 中匹配的路径代理走#当proxy_pass后没有"/"时，会把location中部分路径代理走#示例:#访问:http://www.aaa.com/abc/index.html,配置如下location /abc/ &#123; proxy_pass http://127.0.0.1:8080/;&#125;#会代理到:http://127.0.0.1:8080/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080;&#125;#会代理到:http://127.0.0.1:8080/abc/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev;&#125;#会代理到: http://127.0.0.1:8080/devindex.html;localtion /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev/;&#125;#会被代理到: http://127.0.0.1:8080/dev/index.html;proxy_pass_header field;#传递头部给后端服务器proxy_hide_header field;#设定发送给客户端的报文中需要隐藏的首部proxy_set_header field value;#用于向后端服务器发请求报文时，将某请求首部重新赋值，或在原有值后面添加一个新的值#示例:proxy_set_header HOST $http_host;#将$http_host传递给HOST变量, 在nginx向后端发请求时,加入HOST首部proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#将客户端的真实IP地址赋值给X-Forwarded-For变量，在nginx想后端发时加入X-Forwarded-For变量，#如果中间有多层代理，每经过一层代理时,代理服务器都会将在后面增加自己的IP地址，并以分号分隔proxy_redirect;#重写location并刷新从后端收到报文首部proxy_connect_timeout;#nginx将一个请求发送到后端之前等待最大时长proxy_send_timeout;#在连接断开之前两次发送到后端的写操作的最大间隔时长proxy_rend_timeout;#在连接断开之前两次发送到后端接受操作的最大间隔时长proxy_cookie_domain;#发往后端时SET-COOKIE首部设定的domain属性修改为指定的值，可以设置为字符串,正则表达式模式或者一个引用变量proxy_cookie_path;#发送后端时通过SET-COOKIE首部设定的PATH属性修改为指定的值 proxy缓冲nginx在默认情况下在将其响应给客户端之前会尽可能地接收来upstream服务器的响应报文，它会将这些响应报文存暂存于本地并尽量一次性地响应给客户端。然而，在来自于客户端的请求或来自upsteam服务器的响应过多时，nginx会试图将之存储于本地磁盘中，这将大大降低nginx的性能。因此，在有着更多可用内存的场景中，应该将用于暂存这些报文的缓冲区调大至一个合理的值。 12345678proxy_buffer_size size#设定用于暂存来自于upsteam服务器的第一个响应报文的缓冲区大小；proxy_buffering on|off;#启用缓冲upstream服务器的响应报文，否则，如果proxy_max_temp_file_size指令的值为0，来自upstream服务器的响应报文在接收到的那一刻将同步发送至客户端；一般情况下，启用proxy_buffering并将proxy_max_temp_file_size设定为0能够启用缓存响应报文的功能，并能够避免将其缓存至磁盘中；proxy_buffers 8 4k|8k#用于缓冲来自upstream服务器的响应报文的缓冲区大小； proxy缓存nginx做为反向代理时，能够将来自upstream的响应缓存至本地，并在后续的客户端请求同样内容时直接从本地构造响应报文。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162proxy_cache_path PATH [levels=levels] keys_zone=name:size [inactive=time][max_size=size];#定义缓存，设置缓存名称，缓存路径，缓存大小等。只能用于HTTP上下文#实例:proxy_cache_path /data/nginx/cache/img levels=1:2:1 keys_zone=my_img:20m max_size=10g;#levels=1:2:1 #表示一级目录1个字符,二级目录2个字符,三级目录1个字符,最多只能设置3级#keys_zone=my_img:20m #存储键区域大小#max_size=1g #/img目录空间上限1G，当缓存对象超出时候,采用LRU清理，谁用的少清理谁#inactive #非活动缓存项从缓存中剔除之前的最大缓存时长#loader_files #缓存加载器每次工作过程最多为多少个文件加载器#loader_sleep #缓存加载器的每次迭代工作后的睡眠时长#loader_threashold #缓存加载器的最大睡眠时长proxy_cache NAME;#调用设置的缓存名称，必须实现设定好缓存proxy_cache_lock#在缓存未命中阻止多个相同的请求同时发往后端，其生效范围是worker级别proxy_cache_lock_timeout#proxy_cache_lock功能锁定时长proxy_cache_min_uses#某响应报文被缓存之前至少应该被请求次数proxy_cache_use_stale#在无法连到upstream服务器时候那种情况(error，timeout，http_500)让nginx本地缓存过期的缓存对象之间响应给客户端#实例proxy_cache_use_stable error|timeout|invalid_header|updating|http_50[1~4]|http_404|offproxy_cache_valid#用于为不同响应设定不同时长的有效缓存时长#实例proxy_cache_valid 200 302 10m;#设定状态为200和302的缓存时长为10分钟proxy_cache_methods [GET|POST|HEAD];#为那些方法启用缓存功能.proxy_cache_bypass STRING;#设置那种情况下，nginx不从缓存读取数据#实例proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment;proxy_cache_bypass $http_pragma $httpp_authorization;#配置实例http &#123; proxy_cache_path /data/nginx/cache levels=1:2:1 keys_zone=MYHTML:10m inactive=24h max_size=1g; upstream my_web &#123; server 172.16.0.2:8080; server 172.16.0.2:8081; &#125; server &#123; location / &#123; proxy_pass http://my_web; proxy_set_header Host $host; proxy_cache MYHTML; proxy_cache_valid 200 1d; proxy_cache_valid 301 302 10m; proxy_cache_vaild any 1m; &#125; &#125;&#125; Nginx常用模块nginx-limit模块 ngx_http_core_module，ngx_http_limit_conn_module，ngx_http_limit_req_module中的limit相关参数 123456789101112131415161718192021222324limit_except METHOD &#123;...&#125;;#对指定范围之外的其它方法进行访问控制,应用于location上下文#例子limit_except GET &#123; allow 172.16.0.0/16; deny all;&#125;limit_rate SPEED;#限制客户端每秒种所能够传输的字节数, 默认为0,表示不限制,应用于http,server,location,if in location上下文中#例子server &#123; if ($slow) &#123; set $limit_rate 4k; &#125;&#125;limit_rate_after SIZE;#超出SIZE的值, 就限制速度,应用于http,server,location,if in locataion上下文中#例子location /flv/ &#123; limit_rate_after 500k; limit_rate 50k;&#125; 访问控制12345678910111213141516#allow和deny可用于http，server，location上下文中allow address | CIDR | UNIX | ALL;#允许那些地址可以是网络地址deny address | CIDR | UNIX | ALL;#拒绝，同上例子:location / &#123; allow 172.16.0.2; allow 192.168.1.0/24; allow 2018:abc8::22; deny 172.16.0.1; deny all;&#125; 基本认证模块1234567891011auth_basic STRING;#定义认证名称,主要是提示作用.认证时显示提示信息auth_basic_user_file FILE;#用户认证的用户账号文件#格式:user1:pwd1user2:pwd2#也可以直接使用httpd程序提供的htpasswd生成#htpasswd -c -m /www/.htpasswd user1#&gt;pwd输入密码 自定义头信息12345678add_header_name value [always]#向响应报文添加自定义首部，并为其赋值,应用上下文为http,server.localtion中#例子add_hreader Via $server_addrexpires [modified] time;expires epoch | max | off#允许或者禁止向响应报文的cache-control或者expires首部添加新值或修改其值 nginx状态功能1234567891011121314151617181920#stub_statu功能,编译时添加--with-http_stub_status_module选项#实例location /my_ngx_monitor &#123; stub_status on; allow 172.16.0.100; deny all;&#125;#访问http://www.zhuxyid.com/my_ngx_monitorActive connections: 1server accepts handled requests2 2 18Reading: 0 Writing: 1 Waiting: 0#active connections:当前活动客户端连接数(包括等待)#accepts:已接受客户端连接总数量#handled:已处理完成的客户端连接请求总数量#requests:客户端总的请求数#reading:当前正在读取客户端请求报文首部信息的数量#writing:当前正在向客户端发送响应报文的链接数量#wating:长连接模式的保持连接个数,或者活动连接个数(reading+writing) nginx防盗链模块基于请求报文中的referer首部的值, 做访问控制 ,可以防止盗链,其只应用于server,location上下文 123456789101112131415161718referer_hash_bucket_size SIZE;#可以放多个缓存我要上,默认是64referer_hash_max_size SIZE;#默认2048valid_referers none|blocked|server_names|string...;#none : 请求的报文不存在referer首部#blocked : 请求报文中存在referer首部,但其没有有效值,或其值非以http://或https开头#server_names :其值为一个主机名#arbitrary string : 直接字符串,可以使用*号匹配#rugular expression : 以~起始的正则表达式#注意: 内置变量:$invalid_referer(所有不能符合valid_referer指定定义的引用请求均为不合法引用),需要加上条件判断语句#示例:valid_referers none blocked server_name *.example.com example.* www.example.org/aglleries/ ~\.google\.;if ($invalid_referer) &#123; return 403;&#125; nginx重写模块将请求的url基于正则表达式进行重写(URL重定向), 在如下情况下可以使用: http转换成httpd服务(http —- https) 域名转换domain.tld —-domain2.tld, URL转换uri1—-url2 1234567891011121314151617181920rewrite regex replacement [flag];#应用于server,location,if上下文regex:基于PERL的正则表达式,用于匹配用户请求的URL;replacement:重写重定向的结果flag:标志位[last|break|redirect|permanent]#regex:PCRE正则表达式元字符: 字符: .,[],[^] 次数: *,+,?,&#123;m&#125;,&#123;m,&#125;&#123;m,n&#125; 位置锚定: ^,$ 或者: | 分组: (), 后向引用: 2,…..#flag:last #重写完成之后停止对当前uri的进一步处理,改为对新uri的新一轮处理(对URI的重写规则进行匹配,当检查到第一条匹配到的时候,进行重写.然后返回到重写规则的第一条位置进行重新匹配,如果有匹配到的再进行重写,默认只能10次匹配). 此过程用户端感受不到.break #对URI的重写规则进行匹配,只要匹配到就重写,不再进行再次匹配,此过程用户端感受不到.redirect #重写完成之后返回客户端一个临时重定向,由客户端对新的URI重新发起请求, 即302的状态码permanent #重写完成之后,会返回客户端一个永久的重写向,由客户端对新的URI重新发起请求,即301的状态码 nginx ssl12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485listen 443;#监听端口server_name www.zhuxyid.com;#ssl主机的FQDN名称ssl_certificate cert.pem;#ssl的公钥ssl_certificate_key cert.key;#ssl的私钥ssl on | off;#启用或关闭ssl,若不在listen处定义，也可以在server&#123; &#125;中定义ssl on; 来启用https服务ssl_session_cache off | none | [builtin[:size]] [shard:name:size];#默认使用shared模式#off : 禁止缓存 ,关闭缓存,不支持缓存功能#none :禁止缓存 ,不响应缓存#builtin : 使用openssl内置的ssl会话缓存 ,此机制为各worker私有#shared: 在各worker之间使用一个共享的缓存,name:独有名称,size:缓存空间大小, 默认为1M,可以调到10M示例: ssl_session_cache shared:ssl:1m;ssl_session_timeout 5m;#ssl会议超时时长,即ssl session cache中的缓存有效时长,默认为5mssl_protocols [sslv2][sslv3][tlsv1][tlsv1.1][tlsv1.2];#使用哪些协议版本, 默认为TLSv1,TLSv1.1,TLSv1.2#ssl_protocols SSLv2 SSLv3 TLSv1;ssl_ciphers HIGH:!aNULL:!MD5;ssl_ciphers CIPHERS#nginx使用的加密算法ssl_prefer_server_ciphers on;#依赖SSLv3和TLv1协议的服务器密码将优先于客户端密码ssl_buffer_size SIZE;#ssl缓冲大小ssl_client_certificate file;#需要验证客户端证书ssl_crl FILE;#证书吊销列表ssl_trusted_certificate FILE;#信任的根证书#配置实例a.创建系统私钥(umask 077; openssl genrsa 2048 &gt; /PATH/cakey.pem)b.生成系统自签证书openssl req -new -x509 -key /PATH/cakey.pen -out cacert.pem一次输入:CN,JS,NJ,zhuxyid,it,ca.zhuxyid.com,caadmin@zhuxyid.comc.创建serial index.txtecho 01 &gt; serial &amp; touch index.txt &amp; cd nginx/ssl/d.创建私钥(umake 077;openssl genrsa 1024 &gt; nginx.key)openssl req -new -key nginx.key -out nginx.csr依次输入:CN,JS,NJ,zhuxyid,it,www.zhuxyid.comopenssl ca -in nginx.csr -out nginx.crt -days 3650more nginx.confserver &#123; listen 443; server_name www.zhuxyid.com; ssl on; ssl_certificate /ssl/nginx.crt; ssl_certificate_key /ssl/nginx.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers HIGH:!aNULL:!MD5; listen 443; location / &#123; root html; index index.html index.htm; &#125;&#125;/usr/local/nginx/sbin/nginx -s reload#这里只是测试用,如果是外网需要向权威机构申请证书，freessl.org nginx压缩模块123456789101112131415161718192021222324gzip on|off#开启压缩,通常位于http上下文gzip_comp_level [1-9]#压缩比率，默认为1，越大越占用cpu使用率gzip_types mine.types#指名对那些类型资源进行压缩gzip_disable msie6;#根据游览器来设置是否压缩，这里是ie6不开启压缩gzip_min_length 0#设置允许压缩页面最小字节数，页面字节从header头中的content-length获取，默认值0，不管页面多大都会被压缩，通常设置大于1k字节，小于1k可能越压越大，比如本身10字节，压缩一下反而大了，噗噗噗#实例:http &#123; gzip on; gzip_comp_level 6; gzip_disable msie6; gzip_types text/plain text/css text/xml application/x-javascript application/xml application/json application/java-script; gzip_min_length 2;&#125; 小结 对于nginx模块还有很多很多，以上是最基础的一些安装配置说明，后期还需要总结关于nginx的一些奇淫技巧]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F11%2F26%2FDockerfile%2F</url>
    <content type="text"><![CDATA[关于Docker基础,请看http://blog.zhuxyid.com/2018/11/23/Docker 自制镜像方式​ 基于容器方式来制作镜像，这种方法配置繁琐,不适合使用,每次配置文件更该都需要制作镜像 ​ 基于Dockerfile DockerfileDockerfile是一个文本文档，包含用户可以在命令行上调用命令组合，使用docker build用户可以自动构建一个连续执行多个命令行 Dockerfile编译完成科研使用docker build来进行编译Dockerfile文件 1docker build -t IMAGE_NAME:TAGS /DOCKERFILE_PATH/Dockerfile Dockerfile注意事项12345Comment #注释 INSTRUCTION arguments #指令 参数(指令不区分大小写，约定惯例尽量使用大写) docker运行指令是按照你的指令的顺序。Dockerfile文件首字母必须是大写 .dockeringore定义忽略哪些文件，打包时不包含这些文件 Dockerfile语法FROMFROM指令是最重的 一个且必须为Dockerfile文件开篇的第一个非注释行, 用于镜像文件构建过程 指定基准镜像，后续的指令运行于 此基准镜像 所提供的运行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在docker主机上查找指定的镜像文件，其不存在时，则会从Docker hub registry拉去所需的镜像文件 (如果找不到指定的镜像文件，docker build会返回一个错误信息) 123456789语法:FROM &lt;repository&gt;[:&lt;tag&gt;]FROM &lt;repository&gt;@&lt;digest&gt; @digest指定hash码进行验证 &lt;repository&gt;:指定作为base image的名称 &lt;tag&gt;:base image的标签 可选性，默认是latest例子:# Description: test imgFROM busybox:latest MAINTANIER用于让dockerfile制作者提供信息，Dockerfile并不限制MAINTAINER指令可在出现的位置，但推荐放在FROM指令后 1234567891011语法:MAINTAINER &lt;authtor's detail&gt;&lt;authtor's detail&gt; 可以是任何文本信息，但是通常使用名称和地址邮箱例子:MAINTAINER "zhuxyid &lt;zhuxyid@gmail.com&gt;"LABLE:指定镜像元数据Syntax:LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;例子: LABEL maintainer="zhuxyid &lt;zhuxyid@gmail.com&gt;" COPY用于从Docker主机复制文件到创建的新镜像文件 1234567891011121314语法：COPY &lt;src&gt;&lt;dest&gt;COPY ["&lt;src&gt;",.."&lt;dest&gt;"] 如果路径有空白字符时候，用这种方式复制 src 源文件，支持使用通配符 dest 目标路径 即正在创建image文件系统路径,建议&lt;dest&gt;为绝对路径，否则COPY指定则以WORKDIR为起始路径文件复制准则:&lt;src&gt; 必须是build上下文中路径，不能是父目录的文件如果&lt;src&gt;是目录，则 内部文件或子目录都会 被递归复制,但&lt;src&gt;自身目录不会被复制 相当于 cp -r src/* /dest如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用通配符，则&lt;dest&gt;必须是一个目录，且必须以/结尾 相当于 cp -r src/* /desc/如果&lt;dest&gt;不存在，则会被自动创建，这包括其父目录路径例子：COPY index.html /data/web/html/ #这里index.html文件必须先创建，而且必须为build目录下！ ADDADD指令类似COPY指令，ADD支持使用TAR文件和URL路径 1234567891011语法:ADD &lt;src&gt;,..&lt;dest&gt;ADD ["&lt;src&gt;",.."&lt;dest&gt;"]操作准则: 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接创建为&lt;dest&gt;; 如果&lt;dest&gt;以/结尾,则文件名URL指定文件将被直接下载并保持为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式tar文本，他将被展开为一个目录，其行为类似"tar -x"命令，然而通过URL获取到的tar文件将不会自动展开 如果&lt;src&gt;有多个，或其间接或直接使用通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径； 如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt; WORKDIR用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 12345678语法:WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指定可出现多次，其路径也可以为相对路径，不过其是相对此前一个WORKDIR指令指定的路径,另外，WORKDIR也可以调用由ENV指定定义的变量例子：WORKDIR /var/logWORKDIR $STATEPATH VOLUME用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上的卷 1234语法:VOLUME &lt;mountpoint&gt;VOLUME ["&lt;mountpoint&gt;"]如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 EXPOSE用于为容器打开指定要监听的端口以实现与外部通讯,注意，这里只能是定义容器的端口.后期docker下载下来宿主机的端口并不确定 123456789语法：EXPOSE &lt;port&gt; [/&lt;protocol&gt;][&lt;port&gt;[/&lt;protocol&gt;]...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议EXPOSE指令可一次指定多个端口，如EXPORT 11211/udp 11211/tcpdocker run --name ttt -P 可以自动暴露需要暴露的端口 ENV用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY等)所调用 WORKDIR只是工作目录 调用格式为$variable_name或者${variable_name} 123456789语法:ENV &lt;key&gt;&lt;value&gt;ENV &lt;key&gt;=&lt;value&gt;$&#123;NAME:-tom&#125; #如果NAME变量没有值，将他设为tom，如果有值则使用本身$&#123;NAME:+tom&#125; #如果NAME为空则不设置，如果不为空则设置tom第一种格式中,&lt;key&gt;之后的所有内容均被视作其&lt;value&gt;的组成部分，因此，一次只能设置一个变量第二种格式中,可用一次设置多个变量，每个变量为一个&lt;key&gt;=&lt;value&gt; 的键值对，如果&lt;value&gt;中包含空格，可用反斜线(\)进行转移;也可以通过对&lt;value&gt;加引号进行标识,另外反斜线可以续行定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能 RUN用于指定docker build过程中运行的程序，其可以是任何命令 123456789语法:RUN &lt;command&gt;RUN ["&lt;executable&gt;","&lt;param1&gt;","&lt;param2&gt;"]第一个格式中,&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程在容器中的PID不为1，不能接受Unix型号，因此，当使用docker stop container命令停止容器时，次进程接受不到SIGTERM信号第二个格式中，参数就是一个JSON格式的数组，其&lt;executable&gt;为运行的命令，后面的&lt;paramN&gt;为传递给命令的选项或参数；然而此格式指定的命令不会以"/bin/sh -c"来发起；因此常见shell操作，如变量替换以及通配符(?,*等)替换将不会进行；不过如果要运行的命令依赖次shell特性的话，可以将其替换为类似下面格式RUN ["/bin/bash","-c","&lt;excutable&gt;","&lt;param1&gt;"] CMD类似RUN指令，CMD指令也可以用于运行任何命令或应用程序，不过二者运行时间点不同 RUN 指令运行与镜像文件构建过程，而CMD指令运行基于Dockerfile构建出的新映像文件启动一个容器时 CMD 指定的首要 目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器将终止；不过CMD指令的命令其可以被docker run的命令选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅是最后一个会生效，而RUN不是 1234567语法:CMD &lt;command&gt;CMD ["&lt;excutable&gt;","&lt;param1&gt;","&lt;param2&gt;"]CMD ["&lt;param1&gt;","&lt;param2&gt;"]前两种语法格式的意义相RUN第三种则用于为ENTRYPOINT指令提供默认参数 RUN 是运行在docker build过程中的命令，而CMD 是在docker run运行时的命令 注意:一个容器只是用于单个应用。nginx,redis,mysql都是运行在后台 所有进程都是一个进程的子进程，除了init。init是内核启动 比如手动启动nginx，它是shell的子进程，有些shell子经常会占据终端窗口，需要加&amp;符号 nginx &amp; 这里nginx父进程依然是shell，当shell结束后，会将nginx也结束 nohup nginx &amp; 这里是将nginx送到后台，重新赋予一个新的进程，这是shell退出这个依然存在 在用户空间先启动shell,才能使用ls，cat，等命令，可以直接exec执行命令. 在容器中可以基于shell启动程序，也可以通过exec启动程序 在json数组中，引号一定要写双引号，单引号可能会出现问题 ENTRYPOINT类似CMD指定的功能，用于为容器指定默认运行程序，从而使得容器像一个单独的可执行程序 于CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令指定的参数所覆盖，而且，这些命令参数会被当做参数传递给ENTRYPOINT指定指定的程序 不过,docker run命令的–entrypoint选项参数可覆盖ENTRYPOINT指令指定的程序 12345678910111213141516171819202122语法:ENTRYPOINT &lt;command&gt;ENTRYPOINT [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]ENTRYPOINT /bin/http -f -h /data/www/htmldocker run命令传入的命令参数会覆盖CMD指令的内容并且附加到EMTRYPOINT命令最后作为其参数使用Dockerfile文件中可用存在多个ENTRYPOINT指令，但仅最后一个生效如果Dockfile格式是这样CMD和ENTRYPOINT同时存在CMD [&quot;/bin/httpd&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;]CMD /bin/httpd -h /data/web/html #这样写会出错，因为不会被当成参数，需要写成列表的形式ENTRYPOINT /bin/httpd -f -h /data/web/html #如果需要CMD传参，这里建议写成列表，不然有问题CMD和ENTRYPOINT同时存在，那么CMD会将命令变成参数传递给ENTRYPOINT例子CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;] ENTRYPOINT [&quot;/bin/sh&quot;,&quot;-c&quot;]#CMD将传给ENTRYPONT作为默认参数#如果执行docker run --name ttt --rm image:v1 &quot;ls /data&quot;#&quot;ls /data&quot;则会覆盖CMD#如果执行docker run --name ttt --entrypoint &quot;ls&quot; --rm image:v1 &quot;/data&quot;#ls会覆盖EXTRYPOINT,/data覆盖CMD USER用于指定运行image时或者运行Dockerfile中任何RUN,CMD或者ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下, container运行身份是root用户. 123语法USER &lt;UID&gt;|&lt;USERNAME&gt;需要注意:&lt;UID&gt;可以是任意数字，但实践中必须为容器中/etc/passwd中某用户的有效UID,否则docker run会失败 HEALTHCHECK健康状态检查，判断容器里面的程序是否正常运行. 这里需要注意，如果nginx指定的目录不存在，nginx也会运行，但是用户访问是访问不了的，可以断定这虽然是可以运行但不是想要的结果，比如使用curl检测网页200的信息，如果是200则正常，非200则不正常 123456789101112131415HEALTHCHECK定义一个CMD来检测容器中主进程工作状态与否 HEALTHCHECK NONE 拒绝任何监控状态检查格式: HEALTHCHECK [OPTION] CMD --interval=DURATION(default:30s) 每隔多久 --timeout=DURATION(default:30s) 超时时长 --start-period=DURATION(default:0s) 等待主进程初始化完成在检查，如果tomcat这种应用建议等待5秒 --retries=N(default:3) 检查次数，默认3次#检测状态结果：0:success1:unhealthy2:reserved实例:HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1 #每隔5分钟检查，超时时间3s，curl结果如果成功则不管他，如果不成功则返回1 SHELLlinux默认shell是[“/bin/sh”,”-c”] windows默认是[“cmd”,”/S”,”/C”] 格式：SHELL [&quot;/bin/bash&quot;,&quot;-c&quot;] STOPSIGNAL定义停止的信号，默认是15 格式: STOPSIGNAL 14可以修改停止的信号 ARGARG的参数只是一个变量，只在docker build时候使用，在--build-arg &lt;varname&gt;=&lt;value&gt; 12345678910111213141516语法：ARG &lt;name&gt;[=&lt;default value&gt;]ARG version=1.14ARG user=zhuxyid例子:FROM:nginx:$&#123;version&#125;ARG version=1.15LABEL maintainer=$&#123;author&#125;ARG version=&quot;1.15&quot;ARG author=&quot;zhuxyid &lt;772931883@qq.com&gt;&quot;docker build -t nginx ./docker build --build-arg &quot;version=1.16&quot; --build-arg &quot;author=zhuxyid&lt;hello@qq.com&gt;&quot; -t nginx ./ #可以直接在编译时候使用在docker build中可以用--build-arg参数来传值 ONBUILD用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile作用FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中FROM指令在build过程中被执行，将会”触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 12345678910111213141516语法:ONBUILD &lt;INSTRUCTION&gt;#尽管任何指令都可注册成触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和MAINTAINER指令#使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild#在ONBUILD指令中使用ADD或者COPY要格外小心，因为新构建过程中的下下文在缺少指定源文件会失败例子:cat /dockerfile/baseFROM centos:latestONBUILD RUN yum install nginx gcc gcc-c++#docker build -t base.img ./ #这里并不去安装nginx gcc gcc-c++cat /dockerfile/phpprojectFROM base.img #指定基于刚才创建的base.img作为base imageRUM yum install php-5.6#docker build -t php:v1 ./ #这里才会去安装， Example1234567891011121314151617181920212223242526272829303132333435363738394041424344mkdir /data/container/web1 cp -r /etc/yum.repos.d /data/container/web1/ cd /data/container/web1 wget &lt;http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.90/bin/apache-tomcat-7.0.90.tar.gz&gt; #more Dockerfile #Description: test dockerfile FROM busybox:latest LABEL maintainer=&quot;zhuxyid &lt;zhuxyid@gmail.com&gt;&quot; ENV DOC_ROOT /data/web/html/ #定义DOC_ROOT变量 ENV TOMCAT_ROOT=/data/tomcat/ \ #定义多个变量 TOMCAT_VERSION=&quot;tomcat-7.0.90&quot; \ NGINX_VERSION=&quot;nginx-1.14.0.tar.gz&quot; COPY index.html $DOC_ROOT COPY yum.repos.d /etc/yum.repos.d/ WORKDIR /opt/ADD http://nginx.org/download/nginx-1.14.0.tar.gz ./ VOLUME /data/www ADD apache-$&#123;TOMCAT_VERSION&#125;.tar.gz $&#123;TOMCAT_ROOT:-/data/tomcat/&#125; EXPOSE 80/tcp RUN cd /opt &amp;&amp; \ tar xf $&#123;NGINX_VERSION&#125; &amp;&amp; \ mv nginx-1.14.0 /usr/local/nginx #建议使用一条命令，因为如果多个RUN 那么层级就会越多 echo &quot;this is docker build image&quot; &gt; index.html docker build -t zhuxyid/index:v1 ./#-t指定name:tagdocker run --name web1 -it --rm zhuxyid/index:v1 cat /data/web/html/index.html #查看web1容器中/data/web/html是否有文件index docker run --name webserver --rm -P zhuxyid/index:v1 httpd -f -h /data/web/html docker port webserver docker run --name ttest --rm -P zhuxyid/index:v1 printenv#prinenv查看环境变量 #注意在启动容器的时候可以重新设置环境变量 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 printenv #在初始化容器时候可以重新赋值 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 ls /data/tomcat/apache-tomcat-7.0.90.tar.gz #这里只是重新赋值变量并不能修改image，因为这是docker build中已经生成了]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>DevOps</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F11%2F23%2FDocker%2F</url>
    <content type="text"><![CDATA[容器是什么 容器是一种基础工具，泛指任何可以用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，存储，运输物品；物体可以被放置在容器中，而容器可以保护内容物. 虚拟化技术有哪些主机级别 虚拟化 完全 虚拟化：Vmware，Kvm，Xen 半 虚拟化：Xen,UML Xen如果CPU不支持虚拟化技术那就是半虚拟化，如果支持就是全虚拟化 半虚拟化：修改内核，通过被虚拟化出来的操作系统它是运行在虚拟化技术软件上的，虚拟化出来的操作系统执行的进程还是运行在真实机器上 完全虚拟化：不需要修改内核，直接通过虚拟机化技术软件上运行的操作系统。 容器级别 虚拟化 LXC,OpenVz,Solaris Containers,FreeBSD jails LXC(LinuX Container)容器是内核虚拟化技术,可以提供轻量级的虚拟化,以便隔离进程和资源,不需要提供指令解释机制以及全虚拟化的其他复杂性.容器可以有效的将单个操作系统管理的资源划分到孤立的组件中,以便更好的孤立组之间的平衡有冲突的资源使用需求。 早期容器应用在jail中,后来移植到linux中vserver(chroot),chroot所隔离仅仅只是看上去的,并没有真正隔离。 Linux namespace 是linux提供一种内核级别环境隔离的方法，有6种不同名称空间: linux namesapce: namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 MOUNT CLONE_NEWNS 挂载点(文件系统) 2.4.19 IPC CLONE_NEWIPC 信号量,消息队列,共享内存 2.6.19 PID CLONE_NEWPID 进程变化 2.6.24 USER CLONE_NEWUSER 用户和用户组 3.8 NETWORK CLONE_NEWNET 网络设备,网络栈,端口等 2.6.29 Docker是什么Docker是LXC增强版,Docker简化容器使用难度,通常一个容器中只运行一个进程. 对开发来说带来极大便利,分发容易,一次编写到处运行 然而对运维来说(有优点有缺点), 对开发极大便利需要运维干什么? Docker安装环境说明: 操作系统发行版:CentOS7.4 内核版本:3.10+ 安装说明: 使用yum方式安装,下载国内docker的yum源,加速下载. 安装过程:12345wget -P /etc/yum.repos.d/ https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i s@https://download.docker.com/@https://mirrors.tuna.tsinghua.edu.cn/docker-ce/@g /etc/yum.repos.d/docker-ce.repoyum repolist | grep docker-ceyum install docker-cesystemctl start docker.service 此时docker已经启动了，现在我们来搞清楚什么是docker Docker架构c/s架构，由三个组件（Docker Daemon,Docker Client,Docker Registry）构成 Docker Registry：​ 类似GitHub,只不过Docker Registry是存放镜像的仓库， 官方 https://hub.docker.com 国内 https://www.docker-cn.com/ 当然也可以自己部署一个仓库，建议用Harbor。 Docker Daemon：​ Docker进程，Docker核心服务。 这个类比数据库，比如数据库是放数据的，启动数据库后，等待客户端连接后才能操作。 也就是当docker启动时，等待docker客户端来操作。 Docker Client：​ Docker客户端工具,用来操作Docker的 比如我想在仓库下载一个镜像，从而启动一个容器，在容器中启动一个nginx服务,都是在客户端操作的。（docker client是发出者，docker daemon是执行者） 这里提到的镜像和容器一定要区分清楚。 如果是开发,那这么理解：镜像就是你创建的类，容器就是你的对象，对象是通过类实例化而来。也就是容器通过镜像而来,（容器依赖于镜像） 不要问镜像怎么来的，上面提过镜像是在仓库中。 也不要问仓库中的镜像怎么来的，那是别人做好的。因为你也可以自己做镜像。 Docker客户端操作12docker --help 格式:docker [option] command [args] 镜像类操作1234567891011121314docker search SOFTWARE_NAME #查找镜像名称示例: docker search tomcat #查找tomcat相关镜像，通常建议使用官方镜像，OFFICIAL 为OK的，或者Star点赞数高的镜像，原因自己悟docker pull SOFTWARE_NAME:TAGS #下载镜像示例: docker pull tomcat #下载tomcat镜像，如果不指定tags就下载latest版本 docker pull tomcat:7.0.92-jre8-alpine #详见hub.docker.com找到指定的镜像后在看tagdocker image ls #查看本地镜像，如果没有下载那么这里为空docker image rm SOFTWARE_NAME:TAGS #删除本地镜像示例: docker image rm tomcat #如果不指定删除镜像版本默认删除latest 容器类操作123456789101112131415161718192021222324252627282930313233343536373839404142docker run #运行容器，需要指定镜像实例: docker run tomcat #运行镜像为tomcat的容器,容器里面有tomcat,启动容器后tomcat也将运行起来，容器里面的程序都是在前台运行，会占用窗口 docker run --name myapp -d tomcat #启动myapp容器，镜像使用tomcat:latest，以后台运行 更多命令使用:docker run --help docker ps #查看运行中的容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee1ff8df6e70 tomcat "catalina.sh run" 3 seconds ago Up 2 seconds 8080/tcp myapp说明: 如果在docker run不指定容器名称会随机创建一个容器名称。 端口是容器内的端口.关于docker网络的内容下面会有讲解docker exec实例: docker exec -it myapp /bin/bash #进入myapp容器中 -it #新建一个tty并且进入docker stop实例: docker stop myapp #停止myapp容器 docker ps -a #查看所有容器，如果不加-a不能看到停止的容器 docker start实例: docker start myapp #运行停止的容器docker restart #重启容器实例: docker restart myappdocker rm #删除容器实例: docker rm myappdocker logs #查看容器运行的程序日志实例: docker logs myapp docker kill #杀死容器里的进程，进程一旦停止，容器也就停止。因为容器一般只运行一个前台程序，容器的生命周期下面会讲解实例: docker kill myapp Docker ImageDocker镜像包含启动容器的所需文件系统以及其内容，因此，用于创建并启动docker容器： 分层机制：镜像采用分层构建机制，最底层为bootfs,其为rootfs。 rootfs：用于系统引导的文件系统，包含bootloader和kernel，容器启动完成后被卸载以节约内存资源 rootfs：位于bootfs之上，表现为docker容器根文件系统 传统模式中，系统启动时，内核挂载rootfs时首先将其挂载为“只读”模式，自检其完整性 完成后将其重新挂载为读写模式 docker中，rootfs由内核挂载为“只读”模式，而通过“联合挂载”技术额外挂载一个可写层，容器就是在镜像多了一个可写层 传统模式: Docker: docker镜像层级：位于下层的镜像 称之为 父镜像(parent image)，最底层的称之为 基础镜像(base image) 最上层“可读写成”，下面为“只读层” 联合挂载：Aufs（advanced multi-layered unification filesystem ） 高级多层统一文件系统，同于实现linux平台中的联合挂载 Aufs是unionFS的重新实现,docker最初使用aufs作为容器文件系统层，目前仍作为存储后端之一来支持 Aufs另外一个实现是overlayFS，后者从3.18版本中开始被合并到linux内核中，overlayerFS是叠加文件系统 除了aufs，docker还支持btrFS,Device Mapper和VSF等。在ubuntu中，默认是aufs device mapper在linux2.6中支持逻辑卷管理的通过设备映射机制，它为实现用于存储资源管理的块设备驱动提供一个高度模块化的内核架构，它通过一个个模块化的target driver插件实现对IO请求的过滤或者重新定向等工作，当前已经实现的target driver插件包括软raid，软加密，逻辑卷条带，多路径，镜像，快照等。 docker使用Thin provisioning的snapshot的技术实现了类似auFS分层镜像 12&gt; docker info | grep "Storage Driver:" #来查看&gt; Docker ContainerDocker容器具有生命周期，”STOPD”,’CREATED’,’RUNNING’,’PAUSED’四个稳定状态， 容器一旦删除数据就会丢失，所以项目或者配置文件不要直接存放在容器中，通过卷（volume）的方式挂载至容器里. Docker事件状态图: Docker Registry当容器启动时,docker daemon会试图先从本地获取相关镜像，当本地不存在的时候，其将从registry中下载该镜像并保存在本地 流程图: docker client &lt; - - - http/https - - - &gt;docker daemon &lt; - - - http/https - - - &gt;docker registry 默认是使用https连接到registry，但是可以修改成http Registry 分类registry用于保存docker镜像，包括镜像的层次结构和元数据: 用户可自建registry，也可以使用官方的docker hub 分类: sponsor registry 第三方registry，供客户和docker社区使用 mirror registry 第三方registry，只让客户用 verdor registry 由发布docker镜像的供应商提供registry private registry 通过舍友防火墙和额外的安全层的私有实体提供的registry repository及indexrepository 由某种特定的docker镜像的所有迭代版本组成的镜像仓库 一个registry中可以存在多个repository repository 可以为”顶层仓库”和“用户仓库” 用户仓库名称格式”用户名/仓库名” 每个仓库可以包含多个Tag，每个标签对应一个镜像 index 维护用户账号,镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 镜像相关操作主要介绍镜像如何生成，和如何推送镜像至仓库 镜像生成方式:​ 有三种方式：基于容器方式，Dockerfile方式，Docker Hub Automated Builds 基于容器制作镜像:1234567891011121314151617181920docker run --name web1 -it busybox &gt;mkdir -p /data/www/ &gt;echo "&lt;h1&gt;welcome busybox http server&lt;/h1&gt;" &gt; /data/www/index.html #注意:基于容器制作镜像，容器必须处于运行状态，这里切换终端 docker commit -p web1 #commit制作镜像前需要—p暂停docker image ls #可以看到镜像制作完成（缺少tag） docker tag IMAGEID zhuxyid/busyhttp:v1 #给刚才制作的镜像打标签(可以打多个标签) docker tag zhuxyid/busyhttp:v1 zhuxyid/busyhttp:test_env #在打一个标签 docker image rm zhuxyid/busyhttp:v1 #这里只是删除一个标签，并没有删除镜像 #查看镜像启动时候运行的命令 docker inspect web1 | grep -A 5 "Cmd" #如何在制作镜像运行时执行启动命令 docker commit -a "作者:zhuxy" -c 'CMD ["/bin/httpd","-f","-h","/data/www"]' -p web1 zhuxyid/busyhttp:test_env#运行制作后的镜像 docker run --name -d webserver zhuxyid/busyhttp:test_env 基于Dockerfile制作镜像: 详见:http://blog.zhuxyid.com/2018/11/26/Dockerfile/ 推送镜像推送到官方首先需要有hub.docker.com账号 ，hub.docker.com需要先建立好repositories 示例：这里的是zhuxyid/busyhttp命名,要跟本地的镜像保持一致 12345docker login #输入账号密码才可以登录 docker push zhuxyid/busyhttp:test_env #推送制作的镜像docker logout 推送到阿里云需要修改docker配置文件中的推送地址 12345678910111213141516171819#修改docker配置文件添加registry-mirrors,https://brjvf90f.mirror.aliyuncs.com为我自己的阿里云镜像仓库vi /etc/docker/daemon.json &#123; "registry-mirrors":["https://registry.docker-cn.com","https://brjvf90f.mirror.aliyuncs.com"]&#125;&#125;#重载配置文件并重启systemctl daemon-reloadsystemctl restart docker.service #阿里云创建命名空间，在创建镜像仓库 docker login --username=zhuxyid registry.cn-hangzhou.aliyuncs.com #先重命名镜像标签 docker tag imagename registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:test_env#在推送到阿里云docker push registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:version docker logout 镜像导入导出1234567#在本地导出镜像包，推送到目标机docker save -o busyhttp.gz zhuxyid/busyhttp:latest .. #可以打包多个文件 scp busyhttp.gz root@REMOTEIP:/opt#在目标机上导入推送的镜像docker load -i busyhttp.gz docker image ls Docker网络Docker安装后自动创建docker0网卡(虚拟) 网络虚拟化技术实现: OVS：Open VSwitch 开源虚拟交换 SDN：Software Defined Network 软件定义网络（需要硬件和软件支持） Docker网络接口Docker有三种网络接口： bridge，host，none，Containers 123456789docker image lsNETWORK ID NAME DRIVER SCOPE1f03c706f810 bridge bridge local75c5f8de6db4 host host local871ede94efa8 none null localbridge 桥接物理主机网卡(默认).这里是nat桥接，并不是物理桥接，如果是物理桥接,如果一个交换机下每个宿主机都有十几个容器，很容易导致广播风暴host 使用物理主机的名称空间none 不使用网络(特殊场景,有些程序不需要使用网络通信,比如自动任务不需要网络通信) docker安装后，会生成docker0，此网卡是个NAT桥，当启动容器的时候，宿主机也会生成veth*虚拟网卡，该网卡和容器内的网卡绑定，而veth*就是跟docker0相连，可以使用brctl show来查看 12345678910yum install bridge-utilsbrctl show #可以看出veth网络都是跟docker0关联bridge name bridge id STP enabled interfacesdocker0 8000.024259bff40e no veth05116c6 vethf8f26a6 iptables -t nat -vnL #查看POSTROUTING链,可以看出容器内访问其他网络都是通过MASQUERADE地址伪装方式访问Chain POSTROUTING (policy ACCEPT 54 packets, 3570 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 Docker通讯Docker中如果外部想访问内部的服务有如下三种方式: Bridge方式： 通过桥接，然后设置dnat才能被其他主机访问 Containers方式: 容器可以将6个名称空间分层: 如：docker-a和docker-b docker-a独立6个名称空间:USER,MOUNT,PID,UTS,NET,IPC docker-b独立3个名称空间:USER,MOUNT,PID,另外UTS,NET,IPC共享docker-a的 Host方式： 相当于Open container方式，只不过直接使用宿主机的UTS.NET.IPC Docker 网络相关命令指定网络类型以及端口映射123456789101112#docker run --name test -it --rm busybox:latest #运行busybox命名为test，执行完后直接删除 --network [none|bridge] #指定网络类型(默认是bridge) --hostname|-h HOSTNAME #指定主机名 --dns 114.114.114.114 #指定dns --add-host HOST:IP #设置容器hosts #映射 -p &lt;containerPort&gt; #将指定的容器端口 映射至 主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; #将容器端口containerPort 映射至 主机指定的主机端口&lt;host Port&gt; -p &lt;ip&gt;::&lt;containerPort&gt; #将指定的容器端口&lt;containerPort&gt; 映射至 主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;HostPort&gt;:&lt;containerPort&gt;#将指定容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; -P #-P暴露所有端口 Bridge1234567docker run --name test -it --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --dns 114.114.114.114 --rm busybox:latestdocker run --name webserver -p 80 -d busybox/httpd:latest #本地随机端口映射到容器的80端口docker run --name webserver -p 80:80 -d busybox/httpd:latest #本地80端口映射到容器的80端口docker port webserver #查看webserver容器端口 Containers联盟式容器是指使用某个已存在容器的网络接口的容器，接口被联盟内的各容器共享使用，因此，联盟式容器彼此间完全无隔离 #创建一个监听于80端口的http服务容器 docker run -d --it --rm -p 80:80 busybox/httpd:laster #创建一个联盟式容器 docker run --name web1 -it --rm busybox/httpd docker run --name web2 --network container:web1 -it --rm busybox/httpd #在web2中创建的文件web1看不到，因为隔离Mount名称空间，但是web1和web2的ip是一样的，因为web2共享了web1的Net名称空间 #联盟式容器彼此间 虽然 共享同一个网络名称空间，但其他名称空间如User,Mount，Pid等还是隔离的 #联盟式容器彼此间存在端口冲突的可能性，因此，通常只会在多个容器上的程序需要程序lookback接口互相通信，或对某已存在的容器的网络属性进行监控时才使用此模式的网络模型 Host 创建一个宿主机host的容器 123docker run --name webserver --network host -it --rm busybox/httpd#使用宿主机的IP，可能会郁闷，这跟直接在主机上部署个httpd服务在启动有什么不一样么？#容器，容器可以更加方便移值，直接run container就可以运行了。 Docker存储关于卷Docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层 并在镜像栈顶部 添加一个 读写层，如果运行中容器修改了现有的一个已挂载的文件，那该文件将会从 读写层下面的只读层 复制到读写层，该文件的只读版本依然存在，只是已经被读写层中该文件的副本所修改，即“写时复制(COW)”机制 注意:在IO要求高应用中，如果使用容器的话，那么效率非常低 Container: /data/web &lt; - - - - 建立绑定关系Mount - - - - &gt; Host:/container/web1/data/web 在容器写入时候，可以绕过容器内部层级关系 命名空间Mount是相互独立的,可以共享,关联到存储卷Volume，只要容器挂载存储卷.当容器被停止或者删除后,文件内容不被删除。 为什么用存储卷关闭并重启容器，其数据不受影响，但是删除容器，则数据全部丢失 存在的问题: 存储于联合文件系统中，不易于宿主机访问 容器间数据共享不便利 删除容器其数据丢失 卷的描述卷在容器初始化时候 会自动创建，由base image提供的卷中数据会于此间 完成复制 卷的初衷是独立于容器的生命周期实现数据持久化，因此删除容器时不会删除卷，也不会对哪怕未被应用的卷做垃圾回收 卷为docker提供了独立于容器的数据管理机制 可以把”镜像” 比作成静态文件，例如“程序” ，把卷类比为动态内容，例如“数据”；于是镜像可以重用，而卷可以共享 卷实现了”程序(镜像)”和“数据(卷)”分离，以及 “程序(镜像)”和“制作镜像主机”分离，用户制作镜像时无需考虑镜像运行容器所在的主机环境 卷的类型docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同 绑定挂载卷 bind mount volume: 在宿主机人工指定特定路径，在容器也人工指定特定路径，将两者绑定 容器管理卷 docker-managed volume: 宿主机不需要指定路径(docker daemon)，容器中需要指定路径，docker自动将两者绑定 如何使用卷12345678910111213141516171819docker run -v 选项docker-managed volumedocker run -it --name web1 -v /data busyboxdocker inspect -f &#123;&#123;.Mounts&#125;&#125; web1 #查看容器卷绑定关系docker run -it -v HOSTDIR:VOLUMEDIR --name web2 busyboxdocker run -it -v /data:/test --name web2 busybox #本机的data跟容器的test绑定，如果data不存在自动创建docker inspect -f &#123;&#123;.Mounts&#125;&#125; web1docker inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; web1 #获取web1下的ip地址#多个容器的卷使用同一个主机目录docker run -it --name nginx1 -v /docker/volumes/html:/data busyboxdocker run -it --name tomcat1 -v /docker/volumes/class:/data busybox#复制使用其他容器的卷，为docker run命令使用--volumes-formdocker run -it --name tomcat2 -v /docker/volumes/class:/data busyboxdocker run -it --name tomcat3 --network container:tomcat2 --volumes-from tomcat2 busybox #共享网络和卷 Docker资源限制默认情况下,系统对容器没有做任何资源限制，容器可以使用掉宿主机所有资源。 docker provides可以控制Memory，CPU， Block IO（其实只能控制内存和CPU） 依赖于Linux Capabilities 。 这里需要注意:内存是非可压缩资源，CPU可压缩资源 ​ 如何内存被进程耗尽会触发OOME直接KILL进程，而CPU没有关系 OOM在linux主机中，如果内核探测到当前宿主机没有足够内存可用(用于执行某些重要的系统功能)会抛出OOME 异常，并且kill掉某些进行保证其正常,一旦发生OOME,任何进程包括docker daemon在内,都有可能杀死。因此docker特地调整 docker daemon的OOM优先级，以免它被内核”杀死”，但容器的优先级并未被调整 。 优先级越低，得分越低，通常检测oom-adj，分数越高越容易被kill 不重要的业务建议oom-adj默认值，重要的调低oom-adj Memory从ram，swap两个层面: 123限制单位k,b,m,g-m | --memory 限制ram内存 -m 1g 限制ram为1g，如果后期资源占用超过1G，可能被kill掉，-m|--memory可以单独设置--memory-swap * 限制swap内存 必须先设置-m|--memory –memory-swap –memory 功能 正数S 正数M 容器可用总空间为S,其中ram为M,swap为(S-M),如果S=M，则无可用swap资源 0 正数M 相当没有设置swap(unset) unset 正数M 若主机(docker host)启用swap,则容器可用的swap为2*M 1 正数M 若主机(docker host)启用了swap,则容器可使用最大至主机上的所有swap空间的swap资源 注:在容器使用free命令可用看到swap空间并不具有 其所展现出空间的指示意义 设置–memory-swap必须大于–memory 12345--memory-swapiness 限制容器的虚拟内存控制行为0~100间整数--memory-reservation 限制预留空间大小--kernel-memory 核心内存的限制--oom-kill-disable 如果容器重要，禁止oom被kill掉--oom-score-adj 容器被OOM killer杀死的优先级，范围[-1000,1000]默认为0 CPU默认情况下每个容器，可以使用CPU的资源.大多数系统，系统在调度时候使用CFS调度 (CFS完全公平调度器) 在docker1.13后，可以设置实时调度 1234567--cpus=&lt;value&gt; #设置CPU使用几核心，如果容器只设置了--cpus = 2，那么该容器只能使用200%的cpu--cpu-period=&lt;value&gt; #最多使用多长时间--cpu-quota=&lt;value&gt; #指定周期内--cpuset-cpus #设置容器只能运行在那核心CPU上,如果4核心这里是0~3 如果上面设置--cpus=2 --cpuset-cpus 1,2 意思是使用2核心，只在cpu2和cpu3上面使用--cpu-shares #设置cpu权重，按比例切分，默认权重是1024，CPU是资源共享(因为可以压缩)，只有在系统cpu繁忙时候才体现出来，比如1核心的CPU，两个容器，其中一个A容器设置1024，另一个B设置512，当cpu都需要使用cpu的时候，就按比例分2:1(a是b的两倍) (a使用66% b使用33%)#当512的权重空闲的时候，1024的容器可以吃掉所有CPU。#如果3核心CPU，三个容器，a设置2048，b设置512，c设置1024，当三个都繁忙的时候比例是(4:1:2) (a使用56%,b使用14%,c使用28%) docekr-stress-ng压缩1234567docker run --rm lorel/docker-stress-ng --helpdocker run --name stree1 -it --rm -m 256 lorel/docker-stressng --vm 2docker run --name stree2 -it --rm -cpus 2 lorel/docker-stress-ng --cpu 8docker run --name stree2 -it --rm --cpu-shares 1024 lorel/docker-stress-ng --cpu 8docker top stree1 查看stree1的进程运行情况docker stats 查看容器状态 小结 这些主要是针对CentOS7.4，对于其他平台或者版本可能实现方式略有不同。 如：在macOS下面对于 网络 和 卷 都有不同的地方。 网络在macOS中没有docker0桥，无法ping通容器，只能使用-P 或者-p映射端口的形式访问容器，或者通过host.docker.internal特殊DNS，解析为主机使用的内部IP地址。 卷的话如果要绑定User以外的目录，则需要修改权限让容器内部可以访问该目录，不然直接挂载会提示权限不足情况 暂时遇到这么多，感谢志哥让我遇到这么多坑。 主要是讲解一下Docker基础方面，后期的Dockerfile和Docker Registry在慢慢总结，如果本文有错误，还请大牛指出，谢谢:)]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
</search>
