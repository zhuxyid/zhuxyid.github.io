<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Systemd]]></title>
    <url>%2F2018%2F12%2F05%2FSystemd%2F</url>
    <content type="text"><![CDATA[SystemdSystemd是Linux系统中最新的初始化系统（init），如CentOS 7。它主要解决CentOS7之前的System V init的缺点，提高系统启动速度，Systemd的概念来自于MacOS上的Launchd System V介绍 Linux系统类似Windows一样可以自启动和禁止一些服务程序，在Syst V init的管理体系中，这些服务脚本程序存放在/etc/init.d文件下，在/etc存放rc0~rc6等目录指向init.d下的相应目录，这些目录下的文件即为不同运行级别需要启动或者禁止的服务。 System V有7个级别：runlevel0~runlevel7 级别 说明 0 关机状态，默认系统启动级别不能设置0，否则不能正常启动 1 单用户，无网络，用于系统维护，类似windows下的安全模式 2 多用户 3 完整多用户模式。 4 自定义，通常保留不用 5 图形模式，如果系统有安装GUI软件，XWindows会进入图形模式 6 重启系统，默认系统启动级别也不能设置6，否则不能正常启动 标准运行级别是3和5，可在/etc/inittab 下的id:{$levelnum}:initdefault:修改启动级别，如修改为3级别id:3:initdefault，下次启动后生效，Linux系统init进程会根据inittab配置文件确定当前运行级别并执行相应级别rc3 的服务脚本程序。 rc3目录下存放两种文件，一种S开头：表示启动服务，一种K开头：表示禁止服务，字母后面的数字表示启动顺序，按小到大执行 System V基本工具System V主要用chkconfig,service,命令管理服务，在使用命令前需要将相应服务脚本放在/etc/init.d目录下。 123456789101112131415161718192021222324#chekconfig格式chkconfig --add | --del | --list | --level &lt;levelnum&gt; &lt;servicename&gt; &lt;on|off|reset&gt; | &lt;servicename&gt;#实例:chkconfig --add httpd #添加httpd服务chkconfig --list #查看所有服务的启动级别chkconfig --del httpd #删除httpd服务chkconfig --level 35 httpd on #将httpd服务运行在3,5级别模式下，下次开机后生效#service格式service &lt;servicename&gt; start|stop|restart#实例service httpd startservice httpd stopservice httpd restart#如果需要修改启动优先级可以使用如下方法ln -s /etc/init.d/httpd /etc/rc.d/rc3.d/S60httpd #将httpd服务在init3级别下的开机启动优先级为60，值越大启动顺序越低#在ubuntu下可使用update-rc.d命令update-rc.d -f httpd removeupdate-rc.d httpd start 2 3 5 . stop 60 0 1 6 .#在235级别启动，优先级016级别关闭，优先级60，值越大启动顺序越低 Systemd介绍Systemd是Linux最新的初始化系统。取代了之前Unix时代一直使用的init系统，兼容Syst V init 和 LSB init script，而且在进程启动过程中更有效的引导加载服务。 在Systemd管理体系中，老的运行级别(runlevel)的概念被新的 运行目标(target) 所取代。 target命名类似multi-user.target这种形式。 old new runlevel3 multi-user.target runlevel5 graphical.target 在新版的CentOS上默认target是通过软连接形式实现 ln -s /lib/systemd/system/runlevel3.target /etc/systemd/system/default.target 在/lib/systemd/system/下面定义的runlevelX文件目的主要是为了兼容以前运行levelrunX的管理方式，实际是被链接到了multi-user.target Systemd特点 兼容SysVinit和LSB init scripts 更快的启动速度，以并发启动的原理 尽可能启动更少进程 尽可能将更多进程并行启动 提供按需启动能力 采用Linux的CGroup特性跟踪和管理进程的生命周期 启动挂载点自动挂载管理 实现事务性依赖关系管理 能够对系统进行快照和恢复 日志服务 能够向后支持SysV的服务脚本 特点说明： 按需提供能力 当Sysinit系统初始化的时候，它会将所有可能用到的后台服务进程全部启动运行，并且系统必须等待所有服务都启动就绪后才可以运行用户登录。 这种方式的缺陷启动时间过长，系统资源浪费。如果某些服务可能很长一段时间内或者运行期间没有被使用过的服务，如CPUS，如果花费在启动这些服务上的时间完全没有必要，对系统资源也是一种浪费。 Systemd可以按需启动，在某个服务被真正请求的时候才启动它，当服务结束时，systemd可以关闭它，在下次需要的时候在启动它 采用Linux的CGroup特性跟踪和管理进程的生命周期 init系统的一个重要职责就是负责跟踪和管理服务进程生命周期，它不仅可以启动一个服务，也必须也能停止一个服务，看上去没特别的，但是在真正用到代码实现的时候，获取就会发现停止服务比一开始想的要困难。 服务进程一般都会作为daemon在后台运行，为此服务程序有时会派生fork两次。在UpStart中，需要在配置文件中正确配置expect,这样Upstart通过对fork系统调用进行计数，从而获得真正的daemon PID 如果Upstart找错了，则会出现误杀死情况 还有特殊的情况，比如一个CGI程序会派生两次，从而脱离了和apache的父子关系，当apache进程被停止后，该CGI程序还继续运行，而我们希望服务停止后，所有由它所启动的相关进程也会被停止。为了处理这类问题，UpStart通过strace来跟踪fork和exit等系统调用，但是这种方式简单粗暴，且扩展性弱。Systemd则利用Linux内核CGroup特性来完成跟踪任务，当服务停止后，查询CGroup，Systemd可以确保找到所有相关的进程，从而干净停止服务。 CGroup提供能类似文件系统的接口，使用方便，主要实现系统资源配额管理。当创建子进程时，子进程会继承父进程的CGroup，因此无论服务如何启动新的子进程，所有这些相关的进程都会属于同一个CGroup。Systemd只需要简单的遍历指定的CGroup，即可正取找到所有相关进程，将它逐步停止 启动挂载点自动挂载管理 传统Linux系统中，用户可以用/etc/fstab文件来维护固定文件系统挂载点，这些挂载点在系统启动的过程中被自动挂载，一旦启动过程结束，这些挂载点会确保存在。挂载点是对系统运行至关重要的文件系统，如home目录。和SysVinit一样，Systemd管理这些挂载点，以便在系统启动时自动挂载它们，有时候用户还需要动态挂载，比如打算访问DVD内容时，才临时执行挂载一遍访问其内容，而不访问光盘时候，该挂载点被卸载umount以便节约资源，SysVinit依赖autofs服务来实现这种功能，Systemd内建自动挂载服务，无需额外安装autofs服务，可以直接用systemd提供的自动挂载管理能力来实现autofs功能。另外Systemd也兼容/etc/fstab文件，可以继续使用该文件管理挂载点 实现事务性依赖关系管理 系统启动过程是由很多独立组件共同组成，这些组件存在依赖关系，如果挂载一个NFS文件系统必须依赖网络才能正常工作，System虽然能够最大限度的并发执行很多依赖关系的工作，但是类似挂载NFS和启动网络这两个工作还是存在先后关系，无法并发执行，对于这些任务，Systemd维护一个’事物一致性‘’的概念，保证所有相关服务都可以正常启动而不会出现互相依赖，以至于死锁情况 能够对系统进程快照和恢复 Systemd支持按需启动，因此系统的运行状态是动态变化的，无法确定和准确知道系统当前运行了哪些服务，System快照提供了一种将当前系统运行状态保存并恢复的能力。 如系统当前正运行服务APP1和APP2，可以使用Systemd命令对当前系统运行状况创建快照，然后将APP1停止，或者做其他任意对系统的改变（如启动新的程序APP3），在改变后运行Systemd的快照恢复命令，即可立即将系统恢复到创建快照时候的状态，即只有APP1和APP2运行。常见场景：比如服务器出现一些异常，为了调试用户当前状态保存快照，然后可以任意操作，比如停止服务等，当调试完成后，恢复操作即可。（注意：改功能并不完善，使用时需要慎重） 日志服务 简单性：代码少，依赖少，开销最小 零维护：日志是排错和监控系统的核心功能，因此它自己不能再产生问题，比如自动管理磁盘空间，避免由于日志不断产生的磁盘空间耗尽 移植性：日志文件在所有类型的Linux系统可用 性能：添加 和 游览日志 非常快 最小资源占用：日志数据文件小 统一化：各种不同日志存储应该统一，将所有可记录事件保存在同一个数据存储中，所以日志内容的全局上下文都会被保存并且可供日后查看，如一条固件记录后通常会跟随一条内核记录，最终还有一条用户态记录。重要的是当保存到硬盘上时这三种关系不会丢失。早期Syslog会将不同信息保存到不同文件中，分析时候很难确定哪些条目是相关的 扩展性：日志使用范围广，嵌入式或者超级计算群集都可以满足 安全性：日志文件可以验证 Systemd基本概念Systemd单元概念系统初始化需要做很多事情。需要启动后台服务，如sshd服务，需要做配置工作，比如挂载文件系统，这个过程中每一步都被systemd抽象成一个配置单元，即unit，可以认为一个服务就是一个配置单元；一个挂载点是一个配置单元，一个交换分区配置是一个配置单元。systemd将配置单元归纳为以下不同的类型。 配置单元常见类型 类型 扩展名 说明 service unit .service 定义系统类服务 target unit .target 实现模拟“运行级别” device unit .device 定义实现内核识别设备 mount unit .mount 定义文件系统挂载点，利用logind服务，为用户会话进程分配CGroup资源 socket unit .socket 定义表示进程间通信的socket文件 snapshot unit .snapshot 管理系统快照 swap unit .swap 表示swap设备 automount unit .automount 文件系统自动挂载设备 path unit .path 定义文件系统中 timer unit .timer 定时器配置单元，用来定义触发用户定义的操作，取代了atd，crond等传统定时服务 Target和运行级别对应关系 Sys V init Systemd target 说明 0 poweroff.target 关机 1，s，single rescue.target 单用户 2，4 multi-user.target 用户定义，默认等同于3 3 multi-user.target 多用户，非图形化 5 graphical.target 多用户，图形模式 6 reboot.target 重启 emergency emergency.target 紧急shell Systemd并发启动原理 解决socket依赖 绝大多数的服务依赖是套接字依赖。比如服务 A 通过一个套接字端口 S1 提供自己的服务，其他的服务如果需要服务 A，则需要连接 S1。因此如果服务 A 尚未启动，S1 就不存在，其他的服务就会得到启动错误。所以传统地，人们需要先启动服务 A，等待它进入就绪状态，再启动其他需要它的服务。Systemd 认为，只要我们预先把 S1 建立好，那么其他所有的服务就可以同时启动而无需等待服务 A 来创建 S1 了。如果服务 A 尚未启动，那么其他进程向 S1 发送的服务请求实际上会被 Linux 操作系统缓存，其他进程会在这个请求的地方等待。一旦服务 A 启动就绪，就可以立即处理缓存的请求，一切都开始正常运行。 那么服务如何使用由 init 进程创建的套接字呢？Linux 操作系统有一个特性，当进程调用 fork 或者 exec 创建子进程之后，所有在父进程中被打开的文件句柄 (file descriptor) 都被子进程所继承。套接字也是一种文件句柄，进程 A 可以创建一个套接字，此后当进程 A 调用 exec 启动一个新的子进程时，只要确保该套接字的 close_on_exec 标志位被清空，那么新的子进程就可以继承这个套接字。子进程看到的套接字和父进程创建的套接字是同一个系统套接字，就仿佛这个套接字是子进程自己创建的一样，没有任何区别。 这个特性以前被一个叫做 inetd 的系统服务所利用。Inetd 进程会负责监控一些常用套接字端口，比如 Telnet，当该端口有连接请求时，inetd 才启动 telnetd 进程，并把有连接的套接字传递给新的 telnetd 进程进行处理。这样，当系统没有 telnet 客户端连接时，就不需要启动 telnetd 进程。Inetd 可以代理很多的网络服务，这样就可以节约很多的系统负载和内存资源，只有当有真正的连接请求时才启动相应服务，并把套接字传递给相应的服务进程。 和 inetd 类似，systemd 是所有其他进程的父进程，它可以先建立所有需要的套接字，然后在调用 exec 的时候将该套接字传递给新的服务进程，而新进程直接使用该套接字进行服务即可。 ###### 解决D-bus依赖 D-Bus 是 desktop-bus 的简称，是一个低延迟、低开销、高可用性的进程间通信机制。它越来越多地用于应用程序之间通信，也用于应用程序和操作系统内核之间的通信。很多现代的服务进程都使用D-Bus 取代套接字作为进程间通信机制，对外提供服务。比如简化 Linux 网络配置的 NetworkManager 服务就使用 D-Bus 和其他的应用程序或者服务进行交互：邮件客户端软件 evolution 可以通过 D-Bus 从 NetworkManager 服务获取网络状态的改变，以便做出相应的处理。 D-Bus 支持所谓”bus activation”功能。如果服务 A 需要使用服务 B 的 D-Bus 服务，而服务 B 并没有运行，则 D-Bus 可以在服务 A 请求服务 B 的 D-Bus 时自动启动服务 B。而服务 A 发出的请求会被 D-Bus 缓存，服务 A 会等待服务 B 启动就绪。利用这个特性，依赖 D-Bus 的服务就可以实现并行启动。 解决文件系统依赖 系统启动过程中，文件系统相关的活动是最耗时的，比如挂载文件系统，对文件系统进行磁盘检查（fsck），磁盘配额检查等都是非常耗时的操作。在等待这些工作完成的同时，系统处于空闲状态。那些想使用文件系统的服务似乎必须等待文件系统初始化完成才可以启动。但是 systemd 发现这种依赖也是可以避免的。 Systemd 参考了 autofs 的设计思路，使得依赖文件系统的服务和文件系统本身初始化两者可以并发工作。autofs 可以监测到某个文件系统挂载点真正被访问到的时候才触发挂载操作，这是通过内核 automounter 模块的支持而实现的。比如一个 open()系统调用作用在”/misc/cd/file1”的时候，/misc/cd 尚未执行挂载操作，此时 open()调用被挂起等待，Linux 内核通知 autofs，autofs 执行挂载。这时候，控制权返回给 open()系统调用，并正常打开文件。 Systemd 集成了 autofs 的实现，对于系统中的挂载点，比如/home，当系统启动的时候，systemd 为其创建一个临时的自动挂载点。在这个时刻/home 真正的挂载设备尚未启动好，真正的挂载操作还没有执行，文件系统检测也还没有完成。可是那些依赖该目录的进程已经可以并发启动，他们的 open()操作被内建在 systemd 中的 autofs 捕获，将该 open()调用挂起（可中断睡眠状态）。然后等待真正的挂载操作完成，文件系统检测也完成后，systemd 将该自动挂载点替换为真正的挂载点，并让 open()调用返回。由此，实现了那些依赖于文件系统的服务和文件系统本身同时并发启动。 当然对于”/“根目录的依赖实际上一定还是要串行执行，因为 systemd 自己也存放在/之下，必须等待系统根目录挂载检查好。 不过对于类似/home 等挂载点，这种并发可以提高系统的启动速度，尤其是当/home 是远程的 NFS 节点，或者是加密盘等，需要耗费较长的时间才可以准备就绪的情况下，因为并发启动，这段时间内，系统并不是完全无事可做，而是可以利用这段空余时间做更多的启动进程的事情，总的来说就缩短了系统启动时间 服务的循环依赖 Systemd 能保证事务完整性。Systemd 的事务概念和数据库中的有所不同，主要是为了保证多个依赖的配置单元之间没有环形引用，存在循环依赖，那么 systemd 将无法启动任意一个服务。此时 systemd 将会尝试解决这个问题，因为配置单元之间的依赖关系有两种：required 是强依赖；want 则是弱依赖，systemd 将去掉 wants 关键字指定的依赖看看是否能打破循环。如果无法修复，systemd 会报错。Systemd 能够自动检测和修复这类配置错误，极大地减轻了管理员的排错负担 基于path激活机制 判断一个文件在不在， 如果在可以立即激活一个进程或服务 System V init 和 Systemd命令对比 Sys V init Systemd 作用 service NAME start systemtl start NAME.service 启动 service NAME stop systemctl stop NAME.service 停止 service NAME restart systemctl restart NAME.service 重启 service NAME status systemtl status NAME.service 查看状态 service NAME condrestart systemctl condrestart NAME.service 条件重启 service NAME reload systemctl reload NAME.service 重载 不支持 systemctl is-active NAME.service 查看服务当前激活状态 chkconfig –list systemctl list-units -t service 查看所有已激活服务 不支持 systemctl list-units -t service -a 查看所有服务(包括未激活) chkconfig NAME on systemctl enable NAME.service 设置开机启动 chkconfig NAME off systemctl disable NAME.service 禁止开机启动 chkconfig –list NAME systemctl is-enabled NAME.service 查看服务是否开机启动 不支持 systemctl mask NAME.service 禁止服务设置开机启动 不支持 systemctl unmask NAME.service 取消禁止服务设置开机启动 不支持 systemctl list-dependencies NAME.service 查看服务依赖关系 修改/etc/inittab文件 systemctl set-default NAME.target 修改默认运行级别 init RUNLEVEL systemctl isolate NAME.target 切换系统运行级别 runlevel，who -r systemctl get-default 查看运行级别 Systemd 电源管理 命令 操作 systemctl reboot 重启 systemctl poweroff 关机 systemctl suspend 挂起 systemctl hibernate 休眠 systemctl hybrid 混合休眠模块（快照并挂起） Service unit file配置说明Systemd的相关配置文件路径 /etc/lib/systemd/system /run/systemd/system /etc/systemd/system 文件通常由三个部分组成 [Unit]： 定义与unit类型无关的通用选项，用于提供当前unit描述信息，unit行为以及依赖关系等 [Service]：定义与此处类型相关的专用选项，此类为service类型 [Install]：定义由systemctl enable或者systemtl disable命令在实现服务启动或禁止用到的选项 Unit 常用选项Description： 描述信。 After： 定义unit的启动次数，表示当前unit应该晚于哪些unit启动，功能和before相反 Requies： 依赖到其他units，强依赖，被依赖的units无法激活时，当前unit即无法激活 Wants： 指明依赖到其他的units，弱依赖，依赖的units无法激活时，当前unit无影响 Conflicts： 定义units见的冲突关系 #####Service 常用选项 Type： 用于定义影execstart及相关参数的功能的unit进程启动 Simple： 由execstart启动的命令为主进程 Forking： 由execstart启动的命令，其中一个子进程会成为主进程，父进程会退出 onehot： 功能类似simple dubs notify： 类似于simple idle environmentfile： 启动时环境配置文件，为execstart提供变量 execstart： 指明启动unit要运行的命令或脚本，execstartpre，execstartpost execreload： 指明重载unit要运行的命令或脚本 execstop： 指明要停止units要运行的命令或脚本 restart： 指明要重启units要运行命令或脚本 Install 常用选项alias： requireby： 被那些units所依赖，强依赖 wantsby： 被那些units所依赖，弱依赖 注意：当对新创建的unit文件或修改了unit文件，都需要重载配置文件 systemctl daemon-reload]]></content>
      <categories>
        <category>Linux Base</category>
      </categories>
      <tags>
        <tag>Systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB]]></title>
    <url>%2F2018%2F12%2F03%2FMongoDB%2F</url>
    <content type="text"><![CDATA[MongoDB介绍官方站点 MongoDB：适用海量存储，基于文档数据库，C++编写，开源产品，遵循GNU AGPL，支持OSX，Linux，Windows，Solaris。 MongoDB：适用于web站点，cacheing，高大数据量，高扩展场景，事物要求性不高的场景。 MongoDB面向集合的数据库 ： 数据库：但数据库无须创建 集合：无须事先定义，一个文档相当于mysql中的一行，集合相当于多个文档组成的，mongodb中集合是基本的操作单位 特点: 文档存储：利用json组织数据 性能好：c++，多索引支持，不支持事物（支持原子事务），基于内存（延迟写） 支持复制：类似mysql主从复制replication(废弃) 副本集复制auto-sharding 自动分片机制 支持map/reduce.可以实现并行查询处理 分布式文件系统 支持基于位置索引(空间) 商业支持，很多公司使用mongodb MongoDB可以文档嵌套,KEY/VALUE存储，存储格式JSON，实例 12345678910&#123; Name:tomcat Age:18 Gender:male Books:&#123; first:linux second:python &#125; Birthday:1990&#125; Mongodb架构1234C/S架构：mongod server端 mongo client端 mongo&gt;use tested 创建testdb数据库 MongoDB安装配置yum源码123456vi /etc/yum.repos.d/mongodb.repo [mongodb] name=MongoDB Repository baseurl=http://downloads-distro.[mongodb.org/repo/redhat/os/x86_64/](http://mongodb.org/repo/redhat/os/x86_64/) gpgcheck=0 enabled=1 查询MongoDB软件包12345yum search mongod* mongodb-org-mongos mongodb shareding mongodb-org-server mongodb服务端 mongodb-org-shell mongod客户端 mongodb-org-tools mongodb工具 安装mongodb1yum install mongodb 添加权限12useradd mongodchown -R mongod.mongod /data/mongo 启动mongodb1234server mongod start 或者:mongod -config /etc/mongod.conf 如果想访问mongod监控端口需要启动端口27017，28017(需要开启httpinterface)访问 http://192.168.2.21:27017 监控端口，显示mongodb信息 Mongod客户端mongo [option][db address] [file name] mongo 默认连接127.0.0.1:27017 默认没有用户密码认证 例子： 123456789mongo 192.168.2.21 MongoDB shell version: 2.6.12 connecting to: 192.168.2.21/test Welcome to the MongoDB shell. For interactive help, type "help". For more comprehensive documentation, see &lt;http://docs.mongodb.org/&gt;Questions? Try the support group &lt;http://groups.google.com/group/mongodb-user&gt; MongoDB常用命令12345mongodb常用的命令mongodump mongodb备份mongorestore mongodb恢复mongoexport mongodb导出mongoimport mongodb导入 MongoDB配置文件mongodb配置文件在/etc/mongod.conf下 123456789101112131415161718192021222324252627282930313233343536373839more /etc/mongod.conflogpath=/var/log/mongodb/mongod.log #mongodb日志路径 logappend=true #是否以追加方式存储日志 fork=trueport=27017 #默认端口2701 dbpath=/data/mongo #mongodb数据存储目录 pidfilepath=/var/run/mongodb/mongod.pid #mongodb pid文件 bind_ip=127.0.0.1 #绑定地址 # Disables write-ahead journaling # nojournal=true # Enables periodic logging of CPU utilization and I/O wait # cpu=true # Turn on/off security. Off is currently the default # noauth=true # auth=true # Verbose logging output. # verbose=true # Inspect all client data for validity on receipt (useful for # developing drivers) # objcheck=true # Enable db quota management # quota=true # Set oplogging level where n is # 0=off (default) # 1=W # 2=R # 3=both # 7=W+some reads # diaglog=0 # Ignore query hints # nohints=true httpinterface=true #是否启用http监控接口，端口是28017 # noscripting=true # notablescan=true # noprealloc=true # nssize=&lt;size&gt; # replSet=setname #mongod 副本集名称 # oplogSize=1024 #oplog大小 # keyFile=/path/to/keyfile MongoDB 使用MongoDB基本使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182mongo 192.168.2.21&gt;helpdb.help() db方法 帮助db.mycoll.help() 集合方法 帮助sh.help() sharding 帮助rs.help() 复制集 帮助help admin administrative helphelp connect connecting to a db helphelp keys key shortcutshelp misc misc things to knowhelp mr mapreduceshow dbs 查看数据库名show collections 查看集合名词show users show users in current databaseshow profile show most recent system.profile entries with time &gt;= 1msshow logs show the accessible logger namesshow log [name] prints out the last segment of log in memory, 'global' is defaultuse &lt;db_name&gt; 设置使用数据库db.foo.find() list objects in collection foodb.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1it result of the last line evaluated; use to further iterateDBQuery.shellBatchSize = x set default number of items to display on shell&gt;use study #无须创建，直接使用数据库&gt;db.studycoll.insert(&#123;name:"zhuxy"&#125;) #创建studycoll集合插入数据&gt;db.zhuxy.insert(&#123;name:"zhuyue"&#125;) #创建zhuxy集合插入数据&gt;show collections #查看collectionsstudycollzhuxysystem.indexes&gt;db.getCollectionNames() #以列表方式查看collection[ "studycoll", "system.indexes", "zhuxy" ]&gt;show dbsadmin (empty)local 0.078GBstudy 0.078GBtest (empty)&gt;db.studycoll.find() #在studycoll集合中查询数据&#123; "_id" : ObjectId("5981309eceaab5cdd6507bb9"), "name" : "zhuxy" &#125;#说明(id,对象id号(唯一的，如果添加逐步+1)&gt;db.studycoll.insert(&#123;name:"yukw',age:19,books:[211,'NJAU']&#125;) #studycoll集合插入数据WriteResult(&#123; "nInserted" : 1 &#125;)&gt;db.studycoll.find().count() #查找统计2&gt;db.studycoll.stats() #查看状态&#123; "ns" : "study.studycoll", "count" : 4, "size" : 192, "avgObjSize" : 48, "storageSize" : 8192, "numExtents" : 1, "nindexes" : 1, "lastExtentSize" : 8192, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 8176, "indexSizes" : &#123; "_id_" : 8176&#125;,"ok" : 1&gt;db.studycoll.drop() #删除studycoll集合true&gt;show collections #查看集合system.indexs&gt;show dbs #虽然删除studycoll集合，但是数据库study依然存在admin (empty)local 0.078GBstudy 0.078GBtest (empty) MySQL和MongoDB语法比较INSERT插入123mysql&gt;insert into studycoll(name, age,status) value (&apos;zhuxy&apos;,&apos;19&apos;,&apos;A&apos;)mongodb&gt;db.studycoll.insert(&#123;name:&apos;zhuxy&apos;,age:19,status:&apos;A&apos;&#125;) SORT排序1234mysql&gt;select * from studycoll where age &gt; 18mongodb&gt;db.studycoll.find(&#123;age:&#123;$gt:18&#125;&#125;).sort(&#123;age:1&#125;)#查询age大于18的数据，并排序(从小到大，如果-1从大到小),显示所有字段 SELECT查询1234mysql&gt;select name, gender from studycoll where age &gt; 18 limit 5mongodb&gt;db.studycoll.find(&#123;age:&#123;$gt:18&#125;&#125;,&#123;name:1,gender:1&#125;).limit(5)#显示name和gender并且年龄大约18 UPDATE更新1234mysql&gt;update studycoll set status=&apos;A&apos; WHERE age &gt; 18 mongodb&gt;db.studycoll.update(&#123;age:&#123;$gt:18&#125;&#125;,&#123;$set:&#123;gender:&apos;body&apos;&#125;&#125;,&#123;multi:true&#125;)#如果multi不实true，只修改第一个符合条件的 DELETE删除123mysql&gt;delete from studycoll where status=&apos;D&apos; mongodb&gt;db.studycoll.remove(&#123;status:&apos;D&apos;&#125;) AND方法12345mysql&gt;select * from studycoll age &gt; 70 and age &lt; 75 mysql&gt;select name,gender from studycoll age &gt; 70 and age &lt; 75mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:70&#125;&#125;,&#123;age:&#123;$lt:75&#125;&#125;]&#125;) mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:79&#125;&#125;,&#123;age:&#123;$lt:75&#125;]&#125;,&#123;name:1,gender:1&#125;) 关系型数据库和MongoD RDBMS Mongo table.view collection row Json Document index index join embedded partition shard partition key(分区键) shard key(分片键) MongoDB高级操作批量插入123mongodb&gt;for(i=1;i&lt;=100;i++) db.studycoll.insert(&#123;name:&quot;User&quot;+i,age:i,gender:&quot;M&quot;,books:[&apos;linux&apos;,&apos;python&apos;]&#125;) mongodb&gt;db.studycoll.find()#只能显示20，如果像继续显示输入it find mongodb查询操作支持挑选机制，comparison，logical，element，javascript等几类 comparison比较运算符1234567$gt 大于&#123;filed:&#123;$gt:value&#125;&#125; $gte 大于等于 $in 挑选指定字段位于指定数组&#123;filed:&#123;&lt;value1&gt;,&lt;values2&gt;&#125;&#125; $lt 小于 $lte 小于等于 $ne 不等于 $nin 挑选指定字段的值不位于指定数组 logical逻辑运算符1234$or 或&#123;$or:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; $and 与&#123;$and:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; $not 非&#123;filed:&#123;$not:&#123;&lt;operator&gt;&#125;&#125;&#125; $nor 反&#123;$nor:[&#123;&lt;expression1&gt;&#125;,&#123;&lt;expression2&gt;&#125;]&#125; element元素查询12345$exists #根据指定字段存在性挑选文档，语法格式&#123;filed:&#123;$exists:&lt;boolean&gt;&#125;&#125;,指定&lt;boolean&gt;的值为true，则返回存在指定字段的文档，false则返回不存在指定字段的文档 $mod #将指定字段的值进行取模运算，并返回其余数为指定值的文档,语法&#123;filed:&#123;$mod:[divisor,remainder]&#125;&#125; $type #返回指定字段的值类型为指定类型的文档，语法&#123;filed:&#123;$type:&lt;BSON tye&gt;&#125;&#125; int,str... exists用法查询有address字段的文档 1234567mongodb&gt;db.studycoll.find(&#123;address:&#123;$exists:true&#125;&#125;) mongodb&gt;db.studycoll.find(&#123;$and:[&#123;age:&#123;$gt:80&#125;&#125;,&#123;address:&#123;$exists:false&#125;&#125;]&#125;) #查询age大于80，并且没有address字段mongodb&gt;db.studycoll.update(&#123;age:&#123;$gt:70&#125;&#125;,&#123;$set:&#123;gender:&apos;F&apos;&#125;&#125;,&#123;multi:true&#125;)#将age大于70，性别改成F updateupdate参数使用格式独特，其仅能包含使用update专有操作符来构建表示式，其中大致包含‘filed’,’array’,’bitwise’ filed类常用操作 1234567$inc #增大指定字段,格式&#123;field:value&#125;,&#123;$inc:&#123;field1:amount&#125;&#125;,其中&#123;field"value&#125;用于指定挑选标准，&#123;$inc:&#123;filed:amunt&#125;&#125;指定要提升其字段及提升大小amount $rename #更改字段名,格式&#123;$rename:&#123;&lt;old name1&gt;:&lt;new name1&gt;,&lt;old name2&gt;:&lt;new name2&gt;&#125;&#125; $set #修改字段值为新指定值,格式&#123;field:value1&#125;,&#123;$set:&#123;filed1:value1&#125;&#125; $unset #删除指定字段,格式&#123;filed:value&#125;,&#123;$unset:&#123;filed1:""&#125;&#125; 总结1234567891011121314151617181920212223242526272829301，mongodb常用方法CRUD db.COLL_NAME.METHOD C:insert() R:find() U:update() D:remove() 2，用JSON格式文档:&#123;key:value,key:value&#125; insert(&#123;&#125;) find(&#123;&#125;,&#123;&#125;). limit() sort() count() skip() update(&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;multi:true&#125;) remove(&#123;&#125;) 3,删除collection db.collName.drop 4,删除database use databasename db.dropDatabase() mysql database--&gt;table--&gt;row mongodb database--&gt;collection--&gt;document 索引假设从一百万条数据，在关系型数据库中，找到一个数值改怎么办？难道全表扫描？ 推荐读:“关系型数据库索引设计与优化” 这本书介绍如何设计索引：(索引也会带来坏处)，数据库使用索引，保存的索引文件占用资源，如果数据被修改，索引也应该需要修改，降低写入性能，有利必有弊。 需要根据现有的环境来确定是否使用索引： 如果数据量小，无需索引，如果创建索引反而变慢 如果数据量多，需要根据查询的条件来决定是否创建 简单索引 或者 组合索引 如果数据量海量，创建索引没有意义 索引是什么 在关系型数据库中，索引是一种单独的，物理的对数据库表中一列或多列的值进行排序的一种存储结构，是某个表中一列或者若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单 作用相当于图书目录，可根据目录中的页码快速找到所需内容 索引优点 1，减少服务器需要扫描的数据量 2，索引可以帮助服务器避免排序或者使用临时表 3，可以将随机i/o转化成顺序i/o 索引级别 1星：索引如果能将相关的记录放置在一起，降低I/O，入门级别 2星：索引中数据的存储顺序与查找标准中顺序一致。 3星：如果索引中保护查询中所需要的全部数据，(覆盖索引)。 索引类别： 顺序索引 散列索引:将索引映射至散列桶上，映射是通过散列函数进行的 评估索引标准： 访问类型：范围查找用顺序索引，等值查找用散列 访问时长 插入时长 删除时长 空间开销 顺序索引 聚集索引。如果某记录文件中的记录顺序是按照对应的搜索码指定的顺序排序，聚集索引也叫主索引。不需要二次i/o，找到键就找到行了。 非聚集索引。搜索码中的指定次序与记录文件中的记录次序不一致，叫非聚集索引，需要找到键，在寻找指针指定的行。 有聚集索引的数据文件，也叫做索引的顺序文件。 根据索引中是否为每个记录相应的创建索引项：稠密索引 和 稀疏索引 多级索引: 一级索引指向二级索引，二级索引指向行 辅助索引必须是稠密索引 B+树索引: Balance Tree:平衡树索引 MYISAM是非聚集索引 InnoDB是聚集索引(数据文件和索引文件在一个文件中) 顺序索引的特性：全值匹配：Name=”user12” 匹配最左前缀：Name like “User1%”, 无效：Name LIKE “%User1%” 匹配列前缀：Name like “User1%”, 无效：Name LIKE “%User1%” 匹配范围值： 精确匹配某一列并范围匹配另一列 只访问索引的查询：覆盖查询 组合索引特性： 如果索引是这样的(Name,Age), 那么Age &gt; 80无效，最左查找的; 如果Age&gt;80 and Name = “user12”有效 散列索引：不适合范围查询，适合精确值查询 散列函数 分布要随机 分布要均匀 适用场景： ​ 精确匹配： =,IN(),&lt;=&gt; MySQL索引只有MyISAM存储引擎支持，可以借助sphinx,lucense实现 空间索引，必须使用空间索引函数获取相应的查询结果，MyISAM支持 主键（值不能相同，也不能为空） 唯一键（值不能相同，可以为空） mysql创建索引12345创建索引：CREATE INDEX index_name ON table (col1,...)添加索引：ALTER TABLE ADD INDEX 删除索引：ALTER TABLE DROP INDEX DROP INDEX index_name FROM TABLE查看索引：SHOW INDEXS FROM TABLE MongoDB支持的索引 简单索引 组合索引 多键索引 空间索引 全文索引 哈希索引 MongoDB索引操作1234567891011121314151617181920212223242526272829db.studycoll.find(&#123;name:&quot;User49&quot;&#125;).explain()#explain()语法说明,如果没创建索引会全表扫描db.studycoll.ensureIndex(&#123;name:1&#125;)#创建name索引db.studycoll.find(&#123;name:&apos;User49&apos;&#125;).explain()#再次查看不会全表扫描了db.studycoll.find(&#123;name:&apos;user49&apos;&#125;).hint(&#123;name:1&#125;).explain()#指定什么索引查询db.studycoll.ensureIndex(&#123;name:1,age:1&#125;,&#123;unique:true&#125;)#创建组合索引name和age. 1表示升序排序，-1表示降序排序db.studycoll.ensureIndex(&#123;name:1&#125;,&#123;background:true&#125;)#background:true表示后台执行索引(如果数据量大的情况下使用该选项)db.studycoll.getIndexes()&#123;&quot;v&quot; : 1,&quot;unique&quot; : true,&quot;key&quot; : &#123; &quot;name&quot; : 1, &quot;age&quot; : 1&#125;, &quot;name&quot; : &quot;name_1_age_1&quot;, &quot;ns&quot; : &quot;study.studycoll&quot;&#125; MongoDB复制mongodb复制架构 早期mongodb使用类似mysql复制功能，但是发现主不能故障转移 Replica Set复制集(副本集)，类似mysql复制功能，可实现故障转移功能 mongodb官方不建议使用主从方式 Replication Options 副本集相关选项： replSet #指定副本集名称 oplogsize #操作日志大小，在64位系统下，默认是可用磁盘空间的5%，如果mongodb初始化后，后期修改oplog是不生效的 fastsync #快速同步，类似后台复制 replIndexPrefetch #mongodb2.2才能实现，指定副本集的索引预取，可以让复制过程更为高效 ​ replIndexPrefetch {none | _id_only | all} non 不预取任何索引，_id_only预取id索引，all预取所有索引 副本集架构时间要同步，replset名称一致，确保mongodb能交互 部署配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687环境：192.168.2.10 主192.168.2.11 从192.168.2.12 从三台需要时间同步，需要安装mongod,配置文件需要添加#vi /etc/mongod.confbind_ip = 192.168.2.10 #监听端口，每个服务器绑定自己的ipreplSet = MyRs0 #三台保持一致,副本名称启动mongod群集，三台都需要启动192.168.2.10&gt;rs.help()&gt;rs.initiate() #初始化rs&#123;&quot;info2&quot; : &quot;no configuration explicitly specified -- making one&quot;,&quot;me&quot; : &quot;192.168.2.10:27017&quot;,&quot;info&quot; : &quot;Config now saved locally. Should come online in about a minute.&quot;,&quot;ok&quot; : 1&#125;MyRs0:PRIMARY&gt;rs.status() #查看rs状态MyRs0:PRIMARY&gt;rs.isMaster() #查看是否是主节点MyRs0:PRIMARY&gt;rs.add(&quot;192.168.2.11:27017&quot;) #添加2.11节点MyRs0:PRIMARY&gt;rs.add(&quot;192.168.2.12:27017&quot;) #添加2.12节点添加从节点后，开始插入数据，只有PRIMARY可以添加数据MyRs0:PRIMARY&gt;use studyMyRs0:PRIMARY&gt;for(i=1;i&lt;1000;i++) db.studycoll.insert(&#123;name:&apos;user&apos;+i,age:i,gender:&apos;F&apos;&#125;)192.168.2.11 注意从节点不可写MyRs0:SECONDARY&gt;rs.isMaster() #在从节点查看主从信息 &#123; &quot;setName&quot; : &quot;MyRs0&quot;, &quot;setVersion&quot; : 3, &quot;ismaster&quot; : false, #是否是主节点 &quot;secondary&quot; : true, #是否是从节点 &quot;hosts&quot; : [ &quot;192.168.2.10:27017&quot;, &quot;192.168.2.11:27017&quot;, &quot;192.168.2.12:27017&quot;], &quot;primary&quot; : &quot;192.168.2.10:27017&quot;, #主节点地址 &quot;me&quot; : &quot;192.168.2.11:27017&quot;, #从节点本身 &quot;maxBsonObjectSize&quot; : 16777216, &quot;maxMessageSizeBytes&quot; : 48000000, &quot;maxWriteBatchSize&quot; : 1000, &quot;localTime&quot; : ISODate(&quot;2017-08-04T06:26:25.430Z&quot;), &quot;maxWireVersion&quot; : 2, &quot;minWireVersion&quot; : 0, &quot;ok&quot; : 1&#125;MyRs0:SECONDARY&gt; rs.slaveOk() #如果从需要访问数据，需要输入rs.slaveOk()MyRs0:SECONDARY&gt; use studyMyRs0:SECONDARY&gt; db.studycoll.find().count()MyRs0:SECONDARY&gt; db.studycoll.insert(&#123;name:&quot;hello&quot;&#125;) #这里从不可以写WriteResult(&#123; &quot;writeError&quot; : &#123; &quot;code&quot; : undefined, &quot;errmsg&quot; : &quot;not master&quot; &#125; &#125;)注意：如果192.168.2.10下线，这里会自动选举PRIMARY,如果192.168.2.10上线，不会将其转变成PRIMARY, 上线后变成SECONDARY，需要rs.slaveOk()才可以读取数据如果需要将192.168.2.10下线后，再次上线自动提升PRIMARY需要修改优先级需要在PRIMARY修改配置文件MyRs0:PRIMARY&gt;mycnf = rs.conf() #rs.conf是配置主从的配置文件，mycnf是自定义配置文件 &#123; &quot;_id&quot; : &quot;testrs0&quot;, &quot;version&quot; : 3, &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;host&quot; : &quot;192.168.2.21:27017&quot; &#125;, &#123; &quot;_id&quot; : 1, &quot;host&quot; : &quot;192.168.2.23:27017&quot; &#125;, &#123; &quot;_id&quot; : 2, &quot;host&quot; : &quot;192.168.2.25:27017&quot; &#125; ] &#125;MyRs0:PRIMARY&gt;mycnf.members[0].priority=2 #members指定_id号码，priority是优先级MyRs0:PRIMARY&gt;rs.reconfig(mycnf) #重现加载自定义配置文件mycnfMyRs0:PRIMARY&gt;rs.conf() #查看配置文件 Mongod Shardingmongod副本集 不能降低I/O的请求，只是把数据复制一份到另外一台机器，考虑到后期高并发高吞吐量场景或者数据大于物理磁盘的时候，就需要使用sharding分片 shareding只是将大数据切割成小数据分散至其他机器上。降低i/o压力 Sharding目的： 数据系统巨大和高吞吐量高 高并发的查询会耗尽cpu的资源 sharding可以降低单台服务器的I/O压力 Sharding架构 router 跟config server通讯(router可以有一个，可以有多个) config server 存储元数据(分区键)，在生产环节中建议使用三个config server，一个单点故障，两个不方便选举 share 数据 注意事项： 做sharding对写操作最好做到分散,降低写压力, 对读操作最好不要做到分散,才能降低i/o压力 所以最好做到，写尽可能离散，读尽可能不离散。选择一个合理的分区键(通常使用组合键进行切割)。 环境部署12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667环境说明：router(mongos) 1个 192.168.2.10 config server 1个 192.168.2.11 shard 2个 192.168.2.12:27017 / 192.168.2.12:27018(需要注释httpinterface,因为这里只是用做测试) 1、配置config server192.168.2.11默认监听端口27019端口，可以使用如下命令启动mongod进程#mongod --configsvr --dbpath &lt;path&gt; --port &lt;port&gt;也可以编辑配置文件#vi /etc/mongod.confdbpath = /data/mongoconfigsvr = true启动mongod后使用的端口是27019#mongod -f /etc/mongod.conf2、配置mongos实例192.168.2.10mongos属于轻量级应用，完全可以与其他服务运行同一节点，启动时，需要为mongos实例指明各config服务器访问地址默认情况下，mongos监听27017端口，可以使用如下命令启动mongos实例#mongos --configdb &lt;config server hostnames((ip|hostname):port)&gt;也可以直接编辑配置文件#vi /etc/mongod.conf#dbpath = /data/mongo #需要注释该选项，这里只是用到mongosconfigdb = 192.168.2.11:27019启动mongos, 使用27017#mongos -f /etc/mongod.conf3、配置各副本集或独立的mongod实例配置192.168.2.12:27017 192.168.2.12:270184、向分区集群中添加各shard服务器或副本集192.168.2.11mongo -host 192.168.2.114.1、添加方式使用mongo命令连入mongos实例，命令如下#mongo --host &lt;hostname of machine running mongos&gt; --port &lt;port mongos listens on&gt;&gt;sh.addShard() #方法添加各shard至群集中如果添加shard是副本集，则需要使用&gt;sh.addShard("RS_NAME/RS_SERVER:PORT") &gt;sh.addShard("MyRS/192.168.2.10:27017")如果添加shard是独立的mongod实例，则需要使用&gt;sh.addShard("RS_SERVER:PORT") &gt;sh.addShard("192.168.2.12:27017") &gt;sh.addShard("192.168.2.12:27018")&gt;sh.status() #查看状态&gt;sh.enableSharding('database') #sharding那个数据库&gt;sh.sharedCollection('database.collection',&#123;filed:1,filed1:1&#125;) #sharding那个集合,集合的索引是那个字段&gt;sh.status()&gt;for(i=1;i&lt;=100000;i++) db.collection.insert #批量插入数据(&#123;name:'user'+i,age:(i%150),address:i+"#"+"nanjing",book:['linux','python']&#125;)&gt;sh.help() #查看shared的帮助命令&gt;sh.setBalancerState() #设置均衡&gt;h.getBalancerState() #查看是否是均衡状态 总结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364重复索引： 避免重复索引选择合适的索引，比如一个表有"name,age,gender,address"，那么通常查询name和age，则可以使用组合索引name和age，不要只创建name索引在创建一个age索引覆盖索引: name,age 能在索引中直接查到数据的叫覆盖索引。查看有没有用索引mongod&gt;db.mycoll.find().hint().explain() #hint()指明什么索引，explain()分析查找 mysql&gt;explain select * from tables;通常mongod所需要做的工作#复制集群 master/slave replica /set arbiter:仅参与选举，不持有数据， 0优先级节点：持有数据，参与选举，单不能成为主节点， Replica/set群集需要注意 配置文件replSet=RsName 初始化，添加节点。 #sharding分片 目的:单个节点数据集太大 如果单个节点读写请求，并发请求量较大 读，写 读，不离散 写，离散mongodb，collection级别sharding key；colletion索引选择sharding key需要考虑的标准 应该在哪存数据？ 应该在哪得到希望的数据？ 基本法则 sharding key应该是主键 sharding key应该能尽量保证跨分片查询 chunk：64m 越小越容易迁移rebalance：重新均衡sharding:新增shard，移除shardmongodb常用的命令mongodump mongodb备份mongorestore mongodb恢复mongoexport mongodb导出mongoimport mongodb导入mongodb的监控信息mongostat\mongotopinsert query update delete getmore command vsize res faults netIn netOut conn repl timevsize虚拟内存res实际内存集 mongooplog mongodb的日志mongoperf性能评估mongofiles修改GridFS文件系统]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL简单介绍]]></title>
    <url>%2F2018%2F12%2F03%2FNoSQL%2F</url>
    <content type="text"><![CDATA[NoSQLNoSQL解决大数据处理问题： 并行数据库：水平切分，分区查询 NoSQL数据库管理系统：非关系型模型，分布式，不支持ACID数据库设计范式 关系型数据库中的ACID： Atomicity原子性，一个事物中所有操作都必须全部完成，要么全部不完成 Consistency一致性，事物在开始或结束时，数据库应该在一致状态 Isolation隔离性，事物将设定只有它自己操作数据库，彼此不知晓 Durability持久性：一旦事物完成，就不能返回 大数据分析处理： MapReduce:映射成键值，分析在集合处理 CAP:任何分布式系统只能满足两种 Consistency：一致性 Availability：可用性 Partition tolerance：分区容错性 BASE：不同ACID模型，牺牲数据一致性，获得可用性或可靠性 Basically Available：基本可用性 Soft state：软状态 状态可以有一段时间不同步，异步 Eventually consistent：最终一致性，最终一致，不是实时一致 因果一致性 会话一致性 读 自己写一致性 单调读一致性 时间轴一致性 ACID对比BASE ACID：强制一致性隔离性，采用悲观保守方法，难以变化 BASE：弱一致性，可用性优先，采用乐观的方法，适应变化，更简单，更快 数据一致性的实现技术： NRW，2PC，Paxos，Vector Clock NoSQL特点 简单数据模型（KEY，VALUE）结构 元数据和数据分离 弱一致性 高吞吐量 较高水平扩展能力 低端硬件群集 NoSQL缺点 功能太单一，没有统一查询模型 不支持ACID设计范式（对事物要求高的不要使用） NewSQL继承关系型数据库，NoSQL 比如：Clustrix，GenieDB，ScaleBase，NimbusDB，Drizzle 适用云环境都归类到NewSQL 元数据管理系统：DBaas 数据存储模型：详键：http://www.nosql-database.org 列式存储模型:hadoop/Hbase,Hypertable 文档存储模型:mongoDB ElasticSearch 键值存储模型:redis,Berkeyley DB 图形数据模型:Noe4j,Sparksee 多维数据模型:ArangoDB,OrientDB 对象数据库:Versant,db4o 网格/云数据解决方法:GridGain 列式存储模型： 应用场景：在分布式文件系统之上支持随机读写分布式数据存储 典型产品：Hbase ,Hypertable,Cassandra 数据模型：以列为中心进行存储，将同一列数据存储在一起 优点：快速查询，高可扩展性强，易于实现分布式扩展 文档存储模型： 应用场景：非强事务需求的web应用 典型产品：mongoDB,ElasticSearch(通常存储日志)，CouchDB,CounchDB Server 数据模型：键值模型，存储为文档 优点：数据模型无须实现定义 键值存储模型: 应用场景：用于内容缓冲，用于大量并行数据访问的高负载场景 典型产品：Redis，dynamoDB,Riakn,Memcachedb(不是memcached) 数据模型：基于哈希表实现的key-value模型 优点：查询/写入迅速，数据没有结构 图式存储模型： 应用场景：社交网络，推荐系统，管系统等，如位置定位 典型产品：Neo4j,infinite graph 数据模型：图式结构 优点：适用图式计算场景]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix]]></title>
    <url>%2F2018%2F12%2F02%2FZabbix%2F</url>
    <content type="text"><![CDATA[Zabbixzabbix是一种开源监控软件，能实现各种强大监控功能（数据采集，展示，报警）等功能。 监控的过程 数据采集—&gt;数据存储—&gt;数据显示 时间序列数据（趋式，陡式），采集点连成线会生成数据趋式图 报警:采集到的数据超出阈值（如系统应用指标，文件变化，应用状态） Zabbix监控实现zabbix可使用Zabbix-Agent，ICMP，SNMP，HTTP，JMX，IPMI来监控客户端 IPMI(interlligent platform management interface)智慧平台管理接口，原本是一种inter架构企业系统的周边设备采用的一种工业标准 IPMI也是一个开放免费标准，使用者无需支付额外费用就可以使用 通常一些服务器如DELL,IBM支持这种接口 Zabbix可监控对象设备/软件： 设备：服务器，路由交换设备，IO设备 网络设备：snmp，ssh，ipmi 软件：操作系统，网络，应用 支持操作系统有：linux，windows，freebsd，aix，solaris，hp-unix 偶发现故障: 主机down机,服务不可用,主机不可达 严重事件: 数据节点宕机,磁盘满等 主机性能指标: 趋势数据(时间序列): SNMP协议架构： C/S架构：被监控端(Agent)，监控端(NMS), udp协议：Agent：161端口，NMS：162端口 工作模式: NMS向Agent采集数据 Agent向NMS报告数据 NMS请求Agent修改配置 组件: MIB（管理信息库）management information base OID(object id) SMI（MIB表示符） NMP协议 SNMP说明​ NMS可发起对Agent操作有：GET，GETNEXT，SET，TRAP ​ SNMP中的MIB定义被管理对象的一系列信息，每个Agent都有本地MIB库 ​ Agent操作：Response ​ SNMP仅仅实现数据采集功能 SNMP协议版本snmp版本有v1，v2，v3 V1：无验证 V2C：社区，NMS-&gt;Agent 双方共享一个秘钥，认证过程明文 V3：实现认证加密和解密功能，但是用的少 Linux实现snmp是net-snmp程序包 Windows实现snmp是在控制面板中找到程序SNMP 开源监控工具对比Cactiphp实现利用SNMP收集数据即使绘图展示，报警功能不够理想 cacti仅关注数据收集，数据展示，但是对报警功能较弱 cacti利用RRD库(round robin database)环状数据库，只能保存固定时长 Nagios仅关注是否超出阈值,监控功能强大(短信,网关等),可以报警升级,也可以维护时间暂停报警,定义各组件依赖关系,不适合大规模监控 nagios只是关注超出阈值状态转换，完成报警 如果需要增加图标显示需要安装pnp4nagios插件，如果需要存数据库需要NDOUtils，如果需要分布式需要NSCA icinga是Nagios变种 Zabbix能够实现各种强大监控功能（数据采集，展示，报警等） 支持MySQL，PgSQL，Oracle，DB2，SQLite 其他监控软件 OpenNMS ZenOS GangLia 强大的集合绘图，将多个主机组成一个趋势图 Open-Falcon 小米开源监控系统 Zabbix监控功能 zabbix agent，snmp，ping，ssh，ipmi，web监控,数据库监控,内部监控,内部支持复杂计算,自定义命令监控 zabbix agent，snmp，ipmi可以监控CPU、内存、网络、磁盘、服务、日志、文件监控 web监控可以监控到 响应时间、下载速度、响应代码、获取特定要求内容、支持http/https 报警方式:email、sms、jabber、chat message、自定义命令 Zabbix组件 zabbix-server：（C） zabbix-agent：（C） zabbix-web：GUI接口设定展示zabbix（php） zabbix-proxy:分布式监控环境中专用组件(大规模才能用到) Zabbix安装配置需求 版本 平台 cpu/内存 数据库 监控主机 Small ubuntu linux PII 350MHz 256M SQLite 20 Medium ubuntu linux64 bit AMD Athlon 3200+ 2G MySQL InnoDB 500 Large ubuntu linux64 bit Inter Dual Core6400 4G RAID10 MySQL InnoDB or PostgreSQL &gt;1000 Very large RedHat Enterprise Inter Xeon 2*CPU 8G Fatst RAID10 MySQL or PostgreSQL &gt;10000 zabbix数据 配置数据：很小 历史数据：50bytes/1m 历史趋势数据：128bytes/1m 事件数据：130bytes/1m 通常五分钟采集一次，一个监控项目就是320bytes，一小时3.8KB，一年就是34M，一台机器34M zabbix数据计算公式假设，如果一个主机60个监控项，1k个主机就是6万个监控项目。zabbix database需要用到的空间，60000/60 = 1000条，默认90天，趋势图默认一年 历史数据 历史数据 = 天数 x 每秒处理数据量 x 24 x 3600 x 50Bytes 每个历史数据50bytes 90x1000x24x3600x50 三个月产生360G数据 趋势数据 趋势数据 = 天数 x 监控项数 x 24 x 128bytes 每个趋势数据大概128bytes，按小时保存，假设保存一年 365x6000x24x128 一年大概62G数据 事件数据 事件数据 = 天数 x 86400 X 130bytes 每个事件数据大概130bytes，假设保存一年 365 x 86400 x 130bytes 一年大约3G数据 每分钟取一次数据，每秒请求数据大概千次，数据库写压力巨大（建议，监控5分钟取一次） Zabbix安装yum安装1234#需要实现安装mysql or PostreSQLyum install mysql-serverrpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/6/x86_64/zabbix-release-3.2-1.el6.noarch.rpmyum install zabbix-agent zabbix-get zabbix-java-gateway zabbix-proxy-mysql zabbix-sender zabbix-server-mysql zabbix-web zabbix-web-mysql 源码安装下载zabbix源码包 123#需事先安装好LAMP平台，编译zabbix同时安装server和agent，并支持将数据放入mysql数据库中./configure --prefix=/usr/local/zabbix --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-ssh2make &amp;&amp; make install 安装Server端， 1./configure --enable-server --with-mysql --with-net-snmp --with-libcurl 安装Agent端 1./configure --enable-agent --with-ssh2 导入数据库 1234567#导入数据库顺序(schema.sql，images.sql，data.sql)CREATE DATABASE zabbix CHARACTER SET UTF8;GRANT ALL PRIVILEGES ON zabbix.* TO &apos;zabbix&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;zabbixpass&apos;USE zabbix;source schema.sqlsource images.sqlsource data.sql Zabbix配置文件Zabbix-Server端123456789101112131415161718192021222324#/etc/zabbix/zabbix_server.confLogFile=/tmp/zabbix_server.log #日志文件LogFileSize=0 #不做日志滚动DBHost=127.0.0.1DBName=zabbixDBUser=zabbixDBPassword=zabbixpassDBPort=3306StartPollers=5 #启动poller进程多少个,各agent拉取对应指标StartIPMIPollers=0 #启动多少ipmi的poller进程,默认空闲StartPollersUnreachable=1 #不可达的pollerStartTrappers=5 #如果经常拉取对zabbix性能又影响,agent可以自动发送数据到server端,这个Trapper就是捕获该数据StartPingers=1 #icmp探测主机是否在线StartDiscoverers=1 #启动多个自动发现进程(消耗带宽)StartHTTPPoller=1 #启动web的拉取数据进程StartTimers=1 #启动计时器JavaGateway=127.0.0.1 #启动java网关连接jmxJavaGatewayPort=10052 #使用10052端口StartJavaPollers=5 #启动多少java的poller进程StartVMwareCollectors=0 #监控vm的虚拟主机VMwareFrequency=60 #监控vm的频率AlertScriptsPath=/usr/local/zabbix/alertscripts #脚本报警路径ExternalScripts=/usr/local/zabbix/externalscripts #外部脚本路径FpingLocation=/usr/sbin/fping #fping程序路径需要事先安装,fping(并行ping) Zabbix-Agent端123456#/etc/zabbix/zabbix_agent.confServer=192.168.1.2 #服务端ip可用逗号分隔ListenPort=10050ListenIP=192.168.1.100ServerActive=192.168.1.2 #自动推送数据到监控端(默认是被动监控)Hostname=node1 #主机名,唯一 Zabbix Server Process123456789101112watchdoghowsekeeperalerterproller (拉取)httppoller (web拉取)discoverer (自动发现)pinger (探测主机)nodewatcher (监控各节点) timer (计时器) escalator (报警升级)db_config_syncer(数据库配置同步)db_data_syncer (数据库数据同步) Zabbix配置详解Zabbix术语123456789101112131415161718192021222324252627主机(host) 要监控的网络设备,由ip或dns名称指定 主机组(host group) 主机的逻辑容器,可以包含主机和模板,但同一个组内的主机和模板不能互相链接,主机组通常在给用户和用户组指派监控权限时候使用 监控项(item) 一个特定监控指标的相关数据,这些数据来自于被监控对象,对于item是zabbix进行数据收集的核心,没有item将没有数据;相对某监控对象来说,每个item都是由"key"标识 触发器(trigger) 一个表达式,用于评估某监控对像的特定item内所接受到的数据是否在合理范围内,即阈值;接受到数据量大于阈值时,触发器状态将从"ok"转变成"problem",当数据量再次回归到合理范围内从"problem"转成"ok". 事件(even) 即发生的一个值得关注的事情,例如触发器的状态转变,新的agent或重新上线的agent自动注册等 动作(action) 指对特定时间事先定义的处理方法，通过包含操作(如发送通知)和条件(何时执行操作) 报警升级(escalation) 发送报警或执行远程命令的自定义方案,如每隔5分钟发送一次报警,发5次 媒介(media) 发送通知的手段或者通道,如email,jabber或者sms 通知(notification) 通过选的的媒体向用户发送有关某事件的信息 远程命令(remote command) 预定义的命令,可在被监控主机处于某特定条件下自动执行 模板(template) 用于快速定义被监控主机的预设定条目集合,通常包含item,trigger,graph,screen,application以及**low-level discovery rule(自动发现)**;模板可以直接链接到单个主机 应用(application) 一组item的集合 web场景(web scennario) 用于检测web站定可用性一个或多个http请求 前端(frontend) zabbix的web接口 Item 监控项一个特定监控指标的相关数据，这些数据来自于被监控对象，对于item是zabbix进行数据收集的核心，没有item将没有数据；相对某监控对象来说，每个item都是由”key”标识 监控项是zabbix服务器用于监控一个特定对象上的一个特定指标,并负载针对其收集相关监控数据 如CPU每分钟平均负载可以是一个item，每五分钟平均负载是一个item 在比如特定网口接受报文速率也是一个item 每一个item都拥有相应的的类型”type” 例如”zabbix_agent”，“snmp”，“external check”，“IPMI Agent”，“SSH Agent”，“JMX Agent” Zabbix服务器会自动使用相应类型的协议或机制同时被监控端通讯 监控项Keyzabbix服务器在与被监控端通讯时就使用相应的协议或机制去询问被监控端这个key值,被监控端则调用与此key对应的监控脚本获取数据并返回给服务端 key的命名只能使用”0-9a-zA-Z_-.”等字符,且可以接受参数,其命令习惯如system.cpu.load[&lt;cpi&gt;,&lt;mode&gt;],其中括号中的内容为参数,且分别可按次序使用$1,$2,进行引用,此实例中仅有两个参数 若要使用不定数目的参数,则使用”*”表示 zabbix有需要预先定义的key，获取详细地址 https://www.zabbix.com/documentation/2.0/manual/items/itemtypes/zabbx_agent 对于每一个Item,zabbix服务器还定义了这么存储这个item数据以及数据采集频率及历史数据的保存时长等, 多个item还可归类为一个由”Application”定义逻辑组 数据库查看zabbix自定义的Key12USE zabbix;SELECT keys_ FROM items; 如何获取Key1$ZABBIX/bin/zabbix_get -s IP -p PORT -k "system.uname" 创建Item过程1configuration- - &gt; hosts - - &gt;(选择对应主机的items) - - &gt;create item Item多类型zabbix-agent：工作模式passive,active 网卡流量相关: net.if.in[if,&lt;mode&gt;] 进入 net.if.out[if,&lt;mode&gt;] 流出 net.if.total[if,&lt;mode&gt;] 总流量 if：接口 如eth0 mode: bytes,packets,erros,dropped 实例：create items key:net.if.in[eth0,bytes] 监控eth0网卡 store value:delta(speed per second)，计算上一次和这一次 端口相关 net.tcp.listen[port] #监听的端口,布尔值float net.tcp.port[&lt;ip&gt;,port] net.tcp.service[service,&lt;ip&gt;,&lt;port&gt;] net.upd.listen[port] 进程相关 kernel.maxfiles 最大文件数 kernel.maxproc 最大进程数 cpu相关 system.cpu.intr 中断次数 system.cpu.load[&lt;cpu&gt;,&lt;mode&gt;]负载 system.cpu.num[&lt;type&gt;] CPU颗数 system.cpu.switches CPU上下文切换次数 system.cpu.util[&lt;cpu&gt;,&lt;type&gt;,&lt;mode&gt;] CPU利用率 磁盘io或文件系统相关 vfs.dev.read[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] 磁盘读 vfs.dev.write[&lt;device&gt;,&lt;type&gt;,&lt;mode&gt;] 磁盘写 vfs.fs.inode[fs,&lt;mode&gt;] 磁盘inode值 用户可定义item: 关键:选取一个唯一的key 命令:收集数据的命令或脚本 Trigger 触发器监控项 仅负责收集收据，而通常收集数据的目的还包括在某指标对应的数据超出合理范围时给相关人员发送告警信息,该工作就是触发器来定义用于为监控项所收集的数据定义阈值，每一个触发器仅能关联至一个监控项,但可以为一个监控项同时使用多个触发器（一个trigger只能属于一个item，但一个item可以有多个trigger） 事实上为一个监控项定义多个具有不同阈值的触发器可以实现不同级别的报警功能 一个触发器由一个表达式构成，它定义了监控项所采取的数据的一个阈值 一旦某次采集的数据超出了此触发器定义的阈值,触发器状态会转换成”problem”;而采取的数据再次回归至合理规范内时,其状态将重新返回到”ok” 触发器表达式高度灵活,可以创建出非常复杂的测试条件 触发器格式123456789101112&#123;&lt;server&gt;:&lt;key&gt;.&lt;function&gt;(&lt;parameter&gt;)&#125;&lt;operator&gt;&lt;constant&gt; server #主机名称 key #主机上关系的相应监控项的key function #评估采集到的数据是否在合理范围内时所使用的函数,其评估过程可以根据采集的数据,当前时间以及其他因素进行 #目前触发器所支持的函数avg,count,change,date,dayofweek,delta(增量),diff,iregexp,last,max,min,nodata,now,sum等 operator #表达式所支持的运算符及其功能如下表示 #/ * - + &lt; &gt; # = &amp; |例子:&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125;&gt;3#表示主机www.zhuxyid.com上所有cpu过去1分钟内的平均负载的最后一次取值大于3时,将触发状态变换#对last函数来说,last(0)相当于last(#1)&#123;www.zhuxyid.com:system.cpu.load[all,avg1].last(0)&#125; or &#123;www.zhuxyid.com:system.cpu.load[all,avg5].last)(0)&#125; or.... 触发器依赖关系在一个网络中，主机的可用性之间可能存在依赖关系 例如当某网关主机不可达时,其背后的所有主机都将无法正常访问 如果所有主机都配置触发器并设定了相关的通知功能，相关人员将会接受到许多告警信息，这既不利于快速定位,也会浪费资源 正确定义的触发器依赖关系可以避免类似情况发生,他将使用通知机制仅发送最根本的问题相关告警 目前zabbix不能直接定义主机间的依赖关系,其依赖关系仅能通过触发器来定义 触发器等级 SEVERITY DEFINITION COLOUR Not Classified 未知级别 Grey Infromation 一般信息 Light Green Warning 警告信息 Yellow Average 一般故障 Orange Hight 高级别故障 Red Disaster 致命故障 Bright Red 触发器状态zabbix server每次接受到items的新数据时，对items当前采样值进行判断，即与trigger表达式进行比较 OK PROPLEM 触发器创建过程 Configuration - - &gt; Host - - &gt; Triggers - - &gt; Create trigger Trigger名称使用宏 ​ (HOST.HOST)，{HOST.NAME}，{HOST.IP}，{HOST.CONN}，{HOST.DNS} 触发条件一般为事件: Trigger events: ok—&gt;proplem Discovery event: zabbix的network discovery工作时发现主机 Auto registration event:主动模式的agent注册时发生的时间 Internal event:item变成不在被支持,或者trigger变成未知状态 Operations的功能:动作: send message: 发送通知手段如下 ​ EMAIL,SMS,Jabber,Scripts,EZ texting Remote command:远程命令 配置send message 定义media 定义用户 配置要发送消息;action就已经定义好 配置Remote Command 前提:执行命令需要agent开启执行远程命令zabbix_agent.conf EnableRemoteCommands=1 是否开启远程执行命令 LogRemoteCommands=1 是否将命令记录到日志中 给zabbix定义sudo规则/etc/sudoers zabbix ALL=(ALL) ALL 特别注意：Remote Command不支持active模式的agent ,不支持代理模式 ,命令长度不得超过255个字符 ,远程命令可以使用宏定义 ,zabbix server仅执行命令,不关心命令是否执行成功 注意: 如果用到以其他用户身份执行命令的话,那么命令本身要以sudo方式运行 sudo /etc/rc.d/init.d/httpd restart 注释agent上的sudoers文件,需要注释(sudo模式下需要一个真实的tty) Default requiretty 报警升级可以使用setp定义几次处理可以邮件升级。 Template 模板用于快速定义被监控主机的预设定条目集合,通常包含item,trigger,graph,screen,application以及low-level discovery rule(自动发现);模板可以直接链接到单个主机 模板是一系列配置的集合,它可以方便地快速部署在某监控对象上,并支持重复应用，此配置可通过”链接”方式应用于指定的主机 items trggers graphs applications screens(since zabbix 2.0) low-level discovery rules(since zabbix 2.0) 将模板应用至某主机上时，其定义的所有条目都会自动添加 模板的另一个好处在于,必要时,修改了模板,应用的主机都会相应作出修改 创建模板 configuration –&gt; templates 在模板上按需添加item,trigger,screen,graph,application以及发现规则 模板可以嵌套 macros 宏宏是一种抽象(abstraction),它根据一系列预定义的规则替换一定文本模式,而解释器或者编译器在遇到宏时会自动进行这一模式的替换类似,zabbix基于宏保存预设文本模式,并且调用时将其替换为其中文本. zabbix有许多内置宏 如{HOST.NAME} {HOST.IP} {TRIGGER.DESCRIPTION} {TRIGGER.NAME} {TRIGGER.EVENTS.ACK}等 ，详细信息参考文档 https://www.zabbix.com/documentation/3.0/manual/appendix/macros 为了更强的灵活性,zabbix还支持在全局,模板或者主机级别使用用户自定义宏(user macro) 用户自定义宏使用”${MACRO}”这种特殊的语法格式 宏可以应用在Item keys和descriptions,trigger名称和表达式,主机接口ip/dns以端口,discovery机制的snmp协议的相关信息中等 宏名称只能使用大写字母、数字、下划线 参考https://www.zabbix.com/documentation/3.0/manual/appendix/macros/supported_by_location 宏替换次序 首先是主机级别的宏 其次是当前主机上的上一级模板中(直接连接至主机的模板)的宏,多个一级模板按其ID号排序 再接着就是二级模板中的宏,而后以此类推 最后检查的是全局宏 zabbix如果无法查找某主机定义的宏,则不会对其进行替换操作,要使用用户自定义宏,有一下两种途径 全局宏:”administratorion” –&gt; general —&gt; macros macro:{$NGINX_PORT} value:80 主机或模板级别的宏:编辑相应主机或模板的属性即可,(只针对当前主机.主机级别最高) 总结:宏分为两类: 内建:{MACRO_NAME} 自建:${MACRO_NAME} 三个级别使用: global全局 template模板 host主机 优先级:host —&gt; template—&gt;global 在某级别找到后直接使用不会往后查找 Web Scennario web场景用于检测web站定可用性一个或多个http请求 zabbix还可对web站点可用性的可用性检测 创建web监控需要先定义一个web方案(scenarios) web方案包含一个或多个http请求或”步骤)step” ，步骤(step)的执行过程按照预先定义的顺序进行执行 通过web监控可实现获取如下信息 整个web方案中所有的步骤平均下载速度 失败的步骤号 失败的报错信息 在web方案的具体步骤中,可按需进行如下信息 该步骤的下载速度 回应时间 回应状态吗 zabbix可以检测获取到html页面中是否包含预设的字符串,可以实现登陆和页面点击 创建web方案 创建web方案前提需要创建一个使用的应用(application) 可以在”hosts”或者”templates”上创建应用 如果在”templates”上创建应用,则需要将此”templates”连接至要监控其web的主机上方能使此”application” 步骤： configuration–&gt;web(zabbix2.4) configuration–&gt;templates(host)–&gt;web(zabbix3.0) 例子： 1234567891011121314scenario name:zhuxyid.comnew application:zhuxyid.com update interval:30s agent:chrome3.8(windows) 其他默认 step name:zhuxyid.indexurl:http://www.zhuxyid.comfollow redirects:enable timeout:10 required status codes:200 monitoring--&gt;web--&gt;zhuxyid.com即可出图 Zabbix自动发现zabbix提供网络发现(network discovery)，低级发现(low level discovery) Network Discovery网络发现 HTTP,ICMP,LDAP,SSH,TCP,SNMP,Telnet,Zabbix_agent 扫描指定网络内的主机 一旦主机被发现,如果对其进行操作,由action来决定 LLD:low level discovery 低级发现 自动添加或者移除主机,链接至模板或删除链接,添加监控项,将主机添加至分组,定义触发器 执行远程脚本 Network Discovery网络发现是zabbix最具特色功能,他能够根据用户实现定义的规则自动添加监控的主机或服务 发现中的事件有如下两种: 服务:service discovered,service lost,service up,service down 主机:host discovered,host lost,host up,host down zabbix的网络发现功能可基于如下信息进行 1234IP rangftp,ssh,web,pop3,imap,tcp,etc zabbix agent snmp agent 网络发现通常包含:discovery和action discovery中的事件: service up service down host up host down service discovery service lost host discovery host lost action中网络发现中事件可以触发action,从而自动执行指定的操作 sending notifications adding/remove hosts enabling/disabling host adding hosts to a group remove hosts from a group linking hosts to/unlinking from a template executing remote scripts 这些事件的配置还可以基于设备类型,ip,状态、上线/离线等进行配置 接口添加 网络发现中添加主机时会自动创建interface the service detected,如果基于snmp检测成功,会创建snmp接口 如果某服务同时响应给了agent和snmp则两种接口都会创建 如果同一种机制(如agent)返回非唯一数据,则第一个接口被识别为默认,其他的为额外接口 即便是某主机开始时只有agent接口，后来通过snmp发现他，同样会添加额外snmp接口 不同主机如果返回了相同数据，则第一个主机将被添加，余下的主机会被当作第一个主机额外的接口 Auto Registation 自动注册配置 需要修改agnet配置 12345678&gt; ListenIP=192.168.0.100 #192.168.0.100是agent的地址,最好指定本地地址不要使用0.0.0.0&gt; ListenPort=10050&gt; Server=192.168.0.1&gt; ServerActive=192.168.0.1 #192.168.0.1是zabbixserver的ip,重要&gt; Hostname=iis&gt; HostMetadata=ariis #用于唯一标识主机,只能用于自动注册,最多255个字符&gt; #HostMetadateItem= #也可以使用item获取数据,通常使用systen.uname 发给服务端自动注册&gt; 配置自动注册 configuration—&gt;actions–&gt;Event source(Auto registration)–&gt;create action action: name: auto_reg new condition: host metadata like ariis #主机元数据 operations: default subject 自动注册 default Message 主机名称{HOST.HOST} 主机地址:{HOST.IP} 主机端口:{HOST.PORT} Operations: send message to user: 邮件通知用户 add to host groups 添加主机组 links to templates 连接模板 支持使用agent(active)类型的item key: Low Level DiscoveryLLD低级发现特定变量名称:区别不同主机应用使用items值不一样(如eth0跟em0) 1234&gt; IFNAME&gt; #FSNAME #大多数针对网络接口,文件系统 &gt; #自定义脚本实现相应功能 &gt; 添加针对对应变量的items: 返回值是json格式,方便数据交换 查看zabbix agent内置的keys 123&gt; USE zabbix&gt; select key_ from items where key_ LIKE &apos;%discovery%&apos;; &gt; 配置过程 configuration—&gt;templates(host)—&gt;discovery rules—&gt;create discovery rule 12345discovery rulename:if lldtype:zabbix agentkey:net.if.discoveryupdate interval: 30s filters 12Type of calculation Filters A &#123;#IFNAME&#125; matches em-xxx item 1key:net.if.in[#IFNAME,bytes] Zabbix报警定义发送机制(这里官方提示需要用tls/ssl认证发送，可以使用脚本发送邮件) 邮件方式:administration—&gt;media types name:zabbix_mail type:email SMTP server:exmail.com.cn SMTP helo:exmail.com.cn SMTP email:zabbix@exmail.com.cn enable:enable 脚本方式:12345678910111213141516#tail -n10 /etc/mail.rc set from=zabbix@zhuxyid.comset smtp=smtp.exmail.qq.com set smtp-auth-user=admin@zhuxyid.comset smtp-auth-password=12345 set smtp-auth=login #vi /etc/zabbix/etc/zabbix_server.conf AlertScriptsPath=/etc/zabbix/scripts #more /etc/zabbix/scripts/sendmail.sh #!/bin/bash BODY=/var/zabbix/mailtmp echo "$3" &gt; $BODY dos2unix $BODY #需要事先安装dos2unix转移,不然邮件会是附件形式/bin/mail -s "$2" $1 &lt; $BODY 创建用户以及发送报警级别邮件 administration—&gt;users—&gt;users–&gt;create user user alias:SA_OPS Name:zhuxy last name:zhuxuyue groups:zabbix administrators password: …. media type:zabbix_mail send to:admin@exmail.com.cn when active:1-7,00:00-24:00 7*24 use if severity: 定义报警级别(什么级别发给什么用户) status:enabled 定义发送内容 configuration –&gt; actions–&gt;create action Action Name:cpu problems defalt subject: {TRIGGER.STATUS}:{TRIGGER.NAME} #标题:trigger状态和trigger名称 default message: #正文 recovery message: #如果状态从proplem转换成ok发送信息 enable:enable conditions 发送条件 type of calculation:[and|or|custom expression] 类型条件,如果下列conditions都满足就发送邮件(and),满足其中一个就发邮件(or),可以自定义表达式 conditions: A Maintenace status not in maintenance 维护状态不在维护中,如果状态在维护中应该不能发报警 B Trigger value = PROBLEM C Trigger = node1:cpu too many interrupta operations default operation setp duration 300 #每次报警时长(默认1小时),最小60s action operations operation details: setp from 1 ​ to 2 #从第一步到第二步就是10分钟(1步5分钟) setp duration 0 operation type send message|remote command #如果10分钟后要么发送报警，要么执行远程命令 send to user groups #发个组 send to user #发给用户 send only to ：email #仅通过email发送信息(可以使用all就是所有报警机制都发送),如果问题严重建议使用短信,电话，微信发送信息 default message #默认信息 conditions: #条件 action： 触发条件一般为时间: trigger events: ok –&gt; proplem discovery event:zabbix的network discovery工作时发现主机 autho registration event:主动模式的agent注册时产生的时间 internal events：items变成不在被支持,或者trigger变成未知状态 用户参数zabbix 内置了许多item keys: user parameters实现自定义item key，实现特有数据指标监控 syntax语法: UserParameter=&lt;key&gt;,&lt;command&gt; UserParameter=key[*].command 需要重启agent才可以生效 实例: 1UserParameter=Nginx.active[*],/usr/bin/curl -s "http://$1:$2/status" | awk '/^Active/ &#123;print $NF&#125;' 实例：比如监控agent端的内存 1234567891011121314151617181920#zabbix-agent端#vi $zabbix_home/conf/zabbix_agentd.conf include=/usr/local/zabbix_agents/conf/zabbix_agentd/userparameter_mem.conf #more $zabbix_home/conf/zabbix_agentd/os_linux.conf UserParameter=os.memory.used,free -m|awk '/^Mem/&#123;print $3&#125;' UserParameter=os.memory.total,free -m|awk '/^Mem/&#123;print $2&#125;' UserParameter=os.memory.free,free -m|awk '/^Mem/&#123;print $4&#125;' #service zabbix-agent restart #zabbix-server端zabbix_get -s 'ip' -k "os.memory.free"#看是否能获取数据创建监控项目:host ---&gt;items---&gt;creat items name:内存使用情况 key:os.memory.used #调用agent的key就是刚才定义好的 use custom multiplier:1024000 #之前以及转换成mb,如果直接在units填写mb，超出1G就会出现1kmb,所有不设置units,让计算的值乘以1024000，这里free -m显示多大默认是以b为单位 Zabbix分布式监控分布式监控概述 proxy and node Zabbix三种架构 server-agent server-node-agent server-proxy-agent Zabbix分布式监控概述 zabbix能高效的监控分布式it架构 在大型环境中zabbix提供两种解决方案 使用代理(proxy) 使用节点(node) Proxy or Node 代理(proxy)用于本区域数据收集,并将数据发送给server 节点(node)提供完整的zabbix server用于建立分布式监控中的层级 Proxy Node Lightweight轻量级 YES NO GUI图形接口 NO YES Works idependently独立工作 YES YES EASY maintenance 易维护 YES NO Automatic DB create 数据库自动创建 YES NO Local Administration 本地管理 NO YES Ready for embedded hardware 嵌入式监控 YES NO One way tcp connections 单向TCP连接 YES YES Centralised configuration 集中配置 YES NO Generates notifications 生成通知 NO YES Proxy：高性能，可以独立工作，易于维护，支持自动创建数据库，支持嵌入式监控，只支持一路TCP连接，支持集中配置。 不支持GUI接口，不支持本地管理，不支持通知 Server-Node-Client：特性 解决host过多时单台server面临性能瓶颈问题 使用多个instance 每个instance是独立的一套zabbix,有database和frontend(optional) 支持热插拔,Node和Server的连接可以随时断开,不影响node正常运行 node定时给server发送configuration,history,event server定时给node发送configuration 所有配置变更只能node节点操作,不能在server操作 (http://www.zabbix.com/forum/showthread.php?t=20863) 支持树状结构,Node可以是个server Server-Proxy-Client工作特性 proxy不会向server同步configuration,只接受 proxy的数据库定时回将数据传送给server,proxy本地数据库只保存最近有没有发送的数据 Proxy 对比 NodeNode本身是一台server，有完整的Web页面，完整的数据库,他将数据源源不断的传送给Master proxy只有一个proxy的daemon进程,proxy也有自己的数据库,但他的数据库智慧保存一定时间的数据，他与master通信是将一批信息打包后发送给master，master将这些数据merge入master数据库 master-proxy相比master-node优点有如下几点: proxy压力小,数据库只存一定时间数据 master压力变小,数据不是源源不断获取，减小io压力 架构清晰,便于维护 Zabbix-proxy安装1234567891011121314151617181920212223#需要安装mysql#yum install zabbix-proxy zabbix-proxy-mysql mysql&gt; create database zabbix-proxy character set utf8; mysql&gt; grant all on zabbix_proxy.* to zabbix@&apos;%&apos; identified by &apos;admin123&apos; mysql&gt; flush privileges; mysql&gt; use zabbix-proxy; mysql&gt; source schema.sql; 只需要导入一个库就可以 #vi /etc/zabbix-proxy/etc/zabbix_proxy.conf Server=ZABBIX-SERVER-IP Hostname=Zabbix-Proxy-NJYFXJ HostnameItem=system.host #如果没有定义hostname,就定义item DBHOST=localhost DBName=zabbix-proxy DBUser=zabbix DBPassword=admin123 HeartbeatFrequency=60 #默认60s探测一次可用状态 ConfigFrequency=3600 #每隔1小时到服务端拉取数据 DataSenderFrequency=1 #每隔1s将数据发送给服务端 #server zabbix-proxy start #netstat -anptl | grep 10050 Server端配置Proxy administration–&gt;proxies proxy name:Zabbix-Proxy-NJYFXJ proxy mode:active|passive (拉取|主动推送) hosts proxy hosts Create host Monitored by proxy:Zabbix-Proxy-NJYFXJ Zabbix常用模板官方模板：123456789101112131415161718192021zabbix常用模板Redishttps://github.com/adubkov/zbx_redis_templateRabbitMQhttps://github.com/jasonmcintosh/rabbitmq-zabbixnginxhttps://share.zabbix.com/cat-app/web-servers/nginx-for-zabbix-3-2IIShttps://share.zabbix.com/cat-app/web-servers/iis-sites-and-application-pool-state-monitoringSSL证书https://share.zabbix.com/cat-app/web-servers/ssl-certificates-checkMS sqlserverhttps://share.zabbix.com/databases/microsoft-sql-server/template-ms-sql-2012routeOShttps://share.zabbix.com/network_devices/mikrotik/mikrotik-routeros]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis]]></title>
    <url>%2F2018%2F11%2F30%2FRedis%2F</url>
    <content type="text"><![CDATA[Redis介绍Redis是一个基于BSD开源的高性能键值缓存服务，支持数据结构string，list，hash，set，sorted，bitmaps，hyperloglog。 官方站点：http://www.redis.io Redis特点: kv存储，存储在内存中， redis可以持久化周期性的存储在磁盘上(冗余作用) ​ 快照，内存数据异步传输到磁盘（RDB）。 ​ AOF，每次写操作附加在文件中。 ​ Master-Slave方式,主写，从读。 redis支持主从模式，借助哨兵（Sentinel实现一定意义上的高可用） redis3.0开始支持群集（分布式） Redis和Memcache区别 memcache是一个分布式内存对象缓存系统，且不可持久化，redis支持 持久存储 memcache是基于LRU cache(最近最少使用) ，redis有不同特性以及跟多数据类型 memcache是多线程，redis是单线程，两者的性能几乎相同 Redis优点： ​ 丰富(资料形式)操作(Hashs,Lists,Sorted,Sets,HyperLoglog) ​ 内建replication及cluster ​ 就地更新(in-place update)操作 ​ 支持持久化(磁盘)，避免雪崩 Memcache优点 ​ 多线程(善用多核cpu，更少堵塞操作) ​ 更少内存开销 ​ 更少内存分配压力 ​ 内存碎片更少 其他资料常见的存储系统分为三类: RDBMS：如Oracle，SQLServer，MySQL。 NoSQL：如Hbash，MongoDB，Redis NewSQL：分布式关系型事物系统 NoSQL四种流派： 键值NoSQL：如Redis，Memcache 列族NoSQL：如Hbash，MongoDB，Redis 文档NoSQL：MongoDB 图形NoSQL：Neo4J Redis案例: ​ 一百万的key，内存使用约100M ​ 单线程，虽然单线程，却能承受500k的并发请求 Redis安装12345678910111213141516171819#安装redis需要安装jemalloc内存管理工具(google研发)yum install tcl#下载源码地址：http://download.redis.io/releases/#安装步骤tar zxvf redis-VERSION.tar.gzcd redis-VERSIONmake#安装完成后，生成如下文件redis.conf redis配置文件sentinel.conf 主从架构配置文件src/redis-server redis服务端src/redis-cli redis客户端src/redis-check-aof redis检查工具（AOF）src/redis-check-dump redis检查工具（快照）src/redis-benchmark redis性能工具src/redis-sentinel redis主从架构提供高性能工具 Redis基本配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107cat redis.conf | grep -v "^#" | grep -v "^$"#全局设置####INCLUDE####daemonize nopidfile /var/run/redis.pidport 6379tcp-backlog 511 #tcp-backlog长度 （backlog是个队列缓冲，tcp通常会有backlog）bind 126.0.0.1 192.168.2.21unixsocket /tmp/redis.sock #如果不使用tcp方式，可以直接使用unixsocket方式,效率比tcp高timeout 0 #客户端连接超时时间(0表示不会超时)，根据需求设定tcp-keepalive 0loglevel noticelogfile "/var/log/redis/redis.log"syslog-enabled no #是否启用系统日志syslog-ident redis #日志识别syslog-facility local0 #日志设施databases 16 #redis是否支持多内部数据集合，默认放在0，在redis集群中只支持16#快照，持久化配置信息####SNAPSHOTTING#####格式 save seconds changessave 900 1 #900s（15分钟），如果有1个键值发生改变，就存储save 300 10 #300s（5分钟），如果有10个键值发生改变，就存储save 60 10000 #60s（1分钟），如果有1000个键值发生改变，就存储#save "" #取消注释表示禁用持久化功能stop-writes-on-bgsave-error yes #在RDB方式下，如果使用bgsave保存是否检查如果检查错误是否停止rdbcompression yes #RDB是否压缩，压缩会消耗cpu资源rdbchecksum yes #是否对rdb进行校验码检测dbfilename dump.rdb #DBfile文件名称dir ./ #指明文件保存目录#主从配置信息####REPLICATION#####slaveof &lt;masterip&gt; &lt;master-ports&gt; #如果这个注释，说明是master模式，如果开启需要指定master的IP和端口slave-serve-stale-data yes #是否从服务器使用过期数据slave-read-only yes #是否只读，如果slaveof注释，这里是没有用的，repl-diskless-sync no #是否给予diskess同步，如果网络快，磁盘写慢建议开启repl-diskless-sync-delay 5 #延迟时间多久repl-disable-tcp-nodelay no #tcp nodelay功能slave-priority 100 #slave优先级min-slaves-to-write 3 #从节点至少3个节点，将禁止主服务器写请求min-slaves-max-lag 10 #从节点如果相差10s，主服务器拒绝执行写入操作#安全相关配置####SECURITY#####requirepass foobared #认证密码foobaredrename-command CONFIG ""#并发相关配置####LIMITS######maxclients 10000 #最大并发数量，多少客户端连接maxmemory &lt;bytes&gt; #每个客户端内存使用量maxmemory-policy noevictionmaxmemory-samples 5#AOF持久化####APPEND ONLY MODE####appendonly no #是否使用AOF功能，yes使用，这里是禁用appendfilename "appendonly.aof" #AOF文件名appendfsync &#123;always | everysec | no&#125; #AOF追加方式&#123;always没接受一条写一条，everyse每秒写一条，no 表示根据系统调用来写&#125;no-appendfsync-on-rewrite no #如果是yes表示重写的时候对新写的操作是存在内存auto-aof-rewrite-percentage 100 #aof文件增长了100%也就是两倍，触发重写操作auto-aof-rewrite-min-size 64mb #如果重写大小达到64M就重写aof-load-truncated yes#redis加载aof文件，发现末尾命令不完整自动截掉，成功加载前面正确数据，如果设置no，遇到不完整redis启动失败，redis-check-aof修复#lua脚本设置####LUA SCRIPTING####lua-time-limit 5000#redis群集设置####REDIS CLUSTER####cluster-enabled yescluster-config-file nodes-6379.confcluster-node-timeout 15000cluster-slave-validity-factor 10cluster-require-full-coverage yes#慢查询日志设置####SLOW LOG####slowlog-log-slower-than 10000slowlog-max-len 128#监控设置####LATENCY MONITOR####latency-monitor-threshold 0#事件通知设置 跟发布订阅有关####EVENT NOTIFICATION####notify-keyspace-events ""#高级设置####ADVANCED CONFIG####hash-max-ziplist-entries 512hash-max-ziplist-value 64list-max-ziplist-entries 512list-max-ziplist-value 64set-max-intset-entries 512zset-max-ziplist-entries 128zset-max-ziplist-value 64hll-sparse-max-bytes 3000activerehashing yesclient-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60hz 10aof-rewrite-incremental-fsync yes Redis命令123456789101112131415161718192021222324#启动redis前需要设置echo 'vm.overcommit_memory=1' &gt;&gt; /etc/sysctl.conf #内存不足的情况下，后台程序save可能失败，建议将其改成1echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled#如果使用透明大页，可能导致redis延迟和内存使用问题echo 511 &gt; /proc/sys/net/core/somaxconn#tcp backlog值#启动redis-server &amp;-h HOST : 连接的主机地址或主机名-p PORT :连接的端口-s socket : 指定套接字-a password : 指定连接密码-r &lt;repeat&gt; : 指定命令运行多次overcommit_memory参数说明设置内存分配策略，可以设定0、1、20 表示内核将检查是否有足够的内存供应进程应用，如果没有足够的可用内存，内存允许申请；否则内存申请失败，并将错误返回给应用进程1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何2 表示内核允许分配超过所有物理内存和交换空间总内存注：redis在dump数据时，会fork出一个子进程，理论上child进程所占有内存和parent是一样的，如果parent占用内存为8G，这个时候同样分配8G的内存给child，如果内存无法负担，往往会造成redis服务的down机或者IO负载过高，导致效率下降，所有这里比较优化的内存策略应该为1（表示内核运行分配所有的物理内存，而不管当前内存状态) Redis基本操作1234567891011#redis-cli -h 127.0.0.1127.0.0.1:6379&gt;helpType help @&lt;group&gt; help &lt;tab&gt;127.0.0.1:6379&gt; help @connection #帮助命令 127.0.0.1:6379&gt; help @STRING #获取字符串操作帮组127.0.0.1:6379&gt; ping #测试 PONG127.0.0.1:6379&gt; echo 'hello world' #回显 "hello world" 127.0.0.1:6379&gt; QUIT #退出 server主要设置redis服务器 1234567891011121314151617181920127.0.0.1:6379&gt; CLIENT SETNAME localconn #设置名称OK127.0.0.1:6379&gt; CLIENT GETNAME #获取名称"localconn"127.0.0.1:6379&gt; CLIENT LIST #client列表"id=2 addr=127.0.0.1:38521 fd=6 name= age=272 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client"127.0.0.1:6379&gt; CLIENT KILL ip:port #剔除一个client127.0.0.1:6379&gt; INFO #获取信息127.0.0.1:6379&gt; INFO MEMORY #获取memory信息，如获取cpu，执行info cpu127.0.0.1:6379&gt; CONFIG RESETSTAT #重置所有配置信息127.0.0.1:6379&gt; CONFIG SET #设置仅在内存生效127.0.0.1:6379&gt; CONFIG REWRITE #同步到配置文件中，如果用CONFIG SET方式设置redis参数需要REWRITE同步到配置文件中 SELECT使用0的命名空间，默认是0，使用SELECT [空间名进行跳转最大16个] 同一个名称空间不能使用相同的键值 12345127.0.0.1:6379&gt;SELECT 0127.0.0.1:6379&gt;SELECT 15OK127.0.0.1:6379[15]&gt;SELECT 16(error)ERR invalid DB index SET12345678910111213127.0.0.1:6379&gt; help set格式:SET key value [EX seconds] [PX milliseconds] [NX|XX] #set key value [过期时间] [标识] [如果键值不存在才会创建|如果键值存在覆盖]127.0.0.1:6379&gt; set 01 nameOK127.0.0.1:6379&gt; set 02 name2OK127.0.0.1:6379&gt; set 01 name nx(nil)127.0.0.1:6379&gt; set 03 name nxOK127.0.0.1:6379&gt; set 04 name ex 5 设置5s过期 GET123456127.0.0.1:6379&gt; get 02&quot;name2&quot;127.0.0.1:6379&gt; get 01&quot;name&quot;127.0.0.1:6379&gt; get 04 过期后会提示nil(nil) APPEND12345127.0.0.1:6379&gt; append 01 haha (integer) 8 127.0.0.1:6379&gt; get 01 &quot;namehaha&quot; STRLEN12127.0.0.1:6379&gt; STRLEN 01 #长度(integer) 8 INCR只针对整数增加生效 12345678127.0.0.1:6379&gt; set count 0 OK 127.0.0.1:6379&gt; INCR count #增加(integer) 1 127.0.0.1:6379&gt; INCR count (integer) 2 DECR12345127.0.0.1:6379&gt; DECR count #减(integer) 1 127.0.0.1:6379&gt; DECR count (integer) 0 事物通过MULTI,EXEC,WATCH等命令实现事物功能: redis事物只是将一个或者多个命令打包一个操作服务端按顺序执行机制redis事务不支持回滚操作 123456789101112131415127.0.0.1:6379&gt; MULTT #启动一个事务OK127.0.0.1:6379&gt; SET IP 192.168.2.21QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; SET PORT 8080QUEUED127.0.0.1:6379&gt; GET PORTQUEUED127.0.0.1:6379&gt; EXEC #执行事务，一次性将事务中的所有操作执行完成后返回给客户端1) OK2) "192.168.2.21"3) OK4) "8080" 清空操作:)for _ in range(1000):print(“不要在生产使用”) 12FLUSHDB 清空当前数据库FLUSHALL 清空所有数据库0~15 WATCH 乐观锁WATCH在EXEC命令执行之前，用于监视指定数量的键，如果监视中的某任意键数据被修改，则服务器拒绝执行事务 12345678910127.0.0.1:6379&gt; WATCH IP #监控IP键OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET IP 10.0.0.1QUEUED127.0.0.1:6379&gt; GET IPQUEUED127.0.0.1:6379&gt; EXEC #如果在MULTI之后,EXEC之前有个客户端修改了IP，这里EXEC的话，就会拒绝事务(nil) Redis认证如果使用认证功能需要编辑配置文件找到requirepass 123456789101112格式：requirepass PASS $vi /etc/redis.conf requirepass zhuxyid $redis-server /etc/redis.conf redis-cli -h 127.0.0.1 127.0.0.1:6379&gt; select 0 (error) NOAUTH Authentication required. 127.0.0.1:6379&gt; auth zhuxyid OK 127.0.0.1:6379&gt; select 0 OK Redis发布订阅频道:消息队列 123456789101112SUBSCRIBE:订阅一个或多个队列PUBLISH:向频道发布消息例子&gt;SUBSCRIBE www.zhuxyid.com #订阅www.zhuxyid.com频道&gt;PUBLISH www.zhuxyid.com hello #向www.zhuxyid.com频道发送PSUBSCRIBE:订阅多个队列&gt;PSUBSCRIBE www.zhuxy.i[to] #订阅www.zhuxy.io 和 www.zhuxy.it频道&gt;PUBLISH www.zhuxy.io hello io&gt;PUBLISH www.zhuxy.it hello it Redis持久化#####RDB和AOF RDB:snapshot，二进制格式：被事先定制的策略,如save 900 1,周期性将数据保存到磁盘:数据文件默认为dump.rdb; ​ 客户端也可以使用SAVE或者BGSAVE命令启动快照保持机制 ​ SAVE:在主线程中保存快照，此时会堵塞所有用户请求，如果数据量大，严重影响性能 ​ BGSAVE:异步，不会被堵塞，只是创建子进程，保存到临时文件，主进程依然处理客户端请求 AOF:Append Only File. 记录每一次写操作至指定的文件尾部实现持久化，当redis重启时，可通过重新执行文件中的命令，在内存中重建数据库。 ​ BGREWRITEAOF:AOF文件重写； ​ 不会读取正在使用的AOF文件，在通过将内存中的数据以命令的方式保存在临时文件中，完成后替换原来的AOF文件 RDB：配置:redis-cli可以用config get dir查看 123456789配置如下：save 900 1save 300 10save 60 10000stop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yesdbfilename dump.rdbdir ./ AOF:AOF重写过程： redis主进程调用fork生成子进程 子进程根据redis内存中的数据创建数据库重建命令列于临时文件中 父进程继承clinet请求，并会把这些请求写操作继续追加至原来的AOF文件，额外的这些新的请求会被放置于一个缓冲队列中 子进程重写完成会通知父进程，父进程会把缓冲中的命令写到临时文件中 父进程用临时文件替换老的AOF文件 12345678配置如下：appendonly noappendfilename &quot;appendonly.aof&quot;appendfsync everysecno-appendfsync-on-rewrite noauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mbaof-load-truncated yes RDB和AOF注意事项：redis如果同时使用两种持久化会导致IO影响大。 需要注意的是，就算可以持久化也不要忘记备份，万一磁盘坏了持久化也没什么用，对redis持久化文件进行备份。 RDB和AOF同时使用： BGSAVE和BGREWRITEAOF不会同时执行 在redis服务器启动用于恢复数据时，优先是有AOF，因为RDB是周期性的，数据不能保证为最新的 Redis复制特点: 一个master可以有多个slave 支持链式复制：slave可以有多个slave master以非阻塞方式同步至slave master&amp;slave工作原理: 启动一个slave，会请求同步master，master启动子进程，将快照保存在文件中，将文件传送给slave，slave接受文件保存本地加载至内存，完成同步 配置过程12345678910111213141516配置master&amp;slave192.168.2.21(master)修改配置文件bind 192.168.2.21启动redis192.168.2.23(slave)修改配置文件bind 192.168.2.23slaveof 192.168.2.21 6379启动redis或者直接在redis-cli输入slaveof 192.168.2.21 6379建议master写，slave读。如果master使用requirepass开启认证功能，从服务器要使用masterauth &lt;PASSWORD&gt; 来连入服务请求使用此密码进行认证 主从复制缺点:如果redismaster离线了，怎么办？可以使用redis-sentinel(主从架构实现高可用) Redis sentinelsentinel主要作用： 用于管理多个redis服务实现HA 监控，通知，故障转移 留言协议，投票协议。 启动流程: 服务器自身初始化，运行redis-server中专用于sentinel功能代码初始化sentinel状态，根据给定配置文件，初始化监控的master服务器列表创建连向master的链接 12345依赖配置文件sentinel.confredis-sentinel /path/to/sentinel启动redis-server /path/to/sentinel --sentinel sentinel配置文件说明1234567891011121314151617port 26379dir /tmpsentinel monitor mymaster 127.0.0.1 6379 2#格式:sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;#&lt;quorum&gt;票数,sentinel至少两票启动，如果只有一个则改成1&gt; !!如果还有其他应用使用redis主从也可以做监控，改变master-name就可以sentinel down-after-milliseconds mymaster 3000#格式:sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;#判断节点离线超过多少秒认为离线的。单位毫秒,sentinel parallel-syncs mymaster 1#格式:sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;#执行故障转移时候允许多少从服务器向新的主服务器同步请求sentinel failover-timeout mymaster 180000#格式:sentinel failover-timeout &lt;mymaster&gt; &lt;failover-timeout&gt;#当主服务器出现故障时候,从服务器提升主服务器的超时时间，单位毫秒 sentinel下线机制：主观下线和客观下线 主观下线:一个sentinel实例判断出某个节点下线 客观下线:多个sentinel节点协商后判断出某节点下线 专用命令123456redis-clit -h sentinelip -p sentinelport SENTINEL masters #列出所有主服务器SENTINEL slaves &lt;master name&gt; #获取当前redis示例中的从节点信息SENTINEL get-master-addr-by-name &lt;master name&gt; #直接获取当前redis实例主节点IP地址和端口SENTINEL reset #重置SENTINEL failover &lt;master name&gt; #手动切换 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596环境如下:172.16.36.70 : redis主节点 172.16.36.71 : redis从节点 172.16.36.72 : redis从节点 172.16.36.74 : sentinel节点1 172.16.36.75 : sentinel节点2 172.16.36.76 : sentinel节点3####配置redis主节点 操作主机: 172.16.36.70 #vim /etc/redis.confbind 172.16.36.70daemonize yes #启动服务 #redis-server /etc/redis.conf####配置redis从节点 #操作主机: 172.16.36.71 #vim /etc/redis.conf bind 172.16.36.71 daemonize yes #启动服务#redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置redis从节点#操作主机: 172.16.36.72 #vim /etc/redis.confbind 172.16.36.72daemonize yes #启动服务 #redis-server /etc/redis.conf #配置主节点信息#redis-cli -h 172.16.36.71 -p 6379 172.16.36.71:6379&gt; SLAVEOF 172.16.36.70 6379 OK####配置sentinel节点#操作主机: 172.16.36.74 #vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14)) #操作主机: 172.16.36.75 # vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 #启动服务 #redis-sentinel /etc/redis-sentinel.conf #查看服务启动状态 users:((&quot;master&quot;,2112,14))操作主机: 172.16.36.76# vim /etc/redis-sentinel.conf port 26379 dir &quot;/tmp&quot; daemonize yes sentinel monitor mymaster 172.16.36.70 6379 2 sentinel parallel-syncs mymaster 3 sentinel down-after-milliseconds mymaster 30000 sentinel failover-timeout mymaster 180000 启动服务 redis-sentinel /etc/redis-sentinel.conf 查看服务启动状态 users:((&quot;master&quot;,2112,14)) #这里有个问题，当一个redis挂掉后，如果连接主redis？可以使用vip(虚拟ip(keepalived)来实现)$sentinel client-reconfig-script myredis /opt/notify_myredis.sh$more /opt/notify_myredis.sh#!/bin/bashMASTERIP=$6 #第六个参数是redis的ip地址LOCALIP=&apos;192.168.0.101&apos; #另外一台按需填写VIP=&apos;192.168.0.100&apos; #client连接的redisNETMASK=&apos;24&apos;INTERFACE=&apos;eth1&apos;if [ $&#123;MASTERIP&#125; = $&#123;local_IP&#125; ];then /sbin/ip addr add $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #将vip绑定到服务器上 /sbin/arping -q -c 3 -A $&#123;VIP&#125; -I $&#123;INTERFACE&#125; exit 0else /sbin/ip addr del $&#123;VIP&#125;/$&#123;NETMASK&#125; dev $INTERFACE #删除 exit 0fiexit 1 #如果返回1，sentinel会一致执行这个脚本]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx]]></title>
    <url>%2F2018%2F11%2F27%2FNginx%2F</url>
    <content type="text"><![CDATA[Nginx是什么Nginx是一个Web服务器,也是个高性能方向代理服务器，Nginx起初为了解决基于进程模型产生的C10k问题，由俄罗斯lgor sysoev研发。 Nginxy有企业版本Nginx Plus，还有二次发行版Tengine，OpenResy（淘宝研发） nginx反向代理支持两种协议 HTTP和MAIL C10K 连接超过10K ,1W个请求,1M =100万个请求 Netcraft可以查看全球服务器Web服务器占有率。 传统上基于进程或线程模型架构的web服务通过每进程或每线程处理并发连接请求，这势必会在网络和I/O操作时产生阻塞，其另一个必然结果则是对内存或CPU的利用率低下。生成一个新的进程/线程需要事先备好其运行时环境，这包括为其分配堆内存和栈内存，以及为其创建新的执行上下文等。这些操作都需要占用CPU，而且过多的进程/线程还会带来线程抖动或频繁的上下文切换，系统性能也会由此进一步下降。 在设计的最初阶段，nginx的主要着眼点就是其高性能以及对物理计算资源的高密度利用，因此其采用了不同的架构模型。受启发于多种操作系统设计中基于“事件”的高级处理机制，nginx采用了模块化、事件驱动、异步、单线程及非阻塞的架构，并大量采用了多路复用及事件通知机制。在nginx中，连接请求由为数不多的几个仅包含一个线程的进程worker以高效的回环(run-loop)机制进行处理，而每个worker可以并行处理数千个的并发连接及请求。 如果负载以CPU密集型应用为主，如SSL或压缩应用，则worker数应与CPU数相同；如果负载以IO密集型为主，如响应大量内容给客户端，则worker数应该为CPU个数的1.5或2倍。 Nginx特性模块化设计，较好的扩展性，早期不支持模块的动态装载和卸载 高可靠性，基于Master/Worker模式 支持热部署（平滑升级迁移），不停机的状态下更新配置文件，跟换日志文件，更新服务器程序版本 内存消耗低，10K个keep-alive连接模式下的非活动连接只消耗2.5M内存 支持event-driven事件驱动模型，AIO驱动机制，MMAP内存映射机制 Nginx基本功能 静态资源的web服务器,自身只能简单的接收和响应http http协议的反向代理服务器 pop3,smtp imap4等邮件协议的反向代理 能缓存打开的文件(元数据缓存:文件的描述符等信息),能加快文件的打开速度 支持FastCGI(php-fpm)，UWSGI 等协议机制,实现代理后端应用程序交互 支持过滤器,例如ZIP,SSI(服务端包含) 支持SSL加密机制 模块化（非DSO机制） standard HTTP modules 标准(核心)HTTP模块:自动编译进程序不止一个Optional HTTP modules 可选http模块Mail modules 邮件模块3rd party modules第三方模块,在编译时需手动指明加载方式加载 Nginx服务相关功能虚拟主机，Keepalive，访问日志，日志缓冲（提高存取西能），URL重写，路径别名，访问控制（IP和用户），支持速率限制，并发限制 Nginx架构Master/Worker模型： 一个master进程可以生成一个或者多个worker进程，每个worker基于事件驱动，响应用户请求, 其支持sendfile,sendfile64,这两种支持的文件大小不同 事件驱动：Linux(epoll)，FreeBSD(kqueue)，Solaris(/dev/poll) 除此之外配置了缓存时还会有缓存加载器进程cache loader和缓存管理器进程cache manager等，所有进程均是仅含有一个线程，并主要通过“共享内存”的机制实现进程间通信。 主进程Master以root用户身份运行，而Worker、Cache Loader和Cache Manager均应以非特权用户身份运行。 Master 加载，验证配置文件 创建，绑定，关闭套接字 管理worker进程（启动，终止，维护） 平滑重启（无需终止服务重载配置） 平滑升级（启用新的二进制程序并在需要时回滚到老版本） 重新打开日志文件，实现日志滑动 其他嵌入式perl，go脚本 Worker 响应客户端请求，提供HTTP服务和代理，提供FastCGI，uWSGI，SCGI等代理 Cache Loader 检查缓存存储中的缓存对象； 使用缓存元数据建立内存数据库； Cache Manager 缓存的失效及过期检验； Nginx安装可使用yum或者源码方式安装 yum安装yum方式很简单，直接使用yum源来安装 12yum install nginx #自动安装依赖关系rpm -ql nginx #查找nginx安装生成的文件 源码安装123456789101112131415161718192021222324252627282930yum install -y pcre-devel openssl-devel zlib-develuseradd nginx -s /sbin/nologin#进入解压后的源码包路径，根据需求来定.** 注意:`--with`都是启用模块，`--without`都是禁用模块 **./configure \ --prefix=/usr \ --sbin-path=/usr/sbin/nginx \ --conf-path=/etc/nginx/nginx.conf \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --user=nginx \ --group=nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --with-http_ssl_module \ #使用ssl模块 --with-http_flv_module \ #使用flv流模块 --with-http_stub_status_module \ #使用监控模块 --with-http_gzip_static_module \ #使用gizp模块 --with-pcre #pcre模块启用 --with-file-aio #支持文件异步 --with-http_image_filter_module #支持图片过滤 --http-client-body-temp-path=/var/tmp/nginx/client/ \ #请求报文主体缓存目录 --http-proxy-temp-path=/var/tmp/nginx/proxy/ \ #代理临时目录 --http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ #fastcgi目录，支持php框架 --http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ #uwsgi目录，支持python框架 --http-scgi-temp-path=/var/tmp/nginx/scgi \ #scgi目录，类似fastcgi另外一种机制# make &amp;&amp; make install Nginx常用命令1234nginx -t #测试配置文件是否正确nginx -s reload #nginx重载文件nginx -V #nginx显示版本号,已经编译的那些模块nginx --help查看更多帮助 配置文件说明123456789/etc/nginx/nginx.conf #主配置文件 Include conf.d/*.conf/etc/nginx/mime.types #所支持的MIME类型列表/etc/nginx/fastcgi_params #fastcgi的配置文件/etc/nginx/fastcgi.conf #与fastcgi_params一般只使用一个/etc/nginx/uwsgi_params #与uwsgi框架的配置文件/etc/nginx/scgi_params #cgi的配置文件/etc/nginx/proxy.conf #代理的配置/etc/nginx/sites.conf #配置虚拟主机的 主配置文件/etc/nginx/nginx.conf 格式如下 1234567891011121314151617181920worker_processerror_loguserevents &#123; use epoll;&#125;http &#123; access_log xxx; upstream server&#123; server IP:PORT &#125; server &#123; location URI &#123; driective &lt;parameters&gt;; &#125; &#125; server &#123; ....; &#125;&#125; MAIN该段落主要是配置Nginx运行启动时候必备参数 和 性能优化 以及 调试定位问题的配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465user nginx;worker_processes 1;worker_cpu_affinity auto;worker_rlimit_nofile 10240;timer_resolution 100ms;worker_priority 20;error_log /var/log/nginx/error.logevents &#123; use epoll; worker_connections 1024;&#125;http:&#123; upstream server &#123; .....; &#125; server &#123; ...; location / &#123; ...; &#125; &#125;&#125;user USERNAME#指定nginx启动worker进程时 以什么用户启动worker_processes NUMBER|auto#启动worker个数#如果负载以CPU密集型为主(比如SSL或压缩)则worker数应与CPU数相同;如果以IO密集为主(如大量内容给客户端)，则worker数应是CPU的1.5或2倍worker_cpu_affinity auto|CPUMASK#根据物理cpu自动绑定,worker不使用进程或者线程处理请求,而是直接将worker绑定到CPU上，这样就没有进程切换这一说法#worker_processes 4;#worker_cpu_affinity 0001 0010 0100 1000;worker_rlimit_nofile NUMBER#设置worker进程打开文件数量，worker_rlimit_nofile需要大于等于woker_connections的大小timer_resolution INTERVAL#用于降低gettimeofday()系统调用的缓存时钟，默认情况下，每次从kevent(),epoll,/dev/poll,select()，poll都会执行此系统调用worker_priority [-20~19]#设置worker进程优先级，官方说明一般在-20到19之间，如果想要woker运行快优先级可调到20error_log PATHFILE#配置错误日志，改参数可用于main,http,server,已经localtion上下文中.events事件驱动I/O框架use [ kqueue | rtsig | epoll | /dev/epoll | select | poll | eventport ]#根据当前系统内核版本设置适合自己的事件模型。#kqueue freeBSD 4.1+#epoll linux2.6+#/dev/epoll solaris 7 11/99+worker_connections NUMBER#事件驱动每个worker支持的连接数,如果worker_process为2，那么服务器最大支持2048个连接#当nginx作为web服务时 最大客户端处理数max_clients = worker_processes * worker_connections#当nginx作为反向代理时 最大客户端处理数max_clients = worker_processes * worker_connections/2#这里的max_clients很多人都疑惑为什么有人认为max_clients = worker_preocesses * worker_connections/4呢？#如果max_clients指的是建立连接最大客户数,由于每个游览器默认两个并发连接,那么nginx作为反向代理是/4#如果max_clients指的是处理客户端数,那就nginx作为反向代理是/2server_tokens off;#隐藏版本号 HTTPHTTP上下文配置用于http的各模块，此类指令很多，每个模块都有专用指令，具体参考nginx官方wiki模块部分的说明。大致上这些模块所提供的配置指令还可以分为以下几个类别: 1234567客户端指令：client_body_buffer_size，client_header_buffer_size，client_header_timeout，keepalive_timeout...文件IO指令：aio，directio，open_file_cache，open_file_cache_min_uses，open_file_cache_valid，sendfile....hash类指令：用于定义Nginx为特定的变量分配多大的内存空间，如types_bash_bucket_size，server_name_hash_bucket_size，variables_hash_bucket_size套接字指令：用于定义Nginx如何处理TCP套接字相关的功能，如tcp_nodelay（用于keepalive功能启用）和tcp_nopush（用于sendfile启用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147...;http &#123; include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log logs/access.log main; #send_time #; #sendfile on; #tcp_nopush on; tcp_nodeplay on keepalive_timeout 65; keepalive_requests 100; #keepalive_disable none | browser; #client_body_buffer_size SIZE(8|16K); #client_body_temp_path [LEVEL1 [LEVEL2 [LEVEL3]]]; #aio on; #directio off; #open_file_cache off; #open_file_cache errors off; #open_file_cache_valid TIME; #open_file_cache_min_uses NUMBER; upstream name &#123; server 192.168.1.10:8080 keepalive 300 &#125; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;include mine.types#指定包含文件类型,mine.type里面定义，如html,css,gif,jpeg,js,txt....default_type application/octet-stream#默认是octet-stream，如果一个文件在mime.types没定义，就使用默认的类型octet-stream，这个表示下载，#如果设置default_type text/html;则表示可以在游览器查看log_format main string#设定log日志格式以及名称，main可以随便定义，string必须是nginx可识别的变量,可以自定义变量#$remote_addr，$http_x_forwarded_for #客户端的ip地址； #$remote_user #客户端用户名称； #$time_local #访问时间与时区； #$request #请求的url与http协议； #$status #请求状态，200,302，404，500等， #$body_bytes_sent #发送给客户端文件主体内容大小； #$request_body #请求体 #$http_referer #从那个页面链接访问过来的； #$http_user_agent #客户浏览器的相关信息； access_log path format_name#设定访问日志路径，使用哪个名称日志格式。#还有设置缓存大小刷新时间间隔，以及定义缓冲提升nginx性能#open_log_file_cache max=N [inactive=time] [min_uses] [valid=time]#open_log_file cache off;#max 设置缓存中描述符最大数量，如果缓存占满，最近最少使用(LRU)的描述符被关闭#inactive 设置缓存文件描述符在多长时间内没有被访问就关闭； 默认为10秒。#min_uses 设置在inactive参数指定的时间里， 最少访问多少次才能使文件描述符保留在缓存中；默认为1。#valid 设置一段用于检查超时后文件是否仍以同样名字存在的时间； 默认为60秒。#off 禁用缓存。send_time #;#发送响应报文的超时时长，默认60ssendfile on|off#在内核完成后直接封装响应客户端(支持小文件) sendfile64(支持大文件)#普通响应步骤client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;用户空间---&gt;内核(复制)--&gt;client#senfile响应client---&gt;网卡(内核)---&gt;用户空间(worker进程80套接字)---&gt;内核空间(系统调用)---&gt;复制---&gt;client#但是如果使用file aio模块，必须禁用sendfile支持tcp_nopush on#不做推送，在开启sendfile才有效，它和tcp_nodeplay互斥，TCP_CORK是linux下tcp/ip传输的一个标准（一般情况下tcp交互中，当程序收到数据包后马上传送不等待，而TCP_CORK选项是数据包不会传送出去，等到数据包最大时一次性传输，有助于解决网络拥堵），在tcp_nopush on时候，才会设置TCP_CORK方法，该选项对于www.ftp等大文件才有帮助。在FreeBSD使用TCP_NOPUSH套接字，在Linux使用TCP_CORK套接字，详见Nagle算法tcp_nodeplay on#对于keepalive模式下连接是否使用tcp_nodelay选项，默认关闭，其功能类似tcp_nopush，将多个小报文合并成一个报文一起发送，提高宽带利用率，将发往同一个主机很小的TCP报文合并成一个,实际生产对于用户请求即使浪费带宽也不能合并请求keepalive_timeout 75 75#长链接超时时间，0表示禁用,默认为75s，请求完成后还需要保持多久连接，目的是减少创建连接过程给系统带来的耗损,通常默认足够，如果内部服务器通讯场景过大建议增大。#第一个75设置keep-alive客户端连接在服务端保持开启超时时间，第二个75可选，在客户端响应的header区域中设置一个"keep-alive:timeout=time"#当nginx作为反向代理时候，为了支持场链接#从client到nginx 和 nginx到server连接都需要设置长连接#例子http &#123; keepalive_timeout 75 upstream www &#123; server 192.168.0.1:8080; server 192.168.0.2:8080; keepalive 300; server &#123; location / &#123; proxy_http_version 1.1; proxy_set_header Connection ""; &#125; &#125;&#125;#upstream 中的keepalive，设置upstream服务器的空闲keepalive连接最大数量，当数量被突破时，最近使用最少连接将被关闭，keepalive指令不会限制一个nginx worker进程到upstream服务器连接的总数量。#HTTP协议对长连接支持从1.1版本后才有，需要通过proxy_http_version指令设置为1.1#而Connection header应该被清理，清理从客户端过来的http header，因为即使是客户端和nginx之间是短连接，nginx和upstream之间也是可以开启长连接。所以需要清理客户端请求中的"Conection" headerkeepalive_requests #在keepalive连接上允许请求的最大资源数量，默认为100，当一个keepalive建立后，nginx就会为这个连接设置一个计数器，记录这个keepalive长链接上已经接受并处理的客户端请求数量，如果达到这个参数设置最大时，nginx会强行关闭这个长链接，使客户端重新建立新的场链接。#大多数情况下QPS不是很高，100足够，但是对一些QPS高比如(10000QPS,甚至更高)100显的太低,#QPS=10000时候，客户端每秒发送10000个请求(通常建立长链接)，每个连接最多跑100次请求，意味着每秒就有100个长连接因此被nginx关闭。同样意味着为了保持QPS，客户端不得不每秒重新新建100个连接，从而导致大量TIME_WAIT的socket链接，因此对于QPS较高场景，很有必要加大这个设置，避免出现大量连接被生成在抛弃。#出现大量TIME_WAIT情况#nginx出现大量TIME_WAIT情况有两种#keepalive_request设置较小，高并发超过此值后nginx悔强制关闭客户端保存keepalive长连接；(主动关闭连接后导致nginx出现TIME_WAIT)#keeaplive设置比较小(空闲数小)，导致高并发nginx会平凡出现连接数抖动(超过该值会关闭连接)，不停关闭\开启和后端server保持的keepalive长连接#后端server端出现大量TIME_WAIT情况#nginx没有打开和后端长连接，即使设置proxy_http_version 1.1和proxy_set_header Connection "" ;从而导致后端server每次关闭连接，高并发出现server端大量TIME_WAIT。keepalive_disable none|browser;#禁止那些游览器不使用keepalive功能，如果keepalive_disable msie6，禁止ie6不使用keepalive功能client_body_buffer_size;#接受客户端请求报文body的缓存区大小，默认为16k，在32位系统上是8k，超出指定大小将移存在磁盘上client_body_temp_path [Level1 [level2 [level3]]]#设定与存储客户端请求body临时存放路径以及子目录结构和数量#例子client_body_temp_path /var/tmp 2 2;#说明椅子子目录使用2个字符表示,二级目录下用2字符表示,每级目录都有256个文件夹，采用16进制表示文件，1个字符最多表示16，2字符表示256 aio on;#是否启用异步IO模式,可用于HTTP,SERVER,LOCATION上下文，sendfile不能与AIO同时使用 directio SIZE|off;#当大于SIZE的时候是否直接IO操作,不存在内存缓冲,直接从硬盘加载使用，用于HTTP,SERVER,LOCATION上下文中 open_file_cache off | max=N [inactive=time];#对打开文件缓存.主要包括:文件描述符,文件大小,最近修改时间，目录结构，没有找到或者没有权限操作文件相关信息，#max=N,可缓存的最大条目上限,一旦达到上限, 则会使用LRU算法从缓存中删除最近最少使用的缓存项#inactive=time : 在此处指定的时长内没有被访问过的缓存项识别为非活动缓存项, 因此直接删除 open_file_cache errors on|off;#是否缓存找不到其路径的文件,或没有权限访问的文件相关信息 open_file_cache_valid TIME;#每隔多久检查一次缓存中缓存项的有效性,默认为60秒 open_file_cache_min_uses NUMBER;#缓存项在非活动其限内最少应该被访问的次数 UPSTREAMupstream模块可定义一个新的上下文，位于server之上http之下，包含一组upstream服务器，这些服务器可能被赋予不同权重，不同类型，设置可以基于维护原因被标记为down。 1234567891011121314151617181920212223242526272829303132333435363738http&#123; ...; upstream myserver &#123; service 192.168.1.10:8080 wight=5 max_fails=3 file_timeout=6; service 192.168.1.10:8090 wight=5 max_fails=3 file_timeout=6; service 192.168.1.20:8080 backup; service 192.168.1.30:8080 down; ip_hash; keepalive 300; &#125; service &#123; ..; location &#123; ..; &#125; &#125;&#125;upstream模块常用的指令有：round-robin#轮询发往后端默认为轮轮询ip_hash#基于客户端IP地址完成请求的分发，它可以保证来自于同一个客户端的请求始终被转发至同一个upstream服务器least_conn#最少连接调度算法keepalive#每个worker进程为发送到upstream服务器的连接所缓存的个数.server:定义一个upstream服务器的地址，还可包括一系列可选参数，如： weight： 权重； max_fails： 最大失败连接次数，失败连接的超时时长由fail_timeout指定； fail_timeout： 等待请求的目标服务器发送响应的时长； backup： 用于fallback的目的，所有服务均故障时才启动此服务器； down： 手动标记其不再处理任何请求； SERVER用于定义虚拟服务器相关的属性，位于http上下文，常见的指令有backlog、rcvbuf、bind及sndbuf等 12345678910111213141516171819202122232425262728293031323334....;http &#123; ....; upstream &#123; ...; &#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; root /www; location / &#123; ....; &#125;&#125;listen [:port] | [default_server] | [ssl] [http2 | spdy];#监听端口，如果有多块网卡可以使用listen 192.168.1.2:80#ssl 用于限制只能通过SSL连接提供服务，不是以端口确认其协议,需要启用SSL,需要在监听的端口后面, 添加ssl选项。#http2 支持http version2，需要在nginx编译时开启http2协议支持#spdy google研发的http协议，比http1.1性能好。全称speedy,在编译时编译了spdy模块情况下，用于支持spdy协议server_name localhost;#服务名称或者域名，支持正则表达式匹配*.baidu.com 或者 ~^.*.baidu.com$charset koi8-r;#字符集设置access_log PATH main;#日志路径，以及使用哪个日志格式root /www;#设置web资源路径映射,用于指明请求url所对应的文件目录路径,可用于server或者location中 LOCATION通常位于server上下文，用于设定某URI的访问属性，location也可以嵌套, 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657....;http &#123; ....; upstream &#123; ...; &#125; server &#123; ...; location / &#123; root html; index index.html; try_files index.html /images/test1.html; &#125; location /images/ &#123; alias /data/imgs/; &#125; error_page 404 /404.html; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125;root html;#定义url路径，这里是绝对路径，nginx下的html目录,当访问daemon.com/时候访问的是nginx下的html目录index index.html;#定义默认主页(nginx_http_index_module模块引入),可定义在http,server,locationtry_files $uri $uri/ /index.php?$args;#可用于server和location中,尝试查找第1到最后一个文件,如果第一个不存在跳转到下一个，必须确保最后一个存在,如果不存在则会导致死循环。alias /data/imgs;#只能用于location配置段,定义路径别名root和alias区别:location /imags/ &#123; root /data/imgs/;&#125;location /imags/ &#123; alias /data/imgs/;&#125;root指令:给定的路径对应location的"/",这个URI/imags/test.jpg --&gt; /data/imgs/imags/test.jpgalias指令:路径为对应的location的"/url/"这个URI/imags/test.jpg --&gt; /data/imgs/test.jpgerror_page code $uri;#定义错误页面，根据http状态码重写向错误页面#实例:error_page 404 /404.html;如果页面返回404就以404.html页面返回，状态码是404error_page 404 = /404.html;如果页面返回404就以404.html页面返回，状态码是200 location说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354location语法格式:location [ = | ~ | ~* | ^~ ] url &#123; ...&#125;= URI的精确匹配~ 做正则表达式匹配,区分字符大小写~* 做正则表达式匹配,不区分字符大小写^~ URI的左半部分匹配,不区分字符大小写!~,!~* 区分大小写不匹配，不区分大小写不匹配#允许根据用户请求的URI来匹配定义的各location,匹配到时, 此请求将被相应的location块中的配置所处理。#简言之:用于为需要用到专用配置的uri提供特定配置，当匹配多次时,其匹配优先级为:精确匹配=,^~,~或~*,不带符号的URL, 如果优先级都一样, 就匹配最精确的规则#优先级:location = / &#123; [configuration A]&#125;location / &#123; [configuration B]&#125;location /documents/ &#123; [configuration C]&#125;location ^~ /images/ &#123; [configuration D]&#125;location ~* \.(gif|jpg|jpeg)$ &#123; [configuration E]&#125;#例子:location ~ /\.ht &#123; deny all;&#125;#当访问.htaccess文件时候拒绝所有location ~ \.php$ &#123; root /xxx; fastcgi_pass 127.0.0.1:9000;&#125;#将所有php文件推送到php-fpmlocation ~ .*\.(gif|jpg|jpeg|png|bmp|swf|js|css)$ &#123; ...;&#125;#匹配gif|jpg|jpeg|png|bmp|swf|js|css结尾文件location 后面"/"和没有"/"的区别#看个例子如果域名是www.zhuxyid.com,访问www.zhuxyid.com/helloworl的话location /hello &#123; #这里能匹配到 root xxx;&#125;location /hello/ &#123; #这里则不能匹配 root xxx;&#125; Nginx If判断在location中使用if语句可以实现条件判断，其通常有一个return语句，且一般与有着last或break标记的rewrite规则一同,防盗链模块使用。但其也可以按需要使用在多种场景下，需要注意的是，不当的使用可能会导致不可预料的后果。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#if语句中的判断条件#正则表达式匹配： ~ 与指定正则表达式模式匹配时返回“真”，判断匹配与否时区分字符大小写； ~* 与指定正则表达式模式匹配时返回“真”，判断匹配与否时不区分字符大小写； !~ 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时区分字符大小写； !~* 与指定正则表达式模式不匹配时返回“真”，判断匹配与否时不区分字符大小写；#文件及目录匹配判断： -f, !-f 判断指定的路径是否为存在且为文件； -d, !-d 判断指定的路径是否为存在且为目录； -e, !-e 判断指定的路径是否存在，文件或目录均可； -x, !-x 判断指定路径的文件是否存在且可执行； #例子:http &#123; upstream imageserver&#123; server 192.168.0.10:80; server 192.168.0.11:81; &#125; server &#123;&#125; location / &#123; if ($request_method == “PUT”) &#123; #如果客户端方法是PUT,就代理到0.11上，有点读写分离的感觉。 proxy_pass http://192.168.0.11:8021; &#125; if ($request_uri ~ "\.(jpg|gif|jpeg|png)$") &#123; proxy_pass imageservers; break; &#125; &#125; &#125;实例:#cookie首部检测匹配if ($http_cookie ~* "id=([^;]+)(?:;l$)") &#123; set $id $1;&#125;#请求报文的请求方法是POST,返回405if ($request_method = POST) &#123; return 405;&#125;#限速if($slow) &#123; limit_rate 10k; break;&#125;#非法引用,返回403,注:也可以对非法引用到其它页面if($invalid_referer) &#123; return 403;&#125;#根据IE类型重写if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;returncode [text];returncode URLreturn URL;#return:立即停止对请求的URI的处理,并返回指定的状态码set $variable value;#set:设定变量值,或者自定义变量rewrite_log on | off;#是否将重写日志记录errorlog中,默认为关闭(调试方法:错误日志debug,并开启rewrite_log) Nginx全局变量1234567891011121314151617181920212223$args$content_length$content_type$document_root$document_uri$host$http_user_agent$http_cookie$limit_rate$request_body_file$request_method$remote_addr$remote_port$remote_user$request_filename$request_uri$query_string$scheme$server_protocol$server_addr$server_name$server_port$uri Nginx反向代理Nginx通过proxy模块实现反向代理功能。在作为web反向代理服务器时，nginx负责接收客户请求，并能够根据URI、客户端参数或其它的处理逻辑将用户请求调度至上游服务器上(upstream server)。nginx在实现反向代理功能时的最重要指令为proxy_pass，它能够将location定义的某URI代理至指定的上游服务器(组)上。 反向代理：正对外部网络，如果客户端访问某个网站，但该网站不提供页面，只把请求代理只后端，在从后端返回至代理，在响应给客户端，该代理称作反向代理。 正向代理：针对内部网络，如果客户端不能访问外网，需要设置通过某台机器代理至外网，外网结果返回至代理机，在返回给客户端，该代理称作正向代理。 透明代理：针对内部网络，不需要设置任何代理服务器地址，但是需要将网关指向代理服务器。 参考：Nginx proxy中文文档 proxy模块指令proxy模块的可用配置指令非常多，它们分别用于定义proxy模块工作时的诸多属性，如连接超时时长、代理时使用http协议版本等.下面对常用的指令做一个简单说明。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556proxy_pass [domain | ip | upstream_name]|:PORT;#将location代理到哪里，这里可以是域名,IP,upstream名称，可以加端口，应用于Location上下文#这里值得注意:#当proxy_pass后有"/"时候，相当于绝对根路径，不会将location 中匹配的路径代理走#当proxy_pass后没有"/"时，会把location中部分路径代理走#示例:#访问:http://www.aaa.com/abc/index.html,配置如下location /abc/ &#123; proxy_pass http://127.0.0.1:8080/;&#125;#会代理到:http://127.0.0.1:8080/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080;&#125;#会代理到:http://127.0.0.1:8080/abc/index.htmllocation /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev;&#125;#会代理到: http://127.0.0.1:8080/devindex.html;localtion /abc/ &#123; proxy_pass http://127.0.0.1:8080/dev/;&#125;#会被代理到: http://127.0.0.1:8080/dev/index.html;proxy_pass_header field;#传递头部给后端服务器proxy_hide_header field;#设定发送给客户端的报文中需要隐藏的首部proxy_set_header field value;#用于向后端服务器发请求报文时，将某请求首部重新赋值，或在原有值后面添加一个新的值#示例:proxy_set_header HOST $http_host;#将$http_host传递给HOST变量, 在nginx向后端发请求时,加入HOST首部proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;#将客户端的真实IP地址赋值给X-Forwarded-For变量，在nginx想后端发时加入X-Forwarded-For变量，#如果中间有多层代理，每经过一层代理时,代理服务器都会将在后面增加自己的IP地址，并以分号分隔proxy_redirect;#重写location并刷新从后端收到报文首部proxy_connect_timeout;#nginx将一个请求发送到后端之前等待最大时长proxy_send_timeout;#在连接断开之前两次发送到后端的写操作的最大间隔时长proxy_rend_timeout;#在连接断开之前两次发送到后端接受操作的最大间隔时长proxy_cookie_domain;#发往后端时SET-COOKIE首部设定的domain属性修改为指定的值，可以设置为字符串,正则表达式模式或者一个引用变量proxy_cookie_path;#发送后端时通过SET-COOKIE首部设定的PATH属性修改为指定的值 proxy缓冲nginx在默认情况下在将其响应给客户端之前会尽可能地接收来upstream服务器的响应报文，它会将这些响应报文存暂存于本地并尽量一次性地响应给客户端。然而，在来自于客户端的请求或来自upsteam服务器的响应过多时，nginx会试图将之存储于本地磁盘中，这将大大降低nginx的性能。因此，在有着更多可用内存的场景中，应该将用于暂存这些报文的缓冲区调大至一个合理的值。 12345678proxy_buffer_size size#设定用于暂存来自于upsteam服务器的第一个响应报文的缓冲区大小；proxy_buffering on|off;#启用缓冲upstream服务器的响应报文，否则，如果proxy_max_temp_file_size指令的值为0，来自upstream服务器的响应报文在接收到的那一刻将同步发送至客户端；一般情况下，启用proxy_buffering并将proxy_max_temp_file_size设定为0能够启用缓存响应报文的功能，并能够避免将其缓存至磁盘中；proxy_buffers 8 4k|8k#用于缓冲来自upstream服务器的响应报文的缓冲区大小； proxy缓存nginx做为反向代理时，能够将来自upstream的响应缓存至本地，并在后续的客户端请求同样内容时直接从本地构造响应报文。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162proxy_cache_path PATH [levels=levels] keys_zone=name:size [inactive=time][max_size=size];#定义缓存，设置缓存名称，缓存路径，缓存大小等。只能用于HTTP上下文#实例:proxy_cache_path /data/nginx/cache/img levels=1:2:1 keys_zone=my_img:20m max_size=10g;#levels=1:2:1 #表示一级目录1个字符,二级目录2个字符,三级目录1个字符,最多只能设置3级#keys_zone=my_img:20m #存储键区域大小#max_size=1g #/img目录空间上限1G，当缓存对象超出时候,采用LRU清理，谁用的少清理谁#inactive #非活动缓存项从缓存中剔除之前的最大缓存时长#loader_files #缓存加载器每次工作过程最多为多少个文件加载器#loader_sleep #缓存加载器的每次迭代工作后的睡眠时长#loader_threashold #缓存加载器的最大睡眠时长proxy_cache NAME;#调用设置的缓存名称，必须实现设定好缓存proxy_cache_lock#在缓存未命中阻止多个相同的请求同时发往后端，其生效范围是worker级别proxy_cache_lock_timeout#proxy_cache_lock功能锁定时长proxy_cache_min_uses#某响应报文被缓存之前至少应该被请求次数proxy_cache_use_stale#在无法连到upstream服务器时候那种情况(error，timeout，http_500)让nginx本地缓存过期的缓存对象之间响应给客户端#实例proxy_cache_use_stable error|timeout|invalid_header|updating|http_50[1~4]|http_404|offproxy_cache_valid#用于为不同响应设定不同时长的有效缓存时长#实例proxy_cache_valid 200 302 10m;#设定状态为200和302的缓存时长为10分钟proxy_cache_methods [GET|POST|HEAD];#为那些方法启用缓存功能.proxy_cache_bypass STRING;#设置那种情况下，nginx不从缓存读取数据#实例proxy_cache_bypass $cookie_nocache $arg_nocache $arg_comment;proxy_cache_bypass $http_pragma $httpp_authorization;#配置实例http &#123; proxy_cache_path /data/nginx/cache levels=1:2:1 keys_zone=MYHTML:10m inactive=24h max_size=1g; upstream my_web &#123; server 172.16.0.2:8080; server 172.16.0.2:8081; &#125; server &#123; location / &#123; proxy_pass http://my_web; proxy_set_header Host $host; proxy_cache MYHTML; proxy_cache_valid 200 1d; proxy_cache_valid 301 302 10m; proxy_cache_vaild any 1m; &#125; &#125;&#125; Nginx常用模块nginx-limit模块 ngx_http_core_module，ngx_http_limit_conn_module，ngx_http_limit_req_module中的limit相关参数 123456789101112131415161718192021222324limit_except METHOD &#123;...&#125;;#对指定范围之外的其它方法进行访问控制,应用于location上下文#例子limit_except GET &#123; allow 172.16.0.0/16; deny all;&#125;limit_rate SPEED;#限制客户端每秒种所能够传输的字节数, 默认为0,表示不限制,应用于http,server,location,if in location上下文中#例子server &#123; if ($slow) &#123; set $limit_rate 4k; &#125;&#125;limit_rate_after SIZE;#超出SIZE的值, 就限制速度,应用于http,server,location,if in locataion上下文中#例子location /flv/ &#123; limit_rate_after 500k; limit_rate 50k;&#125; 访问控制12345678910111213141516#allow和deny可用于http，server，location上下文中allow address | CIDR | UNIX | ALL;#允许那些地址可以是网络地址deny address | CIDR | UNIX | ALL;#拒绝，同上例子:location / &#123; allow 172.16.0.2; allow 192.168.1.0/24; allow 2018:abc8::22; deny 172.16.0.1; deny all;&#125; 基本认证模块1234567891011auth_basic STRING;#定义认证名称,主要是提示作用.认证时显示提示信息auth_basic_user_file FILE;#用户认证的用户账号文件#格式:user1:pwd1user2:pwd2#也可以直接使用httpd程序提供的htpasswd生成#htpasswd -c -m /www/.htpasswd user1#&gt;pwd输入密码 自定义头信息12345678add_header_name value [always]#向响应报文添加自定义首部，并为其赋值,应用上下文为http,server.localtion中#例子add_hreader Via $server_addrexpires [modified] time;expires epoch | max | off#允许或者禁止向响应报文的cache-control或者expires首部添加新值或修改其值 nginx状态功能1234567891011121314151617181920#stub_statu功能,编译时添加--with-http_stub_status_module选项#实例location /my_ngx_monitor &#123; stub_status on; allow 172.16.0.100; deny all;&#125;#访问http://www.zhuxyid.com/my_ngx_monitorActive connections: 1server accepts handled requests2 2 18Reading: 0 Writing: 1 Waiting: 0#active connections:当前活动客户端连接数(包括等待)#accepts:已接受客户端连接总数量#handled:已处理完成的客户端连接请求总数量#requests:客户端总的请求数#reading:当前正在读取客户端请求报文首部信息的数量#writing:当前正在向客户端发送响应报文的链接数量#wating:长连接模式的保持连接个数,或者活动连接个数(reading+writing) nginx防盗链模块基于请求报文中的referer首部的值, 做访问控制 ,可以防止盗链,其只应用于server,location上下文 123456789101112131415161718referer_hash_bucket_size SIZE;#可以放多个缓存我要上,默认是64referer_hash_max_size SIZE;#默认2048valid_referers none|blocked|server_names|string...;#none : 请求的报文不存在referer首部#blocked : 请求报文中存在referer首部,但其没有有效值,或其值非以http://或https开头#server_names :其值为一个主机名#arbitrary string : 直接字符串,可以使用*号匹配#rugular expression : 以~起始的正则表达式#注意: 内置变量:$invalid_referer(所有不能符合valid_referer指定定义的引用请求均为不合法引用),需要加上条件判断语句#示例:valid_referers none blocked server_name *.example.com example.* www.example.org/aglleries/ ~\.google\.;if ($invalid_referer) &#123; return 403;&#125; nginx重写模块将请求的url基于正则表达式进行重写(URL重定向), 在如下情况下可以使用: http转换成httpd服务(http —- https) 域名转换domain.tld —-domain2.tld, URL转换uri1—-url2 1234567891011121314151617181920rewrite regex replacement [flag];#应用于server,location,if上下文regex:基于PERL的正则表达式,用于匹配用户请求的URL;replacement:重写重定向的结果flag:标志位[last|break|redirect|permanent]#regex:PCRE正则表达式元字符: 字符: .,[],[^] 次数: *,+,?,&#123;m&#125;,&#123;m,&#125;&#123;m,n&#125; 位置锚定: ^,$ 或者: | 分组: (), 后向引用: 2,…..#flag:last #重写完成之后停止对当前uri的进一步处理,改为对新uri的新一轮处理(对URI的重写规则进行匹配,当检查到第一条匹配到的时候,进行重写.然后返回到重写规则的第一条位置进行重新匹配,如果有匹配到的再进行重写,默认只能10次匹配). 此过程用户端感受不到.break #对URI的重写规则进行匹配,只要匹配到就重写,不再进行再次匹配,此过程用户端感受不到.redirect #重写完成之后返回客户端一个临时重定向,由客户端对新的URI重新发起请求, 即302的状态码permanent #重写完成之后,会返回客户端一个永久的重写向,由客户端对新的URI重新发起请求,即301的状态码 nginx ssl12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485listen 443;#监听端口server_name www.zhuxyid.com;#ssl主机的FQDN名称ssl_certificate cert.pem;#ssl的公钥ssl_certificate_key cert.key;#ssl的私钥ssl on | off;#启用或关闭ssl,若不在listen处定义，也可以在server&#123; &#125;中定义ssl on; 来启用https服务ssl_session_cache off | none | [builtin[:size]] [shard:name:size];#默认使用shared模式#off : 禁止缓存 ,关闭缓存,不支持缓存功能#none :禁止缓存 ,不响应缓存#builtin : 使用openssl内置的ssl会话缓存 ,此机制为各worker私有#shared: 在各worker之间使用一个共享的缓存,name:独有名称,size:缓存空间大小, 默认为1M,可以调到10M示例: ssl_session_cache shared:ssl:1m;ssl_session_timeout 5m;#ssl会议超时时长,即ssl session cache中的缓存有效时长,默认为5mssl_protocols [sslv2][sslv3][tlsv1][tlsv1.1][tlsv1.2];#使用哪些协议版本, 默认为TLSv1,TLSv1.1,TLSv1.2#ssl_protocols SSLv2 SSLv3 TLSv1;ssl_ciphers HIGH:!aNULL:!MD5;ssl_ciphers CIPHERS#nginx使用的加密算法ssl_prefer_server_ciphers on;#依赖SSLv3和TLv1协议的服务器密码将优先于客户端密码ssl_buffer_size SIZE;#ssl缓冲大小ssl_client_certificate file;#需要验证客户端证书ssl_crl FILE;#证书吊销列表ssl_trusted_certificate FILE;#信任的根证书#配置实例a.创建系统私钥(umask 077; openssl genrsa 2048 &gt; /PATH/cakey.pem)b.生成系统自签证书openssl req -new -x509 -key /PATH/cakey.pen -out cacert.pem一次输入:CN,JS,NJ,zhuxyid,it,ca.zhuxyid.com,caadmin@zhuxyid.comc.创建serial index.txtecho 01 &gt; serial &amp; touch index.txt &amp; cd nginx/ssl/d.创建私钥(umake 077;openssl genrsa 1024 &gt; nginx.key)openssl req -new -key nginx.key -out nginx.csr依次输入:CN,JS,NJ,zhuxyid,it,www.zhuxyid.comopenssl ca -in nginx.csr -out nginx.crt -days 3650more nginx.confserver &#123; listen 443; server_name www.zhuxyid.com; ssl on; ssl_certificate /ssl/nginx.crt; ssl_certificate_key /ssl/nginx.key; ssl_session_timeout 5m; ssl_protocols SSLv2 SSLv3 TLSv1; ssl_ciphers HIGH:!aNULL:!MD5; listen 443; location / &#123; root html; index index.html index.htm; &#125;&#125;/usr/local/nginx/sbin/nginx -s reload#这里只是测试用,如果是外网需要向权威机构申请证书，freessl.org nginx压缩模块123456789101112131415161718192021222324gzip on|off#开启压缩,通常位于http上下文gzip_comp_level [1-9]#压缩比率，默认为1，越大越占用cpu使用率gzip_types mine.types#指名对那些类型资源进行压缩gzip_disable msie6;#根据游览器来设置是否压缩，这里是ie6不开启压缩gzip_min_length 0#设置允许压缩页面最小字节数，页面字节从header头中的content-length获取，默认值0，不管页面多大都会被压缩，通常设置大于1k字节，小于1k可能越压越大，比如本身10字节，压缩一下反而大了，噗噗噗#实例:http &#123; gzip on; gzip_comp_level 6; gzip_disable msie6; gzip_types text/plain text/css text/xml application/x-javascript application/xml application/json application/java-script; gzip_min_length 2;&#125; 小结 对于nginx模块还有很多很多，以上是最基础的一些安装配置说明，后期还需要总结关于nginx的一些奇淫技巧]]></content>
      <categories>
        <category>Web Service</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile]]></title>
    <url>%2F2018%2F11%2F26%2FDockerfile%2F</url>
    <content type="text"><![CDATA[关于Docker基础,请看http://blog.zhuxyid.com/2018/11/23/Docker 自制镜像方式​ 基于容器方式来制作镜像，这种方法配置繁琐,不适合使用,每次配置文件更该都需要制作镜像 ​ 基于Dockerfile DockerfileDockerfile是一个文本文档，包含用户可以在命令行上调用命令组合，使用docker build用户可以自动构建一个连续执行多个命令行 Dockerfile编译完成科研使用docker build来进行编译Dockerfile文件 1docker build -t IMAGE_NAME:TAGS /DOCKERFILE_PATH/Dockerfile Dockerfile注意事项12345Comment #注释 INSTRUCTION arguments #指令 参数(指令不区分大小写，约定惯例尽量使用大写) docker运行指令是按照你的指令的顺序。Dockerfile文件首字母必须是大写 .dockeringore定义忽略哪些文件，打包时不包含这些文件 Dockerfile语法FROMFROM指令是最重的 一个且必须为Dockerfile文件开篇的第一个非注释行, 用于镜像文件构建过程 指定基准镜像，后续的指令运行于 此基准镜像 所提供的运行环境 实践中，基准镜像可以是任何可用镜像文件，默认情况下，docker build会在docker主机上查找指定的镜像文件，其不存在时，则会从Docker hub registry拉去所需的镜像文件 (如果找不到指定的镜像文件，docker build会返回一个错误信息) 123456789语法:FROM &lt;repository&gt;[:&lt;tag&gt;]FROM &lt;repository&gt;@&lt;digest&gt; @digest指定hash码进行验证 &lt;repository&gt;:指定作为base image的名称 &lt;tag&gt;:base image的标签 可选性，默认是latest例子:# Description: test imgFROM busybox:latest MAINTANIER用于让dockerfile制作者提供信息，Dockerfile并不限制MAINTAINER指令可在出现的位置，但推荐放在FROM指令后 1234567891011语法:MAINTAINER &lt;authtor's detail&gt;&lt;authtor's detail&gt; 可以是任何文本信息，但是通常使用名称和地址邮箱例子:MAINTAINER "zhuxyid &lt;zhuxyid@gmail.com&gt;"LABLE:指定镜像元数据Syntax:LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;例子: LABEL maintainer="zhuxyid &lt;zhuxyid@gmail.com&gt;" COPY用于从Docker主机复制文件到创建的新镜像文件 1234567891011121314语法：COPY &lt;src&gt;&lt;dest&gt;COPY ["&lt;src&gt;",.."&lt;dest&gt;"] 如果路径有空白字符时候，用这种方式复制 src 源文件，支持使用通配符 dest 目标路径 即正在创建image文件系统路径,建议&lt;dest&gt;为绝对路径，否则COPY指定则以WORKDIR为起始路径文件复制准则:&lt;src&gt; 必须是build上下文中路径，不能是父目录的文件如果&lt;src&gt;是目录，则 内部文件或子目录都会 被递归复制,但&lt;src&gt;自身目录不会被复制 相当于 cp -r src/* /dest如果指定了多个&lt;src&gt;，或在&lt;src&gt;中使用通配符，则&lt;dest&gt;必须是一个目录，且必须以/结尾 相当于 cp -r src/* /desc/如果&lt;dest&gt;不存在，则会被自动创建，这包括其父目录路径例子：COPY index.html /data/web/html/ #这里index.html文件必须先创建，而且必须为build目录下！ ADDADD指令类似COPY指令，ADD支持使用TAR文件和URL路径 1234567891011语法:ADD &lt;src&gt;,..&lt;dest&gt;ADD ["&lt;src&gt;",.."&lt;dest&gt;"]操作准则: 同COPY指令 如果&lt;src&gt;为URL且&lt;dest&gt;不以/结尾，则&lt;src&gt;指定的文件将被下载并直接创建为&lt;dest&gt;; 如果&lt;dest&gt;以/结尾,则文件名URL指定文件将被直接下载并保持为&lt;dest&gt;/&lt;filename&gt; 如果&lt;src&gt;是一个本地系统上的压缩格式tar文本，他将被展开为一个目录，其行为类似"tar -x"命令，然而通过URL获取到的tar文件将不会自动展开 如果&lt;src&gt;有多个，或其间接或直接使用通配符，则&lt;dest&gt;必须是一个以/结尾的目录路径； 如果&lt;dest&gt;不以/结尾，则其被视作一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dest&gt; WORKDIR用于为Dockerfile中所有的RUN,CMD,ENTRYPOINT,COPY和ADD指定设定工作目录 12345678语法:WORKDIR &lt;dirpath&gt; 在Dockerfile文件中，WORKDIR指定可出现多次，其路径也可以为相对路径，不过其是相对此前一个WORKDIR指令指定的路径,另外，WORKDIR也可以调用由ENV指定定义的变量例子：WORKDIR /var/logWORKDIR $STATEPATH VOLUME用于在image中创建一个挂载点目录,以挂载Docker host上的卷或其他容器上的卷 1234语法:VOLUME &lt;mountpoint&gt;VOLUME ["&lt;mountpoint&gt;"]如果挂载点目录路径下此前在文件存在，docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 EXPOSE用于为容器打开指定要监听的端口以实现与外部通讯,注意，这里只能是定义容器的端口.后期docker下载下来宿主机的端口并不确定 123456789语法：EXPOSE &lt;port&gt; [/&lt;protocol&gt;][&lt;port&gt;[/&lt;protocol&gt;]...] &lt;protocol&gt;用于指定传输层协议，可为tcp或udp二者之一，默认为TCP协议EXPOSE指令可一次指定多个端口，如EXPORT 11211/udp 11211/tcpdocker run --name ttt -P 可以自动暴露需要暴露的端口 ENV用于为镜像定义所需的环境变量，并可被Dockerfile文件中位于其后的其他指令(如ENV,ADD,COPY等)所调用 WORKDIR只是工作目录 调用格式为$variable_name或者${variable_name} 123456789语法:ENV &lt;key&gt;&lt;value&gt;ENV &lt;key&gt;=&lt;value&gt;$&#123;NAME:-tom&#125; #如果NAME变量没有值，将他设为tom，如果有值则使用本身$&#123;NAME:+tom&#125; #如果NAME为空则不设置，如果不为空则设置tom第一种格式中,&lt;key&gt;之后的所有内容均被视作其&lt;value&gt;的组成部分，因此，一次只能设置一个变量第二种格式中,可用一次设置多个变量，每个变量为一个&lt;key&gt;=&lt;value&gt; 的键值对，如果&lt;value&gt;中包含空格，可用反斜线(\)进行转移;也可以通过对&lt;value&gt;加引号进行标识,另外反斜线可以续行定义多个变量时,建议使用第二种方式,以便在同一层中完成所有功能 RUN用于指定docker build过程中运行的程序，其可以是任何命令 123456789语法:RUN &lt;command&gt;RUN ["&lt;executable&gt;","&lt;param1&gt;","&lt;param2&gt;"]第一个格式中,&lt;command&gt;通常是一个shell命令，且以“/bin/sh -c”来运行它，这意味着此进程在容器中的PID不为1，不能接受Unix型号，因此，当使用docker stop container命令停止容器时，次进程接受不到SIGTERM信号第二个格式中，参数就是一个JSON格式的数组，其&lt;executable&gt;为运行的命令，后面的&lt;paramN&gt;为传递给命令的选项或参数；然而此格式指定的命令不会以"/bin/sh -c"来发起；因此常见shell操作，如变量替换以及通配符(?,*等)替换将不会进行；不过如果要运行的命令依赖次shell特性的话，可以将其替换为类似下面格式RUN ["/bin/bash","-c","&lt;excutable&gt;","&lt;param1&gt;"] CMD类似RUN指令，CMD指令也可以用于运行任何命令或应用程序，不过二者运行时间点不同 RUN 指令运行与镜像文件构建过程，而CMD指令运行基于Dockerfile构建出的新映像文件启动一个容器时 CMD 指定的首要 目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器将终止；不过CMD指令的命令其可以被docker run的命令选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅是最后一个会生效，而RUN不是 1234567语法:CMD &lt;command&gt;CMD ["&lt;excutable&gt;","&lt;param1&gt;","&lt;param2&gt;"]CMD ["&lt;param1&gt;","&lt;param2&gt;"]前两种语法格式的意义相RUN第三种则用于为ENTRYPOINT指令提供默认参数 RUN 是运行在docker build过程中的命令，而CMD 是在docker run运行时的命令 注意:一个容器只是用于单个应用。nginx,redis,mysql都是运行在后台 所有进程都是一个进程的子进程，除了init。init是内核启动 比如手动启动nginx，它是shell的子进程，有些shell子经常会占据终端窗口，需要加&amp;符号 nginx &amp; 这里nginx父进程依然是shell，当shell结束后，会将nginx也结束 nohup nginx &amp; 这里是将nginx送到后台，重新赋予一个新的进程，这是shell退出这个依然存在 在用户空间先启动shell,才能使用ls，cat，等命令，可以直接exec执行命令. 在容器中可以基于shell启动程序，也可以通过exec启动程序 在json数组中，引号一定要写双引号，单引号可能会出现问题 ENTRYPOINT类似CMD指定的功能，用于为容器指定默认运行程序，从而使得容器像一个单独的可执行程序 于CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令指定的参数所覆盖，而且，这些命令参数会被当做参数传递给ENTRYPOINT指定指定的程序 不过,docker run命令的–entrypoint选项参数可覆盖ENTRYPOINT指令指定的程序 12345678910111213141516171819202122语法:ENTRYPOINT &lt;command&gt;ENTRYPOINT [&quot;&lt;executable&gt;&quot;,&quot;&lt;param1&gt;&quot;,&quot;&lt;param2&gt;&quot;]ENTRYPOINT /bin/http -f -h /data/www/htmldocker run命令传入的命令参数会覆盖CMD指令的内容并且附加到EMTRYPOINT命令最后作为其参数使用Dockerfile文件中可用存在多个ENTRYPOINT指令，但仅最后一个生效如果Dockfile格式是这样CMD和ENTRYPOINT同时存在CMD [&quot;/bin/httpd&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;]CMD /bin/httpd -h /data/web/html #这样写会出错，因为不会被当成参数，需要写成列表的形式ENTRYPOINT /bin/httpd -f -h /data/web/html #如果需要CMD传参，这里建议写成列表，不然有问题CMD和ENTRYPOINT同时存在，那么CMD会将命令变成参数传递给ENTRYPOINT例子CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/web/html&quot;] ENTRYPOINT [&quot;/bin/sh&quot;,&quot;-c&quot;]#CMD将传给ENTRYPONT作为默认参数#如果执行docker run --name ttt --rm image:v1 &quot;ls /data&quot;#&quot;ls /data&quot;则会覆盖CMD#如果执行docker run --name ttt --entrypoint &quot;ls&quot; --rm image:v1 &quot;/data&quot;#ls会覆盖EXTRYPOINT,/data覆盖CMD USER用于指定运行image时或者运行Dockerfile中任何RUN,CMD或者ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下, container运行身份是root用户. 123语法USER &lt;UID&gt;|&lt;USERNAME&gt;需要注意:&lt;UID&gt;可以是任意数字，但实践中必须为容器中/etc/passwd中某用户的有效UID,否则docker run会失败 HEALTHCHECK健康状态检查，判断容器里面的程序是否正常运行. 这里需要注意，如果nginx指定的目录不存在，nginx也会运行，但是用户访问是访问不了的，可以断定这虽然是可以运行但不是想要的结果，比如使用curl检测网页200的信息，如果是200则正常，非200则不正常 123456789101112131415HEALTHCHECK定义一个CMD来检测容器中主进程工作状态与否 HEALTHCHECK NONE 拒绝任何监控状态检查格式: HEALTHCHECK [OPTION] CMD --interval=DURATION(default:30s) 每隔多久 --timeout=DURATION(default:30s) 超时时长 --start-period=DURATION(default:0s) 等待主进程初始化完成在检查，如果tomcat这种应用建议等待5秒 --retries=N(default:3) 检查次数，默认3次#检测状态结果：0:success1:unhealthy2:reserved实例:HEALTHCHECK --interval=5m --timeout=3s CMD curl -f http://localhost/ || exit 1 #每隔5分钟检查，超时时间3s，curl结果如果成功则不管他，如果不成功则返回1 SHELLlinux默认shell是[“/bin/sh”,”-c”] windows默认是[“cmd”,”/S”,”/C”] 格式：SHELL [&quot;/bin/bash&quot;,&quot;-c&quot;] STOPSIGNAL定义停止的信号，默认是15 格式: STOPSIGNAL 14可以修改停止的信号 ARGARG的参数只是一个变量，只在docker build时候使用，在--build-arg &lt;varname&gt;=&lt;value&gt; 12345678910111213141516语法：ARG &lt;name&gt;[=&lt;default value&gt;]ARG version=1.14ARG user=zhuxyid例子:FROM:nginx:$&#123;version&#125;ARG version=1.15LABEL maintainer=$&#123;author&#125;ARG version=&quot;1.15&quot;ARG author=&quot;zhuxyid &lt;772931883@qq.com&gt;&quot;docker build -t nginx ./docker build --build-arg &quot;version=1.16&quot; --build-arg &quot;author=zhuxyid&lt;hello@qq.com&gt;&quot; -t nginx ./ #可以直接在编译时候使用在docker build中可以用--build-arg参数来传值 ONBUILD用于在Dockerfile中定义一个触发器 Dockerfile用于build映像文件,此映像文件亦可作为base image被另一个Dockerfile作用FROM指令的参数，并以之构建新的映像文件 在后面的这个Dockerfile中FROM指令在build过程中被执行，将会”触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 12345678910111213141516语法:ONBUILD &lt;INSTRUCTION&gt;#尽管任何指令都可注册成触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM和MAINTAINER指令#使用包含ONBUILD指令的Dockerfile构建的镜像应该使用特殊的标签，例如ruby:2.0-onbuild#在ONBUILD指令中使用ADD或者COPY要格外小心，因为新构建过程中的下下文在缺少指定源文件会失败例子:cat /dockerfile/baseFROM centos:latestONBUILD RUN yum install nginx gcc gcc-c++#docker build -t base.img ./ #这里并不去安装nginx gcc gcc-c++cat /dockerfile/phpprojectFROM base.img #指定基于刚才创建的base.img作为base imageRUM yum install php-5.6#docker build -t php:v1 ./ #这里才会去安装， Example1234567891011121314151617181920212223242526272829303132333435363738394041424344mkdir /data/container/web1 cp -r /etc/yum.repos.d /data/container/web1/ cd /data/container/web1 wget &lt;http://mirror.bit.edu.cn/apache/tomcat/tomcat-7/v7.0.90/bin/apache-tomcat-7.0.90.tar.gz&gt; #more Dockerfile #Description: test dockerfile FROM busybox:latest LABEL maintainer=&quot;zhuxyid &lt;zhuxyid@gmail.com&gt;&quot; ENV DOC_ROOT /data/web/html/ #定义DOC_ROOT变量 ENV TOMCAT_ROOT=/data/tomcat/ \ #定义多个变量 TOMCAT_VERSION=&quot;tomcat-7.0.90&quot; \ NGINX_VERSION=&quot;nginx-1.14.0.tar.gz&quot; COPY index.html $DOC_ROOT COPY yum.repos.d /etc/yum.repos.d/ WORKDIR /opt/ADD http://nginx.org/download/nginx-1.14.0.tar.gz ./ VOLUME /data/www ADD apache-$&#123;TOMCAT_VERSION&#125;.tar.gz $&#123;TOMCAT_ROOT:-/data/tomcat/&#125; EXPOSE 80/tcp RUN cd /opt &amp;&amp; \ tar xf $&#123;NGINX_VERSION&#125; &amp;&amp; \ mv nginx-1.14.0 /usr/local/nginx #建议使用一条命令，因为如果多个RUN 那么层级就会越多 echo &quot;this is docker build image&quot; &gt; index.html docker build -t zhuxyid/index:v1 ./#-t指定name:tagdocker run --name web1 -it --rm zhuxyid/index:v1 cat /data/web/html/index.html #查看web1容器中/data/web/html是否有文件index docker run --name webserver --rm -P zhuxyid/index:v1 httpd -f -h /data/web/html docker port webserver docker run --name ttest --rm -P zhuxyid/index:v1 printenv#prinenv查看环境变量 #注意在启动容器的时候可以重新设置环境变量 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 printenv #在初始化容器时候可以重新赋值 docker run --name test --rm -P -e TOMCAT_VERSION=&quot;tomcat-8.0&quot; zhuxyid/index:v1 ls /data/tomcat/apache-tomcat-7.0.90.tar.gz #这里只是重新赋值变量并不能修改image，因为这是docker build中已经生成了]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>DevOps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker]]></title>
    <url>%2F2018%2F11%2F23%2FDocker%2F</url>
    <content type="text"><![CDATA[容器是什么 容器是一种基础工具，泛指任何可以用于容纳其他物品的工具，可以部分或完全封闭，被用于容纳，存储，运输物品；物体可以被放置在容器中，而容器可以保护内容物. 虚拟化技术有哪些主机级别 虚拟化 完全 虚拟化：Vmware，Kvm，Xen 半 虚拟化：Xen,UML Xen如果CPU不支持虚拟化技术那就是半虚拟化，如果支持就是全虚拟化 半虚拟化：修改内核，通过被虚拟化出来的操作系统它是运行在虚拟化技术软件上的，虚拟化出来的操作系统执行的进程还是运行在真实机器上 完全虚拟化：不需要修改内核，直接通过虚拟机化技术软件上运行的操作系统。 容器级别 虚拟化 LXC,OpenVz,Solaris Containers,FreeBSD jails LXC(LinuX Container)容器是内核虚拟化技术,可以提供轻量级的虚拟化,以便隔离进程和资源,不需要提供指令解释机制以及全虚拟化的其他复杂性.容器可以有效的将单个操作系统管理的资源划分到孤立的组件中,以便更好的孤立组之间的平衡有冲突的资源使用需求。 早期容器应用在jail中,后来移植到linux中vserver(chroot),chroot所隔离仅仅只是看上去的,并没有真正隔离。 Linux namespace 是linux提供一种内核级别环境隔离的方法，有6种不同名称空间: linux namesapce: namespace 系统调用参数 隔离内容 内核版本 UTS CLONE_NEWUTS 主机名和域名 2.6.19 MOUNT CLONE_NEWNS 挂载点(文件系统) 2.4.19 IPC CLONE_NEWIPC 信号量,消息队列,共享内存 2.6.19 PID CLONE_NEWPID 进程变化 2.6.24 USER CLONE_NEWUSER 用户和用户组 3.8 NETWORK CLONE_NEWNET 网络设备,网络栈,端口等 2.6.29 Docker是什么Docker是LXC增强版,Docker简化容器使用难度,通常一个容器中只运行一个进程. 对开发来说带来极大便利,分发容易,一次编写到处运行 然而对运维来说(有优点有缺点), 对开发极大便利需要运维干什么? Docker安装环境说明: 操作系统发行版:CentOS7.4 内核版本:3.10+ 安装说明: 使用yum方式安装,下载国内docker的yum源,加速下载. 安装过程:12345wget -P /etc/yum.repos.d/ https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i s@https://download.docker.com/@https://mirrors.tuna.tsinghua.edu.cn/docker-ce/@g /etc/yum.repos.d/docker-ce.repoyum repolist | grep docker-ceyum install docker-cesystemctl start docker.service 此时docker已经启动了，现在我们来搞清楚什么是docker Docker架构c/s架构，由三个组件（Docker Daemon,Docker Client,Docker Registry）构成 Docker Registry：​ 类似GitHub,只不过Docker Registry是存放镜像的仓库， 官方 https://hub.docker.com 国内 https://www.docker-cn.com/ 当然也可以自己部署一个仓库，建议用Harbor。 Docker Daemon：​ Docker进程，Docker核心服务。 这个类比数据库，比如数据库是放数据的，启动数据库后，等待客户端连接后才能操作。 也就是当docker启动时，等待docker客户端来操作。 Docker Client：​ Docker客户端工具,用来操作Docker的 比如我想在仓库下载一个镜像，从而启动一个容器，在容器中启动一个nginx服务,都是在客户端操作的。（docker client是发出者，docker daemon是执行者） 这里提到的镜像和容器一定要区分清楚。 如果是开发,那这么理解：镜像就是你创建的类，容器就是你的对象，对象是通过类实例化而来。也就是容器通过镜像而来,（容器依赖于镜像） 不要问镜像怎么来的，上面提过镜像是在仓库中。 也不要问仓库中的镜像怎么来的，那是别人做好的。因为你也可以自己做镜像。 Docker客户端操作12docker --help 格式:docker [option] command [args] 镜像类操作1234567891011121314docker search SOFTWARE_NAME #查找镜像名称示例: docker search tomcat #查找tomcat相关镜像，通常建议使用官方镜像，OFFICIAL 为OK的，或者Star点赞数高的镜像，原因自己悟docker pull SOFTWARE_NAME:TAGS #下载镜像示例: docker pull tomcat #下载tomcat镜像，如果不指定tags就下载latest版本 docker pull tomcat:7.0.92-jre8-alpine #详见hub.docker.com找到指定的镜像后在看tagdocker image ls #查看本地镜像，如果没有下载那么这里为空docker image rm SOFTWARE_NAME:TAGS #删除本地镜像示例: docker image rm tomcat #如果不指定删除镜像版本默认删除latest 容器类操作123456789101112131415161718192021222324252627282930313233343536373839404142docker run #运行容器，需要指定镜像实例: docker run tomcat #运行镜像为tomcat的容器,容器里面有tomcat,启动容器后tomcat也将运行起来，容器里面的程序都是在前台运行，会占用窗口 docker run --name myapp -d tomcat #启动myapp容器，镜像使用tomcat:latest，以后台运行 更多命令使用:docker run --help docker ps #查看运行中的容器CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESee1ff8df6e70 tomcat "catalina.sh run" 3 seconds ago Up 2 seconds 8080/tcp myapp说明: 如果在docker run不指定容器名称会随机创建一个容器名称。 端口是容器内的端口.关于docker网络的内容下面会有讲解docker exec实例: docker exec -it myapp /bin/bash #进入myapp容器中 -it #新建一个tty并且进入docker stop实例: docker stop myapp #停止myapp容器 docker ps -a #查看所有容器，如果不加-a不能看到停止的容器 docker start实例: docker start myapp #运行停止的容器docker restart #重启容器实例: docker restart myappdocker rm #删除容器实例: docker rm myappdocker logs #查看容器运行的程序日志实例: docker logs myapp docker kill #杀死容器里的进程，进程一旦停止，容器也就停止。因为容器一般只运行一个前台程序，容器的生命周期下面会讲解实例: docker kill myapp Docker ImageDocker镜像包含启动容器的所需文件系统以及其内容，因此，用于创建并启动docker容器： 分层机制：镜像采用分层构建机制，最底层为bootfs,其为rootfs。 rootfs：用于系统引导的文件系统，包含bootloader和kernel，容器启动完成后被卸载以节约内存资源 rootfs：位于bootfs之上，表现为docker容器根文件系统 传统模式中，系统启动时，内核挂载rootfs时首先将其挂载为“只读”模式，自检其完整性 完成后将其重新挂载为读写模式 docker中，rootfs由内核挂载为“只读”模式，而通过“联合挂载”技术额外挂载一个可写层，容器就是在镜像多了一个可写层 传统模式: Docker: docker镜像层级：位于下层的镜像 称之为 父镜像(parent image)，最底层的称之为 基础镜像(base image) 最上层“可读写成”，下面为“只读层” 联合挂载：Aufs（advanced multi-layered unification filesystem ） 高级多层统一文件系统，同于实现linux平台中的联合挂载 Aufs是unionFS的重新实现,docker最初使用aufs作为容器文件系统层，目前仍作为存储后端之一来支持 Aufs另外一个实现是overlayFS，后者从3.18版本中开始被合并到linux内核中，overlayerFS是叠加文件系统 除了aufs，docker还支持btrFS,Device Mapper和VSF等。在ubuntu中，默认是aufs device mapper在linux2.6中支持逻辑卷管理的通过设备映射机制，它为实现用于存储资源管理的块设备驱动提供一个高度模块化的内核架构，它通过一个个模块化的target driver插件实现对IO请求的过滤或者重新定向等工作，当前已经实现的target driver插件包括软raid，软加密，逻辑卷条带，多路径，镜像，快照等。 docker使用Thin provisioning的snapshot的技术实现了类似auFS分层镜像 12&gt; docker info | grep "Storage Driver:" #来查看&gt; Docker ContainerDocker容器具有生命周期，”STOPD”,’CREATED’,’RUNNING’,’PAUSED’四个稳定状态， 容器一旦删除数据就会丢失，所以项目或者配置文件不要直接存放在容器中，通过卷（volume）的方式挂载至容器里. Docker事件状态图: Docker Registry当容器启动时,docker daemon会试图先从本地获取相关镜像，当本地不存在的时候，其将从registry中下载该镜像并保存在本地 流程图: docker client &lt; - - - http/https - - - &gt;docker daemon &lt; - - - http/https - - - &gt;docker registry 默认是使用https连接到registry，但是可以修改成http Registry 分类registry用于保存docker镜像，包括镜像的层次结构和元数据: 用户可自建registry，也可以使用官方的docker hub 分类: sponsor registry 第三方registry，供客户和docker社区使用 mirror registry 第三方registry，只让客户用 verdor registry 由发布docker镜像的供应商提供registry private registry 通过舍友防火墙和额外的安全层的私有实体提供的registry repository及indexrepository 由某种特定的docker镜像的所有迭代版本组成的镜像仓库 一个registry中可以存在多个repository repository 可以为”顶层仓库”和“用户仓库” 用户仓库名称格式”用户名/仓库名” 每个仓库可以包含多个Tag，每个标签对应一个镜像 index 维护用户账号,镜像的校验以及公共命名空间的信息 相当于为Registry提供了一个完成用户认证等功能的检索接口 镜像相关操作主要介绍镜像如何生成，和如何推送镜像至仓库 镜像生成方式:​ 有三种方式：基于容器方式，Dockerfile方式，Docker Hub Automated Builds 基于容器制作镜像:1234567891011121314151617181920docker run --name web1 -it busybox &gt;mkdir -p /data/www/ &gt;echo "&lt;h1&gt;welcome busybox http server&lt;/h1&gt;" &gt; /data/www/index.html #注意:基于容器制作镜像，容器必须处于运行状态，这里切换终端 docker commit -p web1 #commit制作镜像前需要—p暂停docker image ls #可以看到镜像制作完成（缺少tag） docker tag IMAGEID zhuxyid/busyhttp:v1 #给刚才制作的镜像打标签(可以打多个标签) docker tag zhuxyid/busyhttp:v1 zhuxyid/busyhttp:test_env #在打一个标签 docker image rm zhuxyid/busyhttp:v1 #这里只是删除一个标签，并没有删除镜像 #查看镜像启动时候运行的命令 docker inspect web1 | grep -A 5 "Cmd" #如何在制作镜像运行时执行启动命令 docker commit -a "作者:zhuxy" -c 'CMD ["/bin/httpd","-f","-h","/data/www"]' -p web1 zhuxyid/busyhttp:test_env#运行制作后的镜像 docker run --name -d webserver zhuxyid/busyhttp:test_env 基于Dockerfile制作镜像: 详见:http://blog.zhuxyid.com/2018/11/26/Dockerfile/ 推送镜像推送到官方首先需要有hub.docker.com账号 ，hub.docker.com需要先建立好repositories 示例：这里的是zhuxyid/busyhttp命名,要跟本地的镜像保持一致 12345docker login #输入账号密码才可以登录 docker push zhuxyid/busyhttp:test_env #推送制作的镜像docker logout 推送到阿里云需要修改docker配置文件中的推送地址 12345678910111213141516171819#修改docker配置文件添加registry-mirrors,https://brjvf90f.mirror.aliyuncs.com为我自己的阿里云镜像仓库vi /etc/docker/daemon.json &#123; "registry-mirrors":["https://registry.docker-cn.com","https://brjvf90f.mirror.aliyuncs.com"]&#125;&#125;#重载配置文件并重启systemctl daemon-reloadsystemctl restart docker.service #阿里云创建命名空间，在创建镜像仓库 docker login --username=zhuxyid registry.cn-hangzhou.aliyuncs.com #先重命名镜像标签 docker tag imagename registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:test_env#在推送到阿里云docker push registry.cn-hangzhou.aliyuncs.com/zhuxyid/busyhttp:version docker logout 镜像导入导出1234567#在本地导出镜像包，推送到目标机docker save -o busyhttp.gz zhuxyid/busyhttp:latest .. #可以打包多个文件 scp busyhttp.gz root@REMOTEIP:/opt#在目标机上导入推送的镜像docker load -i busyhttp.gz docker image ls Docker网络Docker安装后自动创建docker0网卡(虚拟) 网络虚拟化技术实现: OVS：Open VSwitch 开源虚拟交换 SDN：Software Defined Network 软件定义网络（需要硬件和软件支持） Docker网络接口Docker有三种网络接口： bridge，host，none，Containers 123456789docker image lsNETWORK ID NAME DRIVER SCOPE1f03c706f810 bridge bridge local75c5f8de6db4 host host local871ede94efa8 none null localbridge 桥接物理主机网卡(默认).这里是nat桥接，并不是物理桥接，如果是物理桥接,如果一个交换机下每个宿主机都有十几个容器，很容易导致广播风暴host 使用物理主机的名称空间none 不使用网络(特殊场景,有些程序不需要使用网络通信,比如自动任务不需要网络通信) docker安装后，会生成docker0，此网卡是个NAT桥，当启动容器的时候，宿主机也会生成veth*虚拟网卡，该网卡和容器内的网卡绑定，而veth*就是跟docker0相连，可以使用brctl show来查看 12345678910yum install bridge-utilsbrctl show #可以看出veth网络都是跟docker0关联bridge name bridge id STP enabled interfacesdocker0 8000.024259bff40e no veth05116c6 vethf8f26a6 iptables -t nat -vnL #查看POSTROUTING链,可以看出容器内访问其他网络都是通过MASQUERADE地址伪装方式访问Chain POSTROUTING (policy ACCEPT 54 packets, 3570 bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 Docker通讯Docker中如果外部想访问内部的服务有如下三种方式: Bridge方式： 通过桥接，然后设置dnat才能被其他主机访问 Containers方式: 容器可以将6个名称空间分层: 如：docker-a和docker-b docker-a独立6个名称空间:USER,MOUNT,PID,UTS,NET,IPC docker-b独立3个名称空间:USER,MOUNT,PID,另外UTS,NET,IPC共享docker-a的 Host方式： 相当于Open container方式，只不过直接使用宿主机的UTS.NET.IPC Docker 网络相关命令指定网络类型以及端口映射123456789101112#docker run --name test -it --rm busybox:latest #运行busybox命名为test，执行完后直接删除 --network [none|bridge] #指定网络类型(默认是bridge) --hostname|-h HOSTNAME #指定主机名 --dns 114.114.114.114 #指定dns --add-host HOST:IP #设置容器hosts #映射 -p &lt;containerPort&gt; #将指定的容器端口 映射至 主机所有地址的一个动态端口 -p &lt;hostPort&gt;:&lt;containerPort&gt; #将容器端口containerPort 映射至 主机指定的主机端口&lt;host Port&gt; -p &lt;ip&gt;::&lt;containerPort&gt; #将指定的容器端口&lt;containerPort&gt; 映射至 主机指定&lt;ip&gt;的动态端口 -p &lt;ip&gt;:&lt;HostPort&gt;:&lt;containerPort&gt;#将指定容器端口&lt;containerPort&gt;映射至主机指定&lt;ip&gt;的端口&lt;hostPort&gt; -P #-P暴露所有端口 Bridge1234567docker run --name test -it --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --network bridge --rm busybox:latestdocker run --name test -it -h webserver.node1 --dns 114.114.114.114 --rm busybox:latestdocker run --name webserver -p 80 -d busybox/httpd:latest #本地随机端口映射到容器的80端口docker run --name webserver -p 80:80 -d busybox/httpd:latest #本地80端口映射到容器的80端口docker port webserver #查看webserver容器端口 Containers联盟式容器是指使用某个已存在容器的网络接口的容器，接口被联盟内的各容器共享使用，因此，联盟式容器彼此间完全无隔离 #创建一个监听于80端口的http服务容器 docker run -d --it --rm -p 80:80 busybox/httpd:laster #创建一个联盟式容器 docker run --name web1 -it --rm busybox/httpd docker run --name web2 --network container:web1 -it --rm busybox/httpd #在web2中创建的文件web1看不到，因为隔离Mount名称空间，但是web1和web2的ip是一样的，因为web2共享了web1的Net名称空间 #联盟式容器彼此间 虽然 共享同一个网络名称空间，但其他名称空间如User,Mount，Pid等还是隔离的 #联盟式容器彼此间存在端口冲突的可能性，因此，通常只会在多个容器上的程序需要程序lookback接口互相通信，或对某已存在的容器的网络属性进行监控时才使用此模式的网络模型 Host 创建一个宿主机host的容器 123docker run --name webserver --network host -it --rm busybox/httpd#使用宿主机的IP，可能会郁闷，这跟直接在主机上部署个httpd服务在启动有什么不一样么？#容器，容器可以更加方便移值，直接run container就可以运行了。 Docker存储关于卷Docker镜像由多个只读层叠加而成，启动容器时，docker会加载只读镜像层 并在镜像栈顶部 添加一个 读写层，如果运行中容器修改了现有的一个已挂载的文件，那该文件将会从 读写层下面的只读层 复制到读写层，该文件的只读版本依然存在，只是已经被读写层中该文件的副本所修改，即“写时复制(COW)”机制 注意:在IO要求高应用中，如果使用容器的话，那么效率非常低 Container: /data/web &lt; - - - - 建立绑定关系Mount - - - - &gt; Host:/container/web1/data/web 在容器写入时候，可以绕过容器内部层级关系 命名空间Mount是相互独立的,可以共享,关联到存储卷Volume，只要容器挂载存储卷.当容器被停止或者删除后,文件内容不被删除。 为什么用存储卷关闭并重启容器，其数据不受影响，但是删除容器，则数据全部丢失 存在的问题: 存储于联合文件系统中，不易于宿主机访问 容器间数据共享不便利 删除容器其数据丢失 卷的描述卷在容器初始化时候 会自动创建，由base image提供的卷中数据会于此间 完成复制 卷的初衷是独立于容器的生命周期实现数据持久化，因此删除容器时不会删除卷，也不会对哪怕未被应用的卷做垃圾回收 卷为docker提供了独立于容器的数据管理机制 可以把”镜像” 比作成静态文件，例如“程序” ，把卷类比为动态内容，例如“数据”；于是镜像可以重用，而卷可以共享 卷实现了”程序(镜像)”和“数据(卷)”分离，以及 “程序(镜像)”和“制作镜像主机”分离，用户制作镜像时无需考虑镜像运行容器所在的主机环境 卷的类型docker有两种类型的卷，每种类型都在容器中存在一个挂载点，但其在宿主机上的位置有所不同 绑定挂载卷 bind mount volume: 在宿主机人工指定特定路径，在容器也人工指定特定路径，将两者绑定 容器管理卷 docker-managed volume: 宿主机不需要指定路径(docker daemon)，容器中需要指定路径，docker自动将两者绑定 如何使用卷12345678910111213141516171819docker run -v 选项docker-managed volumedocker run -it --name web1 -v /data busyboxdocker inspect -f &#123;&#123;.Mounts&#125;&#125; web1 #查看容器卷绑定关系docker run -it -v HOSTDIR:VOLUMEDIR --name web2 busyboxdocker run -it -v /data:/test --name web2 busybox #本机的data跟容器的test绑定，如果data不存在自动创建docker inspect -f &#123;&#123;.Mounts&#125;&#125; web1docker inspect -f &#123;&#123;.NetworkSettings.Networks.bridge.IPAddress&#125;&#125; web1 #获取web1下的ip地址#多个容器的卷使用同一个主机目录docker run -it --name nginx1 -v /docker/volumes/html:/data busyboxdocker run -it --name tomcat1 -v /docker/volumes/class:/data busybox#复制使用其他容器的卷，为docker run命令使用--volumes-formdocker run -it --name tomcat2 -v /docker/volumes/class:/data busyboxdocker run -it --name tomcat3 --network container:tomcat2 --volumes-from tomcat2 busybox #共享网络和卷 Docker资源限制默认情况下,系统对容器没有做任何资源限制，容器可以使用掉宿主机所有资源。 docker provides可以控制Memory，CPU， Block IO（其实只能控制内存和CPU） 依赖于Linux Capabilities 。 这里需要注意:内存是非可压缩资源，CPU可压缩资源 ​ 如何内存被进程耗尽会触发OOME直接KILL进程，而CPU没有关系 OOM在linux主机中，如果内核探测到当前宿主机没有足够内存可用(用于执行某些重要的系统功能)会抛出OOME 异常，并且kill掉某些进行保证其正常,一旦发生OOME,任何进程包括docker daemon在内,都有可能杀死。因此docker特地调整 docker daemon的OOM优先级，以免它被内核”杀死”，但容器的优先级并未被调整 。 优先级越低，得分越低，通常检测oom-adj，分数越高越容易被kill 不重要的业务建议oom-adj默认值，重要的调低oom-adj Memory从ram，swap两个层面: 123限制单位k,b,m,g-m | --memory 限制ram内存 -m 1g 限制ram为1g，如果后期资源占用超过1G，可能被kill掉，-m|--memory可以单独设置--memory-swap * 限制swap内存 必须先设置-m|--memory –memory-swap –memory 功能 正数S 正数M 容器可用总空间为S,其中ram为M,swap为(S-M),如果S=M，则无可用swap资源 0 正数M 相当没有设置swap(unset) unset 正数M 若主机(docker host)启用swap,则容器可用的swap为2*M 1 正数M 若主机(docker host)启用了swap,则容器可使用最大至主机上的所有swap空间的swap资源 注:在容器使用free命令可用看到swap空间并不具有 其所展现出空间的指示意义 设置–memory-swap必须大于–memory 12345--memory-swapiness 限制容器的虚拟内存控制行为0~100间整数--memory-reservation 限制预留空间大小--kernel-memory 核心内存的限制--oom-kill-disable 如果容器重要，禁止oom被kill掉--oom-score-adj 容器被OOM killer杀死的优先级，范围[-1000,1000]默认为0 CPU默认情况下每个容器，可以使用CPU的资源.大多数系统，系统在调度时候使用CFS调度 (CFS完全公平调度器) 在docker1.13后，可以设置实时调度 1234567--cpus=&lt;value&gt; #设置CPU使用几核心，如果容器只设置了--cpus = 2，那么该容器只能使用200%的cpu--cpu-period=&lt;value&gt; #最多使用多长时间--cpu-quota=&lt;value&gt; #指定周期内--cpuset-cpus #设置容器只能运行在那核心CPU上,如果4核心这里是0~3 如果上面设置--cpus=2 --cpuset-cpus 1,2 意思是使用2核心，只在cpu2和cpu3上面使用--cpu-shares #设置cpu权重，按比例切分，默认权重是1024，CPU是资源共享(因为可以压缩)，只有在系统cpu繁忙时候才体现出来，比如1核心的CPU，两个容器，其中一个A容器设置1024，另一个B设置512，当cpu都需要使用cpu的时候，就按比例分2:1(a是b的两倍) (a使用66% b使用33%)#当512的权重空闲的时候，1024的容器可以吃掉所有CPU。#如果3核心CPU，三个容器，a设置2048，b设置512，c设置1024，当三个都繁忙的时候比例是(4:1:2) (a使用56%,b使用14%,c使用28%) docekr-stress-ng压缩1234567docker run --rm lorel/docker-stress-ng --helpdocker run --name stree1 -it --rm -m 256 lorel/docker-stressng --vm 2docker run --name stree2 -it --rm -cpus 2 lorel/docker-stress-ng --cpu 8docker run --name stree2 -it --rm --cpu-shares 1024 lorel/docker-stress-ng --cpu 8docker top stree1 查看stree1的进程运行情况docker stats 查看容器状态 小结 这些主要是针对CentOS7.4，对于其他平台或者版本可能实现方式略有不同。 如：在macOS下面对于 网络 和 卷 都有不同的地方。 网络在macOS中没有docker0桥，无法ping通容器，只能使用-P 或者-p映射端口的形式访问容器，或者通过host.docker.internal特殊DNS，解析为主机使用的内部IP地址。 卷的话如果要绑定User以外的目录，则需要修改权限让容器内部可以访问该目录，不然直接挂载会提示权限不足情况 暂时遇到这么多，感谢志哥让我遇到这么多坑。 主要是讲解一下Docker基础方面，后期的Dockerfile和Docker Registry在慢慢总结，如果本文有错误，还请大牛指出，谢谢:)]]></content>
      <categories>
        <category>Container</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
</search>
